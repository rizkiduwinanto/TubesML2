{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar Pembelajaran Mesin 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pustaka Terkait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, metrics\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a. Create a Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deskripsi Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritma ini menghitung.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Code Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.history = d = {'acc': [], 'val_acc': [], 'loss': [], 'val_loss': []}\n",
    "    \n",
    "    def feed_forward(self, activation):\n",
    "        for bias, weight in zip(self.biases, self.weights):\n",
    "            activation = sigmoid(np.dot(weight, activation) + bias.transpose()[0])\n",
    "        return activation\n",
    "    \n",
    "    def fit(self, training_data, epochs, mini_batch_size, learning_rate,\n",
    "            momentum=0, validation_data=None, validation_split=0.0):\n",
    "        if validation_split != 0.0 and not validation_data :\n",
    "            training_data, validation_data = train_test_split(training_data, test_size=validation_split, random_state=42)\n",
    "        n_training = len(training_data)\n",
    "        if validation_data or validation_split != 0.0: \n",
    "            n_validation = len(validation_data)\n",
    "            print(\"Train on {} samples, validate on {} samples\".format(n_training, n_validation))\n",
    "        for epoch in range(epochs):\n",
    "            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n_training, mini_batch_size)]\n",
    "            previous_weights = self.weights\n",
    "            previous_biases =self.biases\n",
    "            first = True\n",
    "            for mini_batch in mini_batches:\n",
    "                if first: previous_weights, previous_biases = self.weights, self.biases\n",
    "                start = time.time()\n",
    "                previous_weights, previous_biases = self.update_mini_batch(mini_batch, \n",
    "                                                                           learning_rate,\n",
    "                                                                           momentum, \n",
    "                                                                           previous_weights, \n",
    "                                                                           previous_biases)\n",
    "                end = time.time() - start\n",
    "            if validation_data or validation_split != 0:\n",
    "                training_accuracy, training_loss = self.evaluate(mini_batches[0])\n",
    "                validation_accuracy, validation_loss = self.evaluate(validation_data)\n",
    "                self.history['acc'].append(training_accuracy)\n",
    "                self.history['val_acc'].append(validation_accuracy)\n",
    "                self.history['loss'].append(training_loss)\n",
    "                self.history['val_loss'].append(validation_loss)\n",
    "                print(\"Epoch {}/{} : {} s - loss: {} - acc: {} - val_loss: {} - val_acc: {}\".format(epoch + 1, \n",
    "                                                                                                    epochs,\n",
    "                                                                                                    end,\n",
    "                                                                                                    training_loss,\n",
    "                                                                                                    training_accuracy,\n",
    "                                                                                                    validation_loss,\n",
    "                                                                                                    validation_accuracy))\n",
    "            else :\n",
    "                print(\"Epoch {} complete.\".format(epoch + 1))\n",
    "        \n",
    "    def update_mini_batch(self, mini_batch, learning_rate, momentum, previous_weights, previous_biases):\n",
    "        nabla_biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        nabla_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_bias, delta_nabla_weights = self.backpropagation(x, y)\n",
    "            nabla_biases = [nb + dnb for nb, dnb in zip(nabla_biases, delta_nabla_bias)]\n",
    "            nabla_weights = [nw + dnw for nw, dnw in zip(nabla_weights, delta_nabla_weights)]\n",
    "        temp_weights = self.weights\n",
    "        temp_biases = self.biases\n",
    "        self.weights = [w + momentum * pw + (learning_rate/len(mini_batch)) * nw \n",
    "                        for w, nw, pw in zip(self.weights, nabla_weights, previous_weights)]\n",
    "        self.biases = [b + momentum * pb + (learning_rate/len(mini_batch)) * nb \n",
    "                       for b, nb, pb in zip(self.biases, nabla_biases, previous_biases)]\n",
    "        return (temp_weights, temp_biases)\n",
    "        \n",
    "    def backpropagation(self, x, y):\n",
    "        nabla_bias = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        nabla_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        z_vectors = []\n",
    "        \n",
    "        for bias, weight in zip(self.biases, self.weights):\n",
    "            z = np.dot(weight, activation) + bias.transpose()[0]\n",
    "            z_vectors.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(z_vectors[-1])\n",
    "        nabla_bias[-1] = delta\n",
    "        delta_newaxis = delta[:, np.newaxis]\n",
    "        m = len(activations[-2])\n",
    "        activations_newaxis = activations[-2][:, np.newaxis].reshape(1, m)\n",
    "        nabla_weights[-1] = np.dot(delta_newaxis, activations_newaxis)\n",
    "        \n",
    "        for layer in range(2, self.num_layers):\n",
    "            z = z_vectors[-layer]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-layer+1].transpose(), delta) * sp\n",
    "            nabla_bias[-layer] = delta\n",
    "            delta_newaxis = delta[:, np.newaxis]\n",
    "            m = len(activations[-layer-1].transpose())\n",
    "            activations_newaxis = activations[-layer-1].transpose()[:, np.newaxis].reshape(1, m)\n",
    "            nabla_weights[-layer] = np.dot(delta_newaxis, activations_newaxis)\n",
    "        \n",
    "        return (nabla_bias, nabla_weights)\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(1 if self.feed_forward(x) * 2 >= 1 else 0, y) for x, y in test_data]\n",
    "        accuracy = sum(int(x == y) for x, y in test_results)/len(test_results)\n",
    "        loss = sum(pow(int(y - x), 2) for x, y in test_results)/len(test_results)\n",
    "        return accuracy, loss\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        test_results = [1 if self.feed_forward(x) * 2 >= 1 else 0 for x, y in test_data]\n",
    "        return (test_results)\n",
    "    \n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return np.squeeze(y - output_activations)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percobaan pada Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/200 : 0.00019550323486328125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 2/200 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 3/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 4/200 : 0.00015234947204589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 5/200 : 0.00016999244689941406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 6/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 7/200 : 0.00015211105346679688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 8/200 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 9/200 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 10/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 11/200 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 12/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 13/200 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 14/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 15/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 16/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 17/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 18/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 19/200 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 20/200 : 0.00015115737915039062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 21/200 : 0.0001518726348876953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 22/200 : 0.0001513957977294922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 23/200 : 0.0001513957977294922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 24/200 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 25/200 : 0.0001533031463623047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 26/200 : 0.0001533031463623047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 27/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 28/200 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 29/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 30/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 31/200 : 0.0001513957977294922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 32/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 33/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 34/200 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 35/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 36/200 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 37/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 38/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 39/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 40/200 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 41/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 42/200 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 43/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 44/200 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 45/200 : 0.00015211105346679688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 46/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 47/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 48/200 : 0.00022149085998535156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 49/200 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 50/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 51/200 : 0.00019407272338867188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 52/200 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 53/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 54/200 : 0.00017690658569335938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 55/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 56/200 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 57/200 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 58/200 : 0.0001552104949951172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 59/200 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 60/200 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 61/200 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 62/200 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 63/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 64/200 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 65/200 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 66/200 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 67/200 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 68/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 69/200 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 70/200 : 0.0001773834228515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 71/200 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 72/200 : 0.00017595291137695312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 73/200 : 0.00030517578125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 74/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 75/200 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 76/200 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 77/200 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 78/200 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 79/200 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 80/200 : 0.0001533031463623047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 81/200 : 0.00017690658569335938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 82/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 83/200 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 84/200 : 0.00016307830810546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 85/200 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 86/200 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 87/200 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 88/200 : 0.00016117095947265625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 89/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 91/200 : 0.00022935867309570312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 92/200 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 93/200 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 94/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 95/200 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 96/200 : 0.0001666545867919922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 97/200 : 0.00015473365783691406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 98/200 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 99/200 : 0.0001552104949951172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 100/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 101/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 102/200 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 103/200 : 0.0001552104949951172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 104/200 : 0.0002086162567138672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 105/200 : 0.0001544952392578125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 106/200 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 107/200 : 0.00015473365783691406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 108/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 109/200 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 110/200 : 0.00022220611572265625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 111/200 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 112/200 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 113/200 : 0.0001773834228515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 114/200 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 115/200 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 116/200 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 117/200 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 118/200 : 0.0001552104949951172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 119/200 : 0.00018286705017089844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 120/200 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 121/200 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 122/200 : 0.00017881393432617188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 123/200 : 0.00021576881408691406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 124/200 : 0.00015211105346679688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 125/200 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 126/200 : 0.00015234947204589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 127/200 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 128/200 : 0.00015234947204589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 129/200 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 130/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 131/200 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 132/200 : 0.0001513957977294922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 133/200 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 134/200 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 135/200 : 0.00015115737915039062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 136/200 : 0.0001518726348876953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 137/200 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 138/200 : 0.0001533031463623047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 139/200 : 0.0001804828643798828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 140/200 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 141/200 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 142/200 : 0.00034236907958984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 143/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 144/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 145/200 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 146/200 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 147/200 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 148/200 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 149/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 150/200 : 0.00015473365783691406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 151/200 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 152/200 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 153/200 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 154/200 : 0.0002989768981933594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 155/200 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 156/200 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 157/200 : 0.0001628398895263672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 158/200 : 0.0001518726348876953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 159/200 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 160/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 161/200 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 162/200 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 163/200 : 0.00017070770263671875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 164/200 : 0.00017070770263671875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 165/200 : 0.0001709461212158203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 166/200 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 167/200 : 0.0001785755157470703 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 168/200 : 0.00016045570373535156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 169/200 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 170/200 : 0.00017023086547851562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 171/200 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 172/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 173/200 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 174/200 : 0.00017023086547851562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 175/200 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 176/200 : 0.0001709461212158203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 178/200 : 0.00021266937255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 179/200 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 180/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 181/200 : 0.00017118453979492188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 182/200 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 183/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 184/200 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 185/200 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 186/200 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 187/200 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 188/200 : 0.0001761913299560547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 189/200 : 0.00020360946655273438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 190/200 : 0.0001823902130126953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 191/200 : 0.00015234947204589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 192/200 : 0.00028014183044433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 193/200 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 194/200 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 195/200 : 0.0002117156982421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 196/200 : 0.0002415180206298828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 197/200 : 0.00028514862060546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 198/200 : 0.00020241737365722656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 199/200 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 200/200 : 0.00015163421630859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "neural_network = Network([4, 2, 3, 4, 1])\n",
    "neural_network.fit(train_data, 200, 1, 0.1, momentum=0.0001, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, loss = neural_network.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.0 %\n",
      "Accuracy 60.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(accuracy*100.0))\n",
    "print(\"Accuracy {} %\".format(loss*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network.history['acc'])\n",
    "plt.plot(neural_network.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network.history['loss'])\n",
    "plt.plot(neural_network.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Explorasi Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deskripsi Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembelajaran akan menggunakan kakas keras dengan model <i>sequential</i> dan lapisan <i>dense</i> .Model akan memakai input layer sebanyak 1 neuron dengan bentuk input 4 sesuai jumlah attribute data latih, kemudian dengan 3 hidden layer masing-masing 2 neuron kemudian 3 neuron, dan 4 neuron dan 1 output layer dengan 1 neuron. Optimizer yang dipakai adalah Adam (Adaptive Moment Estimation), dengan perhitungan loss dengan Mean Squared Error, dan Metrics Accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Code Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(1, activation='sigmoid', input_shape=(4,)))\n",
    "network.add(Dense(2, activation='sigmoid'))\n",
    "network.add(Dense(3, activation='sigmoid'))\n",
    "network.add(Dense(4, activation='sigmoid'))\n",
    "network.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percobaan pada Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/200\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.7466 - acc: 0.3223 - val_loss: 0.8980 - val_acc: 0.3571\n",
      "Epoch 2/200\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.7318 - acc: 0.3223 - val_loss: 0.8671 - val_acc: 0.3571\n",
      "Epoch 3/200\n",
      "121/121 [==============================] - 0s 962us/step - loss: 0.7211 - acc: 0.3223 - val_loss: 0.8398 - val_acc: 0.3571\n",
      "Epoch 4/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7126 - acc: 0.3223 - val_loss: 0.8195 - val_acc: 0.3571\n",
      "Epoch 5/200\n",
      "121/121 [==============================] - 0s 967us/step - loss: 0.7068 - acc: 0.3223 - val_loss: 0.8027 - val_acc: 0.3571\n",
      "Epoch 6/200\n",
      "121/121 [==============================] - 0s 978us/step - loss: 0.7020 - acc: 0.3223 - val_loss: 0.7876 - val_acc: 0.3571\n",
      "Epoch 7/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6982 - acc: 0.3223 - val_loss: 0.7749 - val_acc: 0.3571\n",
      "Epoch 8/200\n",
      "121/121 [==============================] - 0s 971us/step - loss: 0.6954 - acc: 0.3223 - val_loss: 0.7663 - val_acc: 0.3571\n",
      "Epoch 9/200\n",
      "121/121 [==============================] - 0s 961us/step - loss: 0.6928 - acc: 0.3223 - val_loss: 0.7570 - val_acc: 0.3571\n",
      "Epoch 10/200\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.6908 - acc: 0.3223 - val_loss: 0.7505 - val_acc: 0.3571\n",
      "Epoch 11/200\n",
      "121/121 [==============================] - 0s 945us/step - loss: 0.6892 - acc: 0.3223 - val_loss: 0.7434 - val_acc: 0.3571\n",
      "Epoch 12/200\n",
      "121/121 [==============================] - 0s 989us/step - loss: 0.6879 - acc: 0.3223 - val_loss: 0.7377 - val_acc: 0.3571\n",
      "Epoch 13/200\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.6867 - acc: 0.3223 - val_loss: 0.7312 - val_acc: 0.3571\n",
      "Epoch 14/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6856 - acc: 0.3223 - val_loss: 0.7276 - val_acc: 0.3571\n",
      "Epoch 15/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6849 - acc: 0.3223 - val_loss: 0.7234 - val_acc: 0.3571\n",
      "Epoch 16/200\n",
      "121/121 [==============================] - 0s 914us/step - loss: 0.6841 - acc: 0.3223 - val_loss: 0.7203 - val_acc: 0.3571\n",
      "Epoch 17/200\n",
      "121/121 [==============================] - 0s 991us/step - loss: 0.6835 - acc: 0.3223 - val_loss: 0.7161 - val_acc: 0.3571\n",
      "Epoch 18/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6829 - acc: 0.3223 - val_loss: 0.7122 - val_acc: 0.3571\n",
      "Epoch 19/200\n",
      "121/121 [==============================] - 0s 988us/step - loss: 0.6824 - acc: 0.3223 - val_loss: 0.7099 - val_acc: 0.3571\n",
      "Epoch 20/200\n",
      "121/121 [==============================] - 0s 979us/step - loss: 0.6820 - acc: 0.3223 - val_loss: 0.7070 - val_acc: 0.3571\n",
      "Epoch 21/200\n",
      "121/121 [==============================] - 0s 913us/step - loss: 0.6816 - acc: 0.3223 - val_loss: 0.7045 - val_acc: 0.3571\n",
      "Epoch 22/200\n",
      "121/121 [==============================] - 0s 949us/step - loss: 0.6813 - acc: 0.3223 - val_loss: 0.7030 - val_acc: 0.3571\n",
      "Epoch 23/200\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.6810 - acc: 0.3223 - val_loss: 0.7010 - val_acc: 0.3571\n",
      "Epoch 24/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6807 - acc: 0.3223 - val_loss: 0.6986 - val_acc: 0.3571\n",
      "Epoch 25/200\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.6805 - acc: 0.3223 - val_loss: 0.6967 - val_acc: 0.3571\n",
      "Epoch 26/200\n",
      "121/121 [==============================] - 0s 912us/step - loss: 0.6803 - acc: 0.3223 - val_loss: 0.6950 - val_acc: 0.3571\n",
      "Epoch 27/200\n",
      "121/121 [==============================] - 0s 954us/step - loss: 0.6800 - acc: 0.3223 - val_loss: 0.6942 - val_acc: 0.3571\n",
      "Epoch 28/200\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.6800 - acc: 0.3223 - val_loss: 0.6929 - val_acc: 0.3571\n",
      "Epoch 29/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6797 - acc: 0.3223 - val_loss: 0.6906 - val_acc: 0.3571\n",
      "Epoch 30/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6795 - acc: 0.3223 - val_loss: 0.6896 - val_acc: 0.3571\n",
      "Epoch 31/200\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.6794 - acc: 0.3223 - val_loss: 0.6885 - val_acc: 0.3571\n",
      "Epoch 32/200\n",
      "121/121 [==============================] - 0s 957us/step - loss: 0.6793 - acc: 0.3223 - val_loss: 0.6874 - val_acc: 0.3571\n",
      "Epoch 33/200\n",
      "121/121 [==============================] - 0s 978us/step - loss: 0.6791 - acc: 0.3223 - val_loss: 0.6865 - val_acc: 0.3571\n",
      "Epoch 34/200\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 0.6791 - acc: 0.3223 - val_loss: 0.6845 - val_acc: 0.3571\n",
      "Epoch 35/200\n",
      "121/121 [==============================] - 0s 949us/step - loss: 0.6789 - acc: 0.3223 - val_loss: 0.6840 - val_acc: 0.3571\n",
      "Epoch 36/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6790 - acc: 0.3223 - val_loss: 0.6826 - val_acc: 0.3571\n",
      "Epoch 37/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6788 - acc: 0.3223 - val_loss: 0.6820 - val_acc: 0.3571\n",
      "Epoch 38/200\n",
      "121/121 [==============================] - 0s 996us/step - loss: 0.6787 - acc: 0.3223 - val_loss: 0.6812 - val_acc: 0.3571\n",
      "Epoch 39/200\n",
      "121/121 [==============================] - 0s 881us/step - loss: 0.6786 - acc: 0.3223 - val_loss: 0.6805 - val_acc: 0.3571\n",
      "Epoch 40/200\n",
      "121/121 [==============================] - 0s 948us/step - loss: 0.6786 - acc: 0.3223 - val_loss: 0.6798 - val_acc: 0.3571\n",
      "Epoch 41/200\n",
      "121/121 [==============================] - 0s 920us/step - loss: 0.6786 - acc: 0.3223 - val_loss: 0.6787 - val_acc: 0.3571\n",
      "Epoch 42/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6784 - acc: 0.3223 - val_loss: 0.6781 - val_acc: 0.3571\n",
      "Epoch 43/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6784 - acc: 0.3223 - val_loss: 0.6775 - val_acc: 0.3571\n",
      "Epoch 44/200\n",
      "121/121 [==============================] - 0s 872us/step - loss: 0.6784 - acc: 0.3223 - val_loss: 0.6767 - val_acc: 0.3571\n",
      "Epoch 45/200\n",
      "121/121 [==============================] - 0s 954us/step - loss: 0.6783 - acc: 0.3223 - val_loss: 0.6762 - val_acc: 0.3571\n",
      "Epoch 46/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6782 - acc: 0.3223 - val_loss: 0.6754 - val_acc: 0.3571\n",
      "Epoch 47/200\n",
      "121/121 [==============================] - 0s 953us/step - loss: 0.6782 - acc: 0.3223 - val_loss: 0.6744 - val_acc: 0.3571\n",
      "Epoch 48/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6782 - acc: 0.3223 - val_loss: 0.6747 - val_acc: 0.3571\n",
      "Epoch 49/200\n",
      "121/121 [==============================] - 0s 978us/step - loss: 0.6780 - acc: 0.3223 - val_loss: 0.6738 - val_acc: 0.3571\n",
      "Epoch 50/200\n",
      "121/121 [==============================] - 0s 993us/step - loss: 0.6779 - acc: 0.3223 - val_loss: 0.6731 - val_acc: 0.3571\n",
      "Epoch 51/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6778 - acc: 0.3223 - val_loss: 0.6726 - val_acc: 0.3571\n",
      "Epoch 52/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6778 - acc: 0.3223 - val_loss: 0.6721 - val_acc: 0.3571\n",
      "Epoch 53/200\n",
      "121/121 [==============================] - 0s 974us/step - loss: 0.6775 - acc: 0.3223 - val_loss: 0.6718 - val_acc: 0.3571\n",
      "Epoch 54/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6775 - acc: 0.3223 - val_loss: 0.6714 - val_acc: 0.3571\n",
      "Epoch 55/200\n",
      "121/121 [==============================] - 0s 949us/step - loss: 0.6772 - acc: 0.3223 - val_loss: 0.6707 - val_acc: 0.3571\n",
      "Epoch 56/200\n",
      "121/121 [==============================] - 0s 981us/step - loss: 0.6771 - acc: 0.3223 - val_loss: 0.6706 - val_acc: 0.3571\n",
      "Epoch 57/200\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.6768 - acc: 0.3223 - val_loss: 0.6700 - val_acc: 0.3571\n",
      "Epoch 58/200\n",
      "121/121 [==============================] - 0s 920us/step - loss: 0.6765 - acc: 0.3223 - val_loss: 0.6695 - val_acc: 0.3571\n",
      "Epoch 59/200\n",
      "121/121 [==============================] - 0s 979us/step - loss: 0.6762 - acc: 0.3223 - val_loss: 0.6697 - val_acc: 0.3571\n",
      "Epoch 60/200\n",
      "121/121 [==============================] - 0s 963us/step - loss: 0.6758 - acc: 0.3223 - val_loss: 0.6692 - val_acc: 0.3571\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 998us/step - loss: 0.6754 - acc: 0.3223 - val_loss: 0.6683 - val_acc: 0.3571\n",
      "Epoch 62/200\n",
      "121/121 [==============================] - 0s 973us/step - loss: 0.6748 - acc: 0.3223 - val_loss: 0.6687 - val_acc: 0.3571\n",
      "Epoch 63/200\n",
      "121/121 [==============================] - 0s 968us/step - loss: 0.6742 - acc: 0.3223 - val_loss: 0.6686 - val_acc: 0.3571\n",
      "Epoch 64/200\n",
      "121/121 [==============================] - 0s 985us/step - loss: 0.6735 - acc: 0.3223 - val_loss: 0.6679 - val_acc: 0.3571\n",
      "Epoch 65/200\n",
      "121/121 [==============================] - 0s 930us/step - loss: 0.6726 - acc: 0.3223 - val_loss: 0.6681 - val_acc: 0.3571\n",
      "Epoch 66/200\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.6715 - acc: 0.3223 - val_loss: 0.6676 - val_acc: 0.3571\n",
      "Epoch 67/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6704 - acc: 0.3223 - val_loss: 0.6688 - val_acc: 0.3571\n",
      "Epoch 68/200\n",
      "121/121 [==============================] - 0s 944us/step - loss: 0.6687 - acc: 0.3223 - val_loss: 0.6678 - val_acc: 0.3571\n",
      "Epoch 69/200\n",
      "121/121 [==============================] - 0s 977us/step - loss: 0.6671 - acc: 0.3223 - val_loss: 0.6677 - val_acc: 0.3571\n",
      "Epoch 70/200\n",
      "121/121 [==============================] - 0s 934us/step - loss: 0.6647 - acc: 0.3223 - val_loss: 0.6676 - val_acc: 0.3571\n",
      "Epoch 71/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6619 - acc: 0.3223 - val_loss: 0.6682 - val_acc: 0.3571\n",
      "Epoch 72/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6587 - acc: 0.3223 - val_loss: 0.6680 - val_acc: 0.3571\n",
      "Epoch 73/200\n",
      "121/121 [==============================] - 0s 994us/step - loss: 0.6544 - acc: 0.3223 - val_loss: 0.6680 - val_acc: 0.3571\n",
      "Epoch 74/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6491 - acc: 0.3223 - val_loss: 0.6682 - val_acc: 0.3571\n",
      "Epoch 75/200\n",
      "121/121 [==============================] - 0s 953us/step - loss: 0.6421 - acc: 0.3223 - val_loss: 0.6662 - val_acc: 0.3571\n",
      "Epoch 76/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.6341 - acc: 0.3223 - val_loss: 0.6665 - val_acc: 0.3571\n",
      "Epoch 77/200\n",
      "121/121 [==============================] - 0s 900us/step - loss: 0.6233 - acc: 0.3223 - val_loss: 0.6648 - val_acc: 0.3571\n",
      "Epoch 78/200\n",
      "121/121 [==============================] - 0s 879us/step - loss: 0.6104 - acc: 0.3223 - val_loss: 0.6598 - val_acc: 0.3571\n",
      "Epoch 79/200\n",
      "121/121 [==============================] - 0s 958us/step - loss: 0.5958 - acc: 0.3223 - val_loss: 0.6556 - val_acc: 0.3571\n",
      "Epoch 80/200\n",
      "121/121 [==============================] - 0s 961us/step - loss: 0.5782 - acc: 0.3223 - val_loss: 0.6513 - val_acc: 0.3571\n",
      "Epoch 81/200\n",
      "121/121 [==============================] - 0s 936us/step - loss: 0.5594 - acc: 0.3223 - val_loss: 0.6455 - val_acc: 0.3571\n",
      "Epoch 82/200\n",
      "121/121 [==============================] - 0s 915us/step - loss: 0.5405 - acc: 0.3223 - val_loss: 0.6383 - val_acc: 0.3571\n",
      "Epoch 83/200\n",
      "121/121 [==============================] - 0s 934us/step - loss: 0.5219 - acc: 0.3223 - val_loss: 0.6307 - val_acc: 0.3571\n",
      "Epoch 84/200\n",
      "121/121 [==============================] - 0s 869us/step - loss: 0.5038 - acc: 0.3223 - val_loss: 0.6224 - val_acc: 0.3571\n",
      "Epoch 85/200\n",
      "121/121 [==============================] - 0s 933us/step - loss: 0.4868 - acc: 0.3223 - val_loss: 0.6154 - val_acc: 0.3571\n",
      "Epoch 86/200\n",
      "121/121 [==============================] - 0s 941us/step - loss: 0.4718 - acc: 0.3471 - val_loss: 0.6075 - val_acc: 0.5000\n",
      "Epoch 87/200\n",
      "121/121 [==============================] - 0s 921us/step - loss: 0.4581 - acc: 0.6694 - val_loss: 0.5994 - val_acc: 0.5000\n",
      "Epoch 88/200\n",
      "121/121 [==============================] - 0s 965us/step - loss: 0.4459 - acc: 0.6694 - val_loss: 0.5920 - val_acc: 0.5000\n",
      "Epoch 89/200\n",
      "121/121 [==============================] - 0s 988us/step - loss: 0.4347 - acc: 0.6694 - val_loss: 0.5843 - val_acc: 0.5000\n",
      "Epoch 90/200\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.4250 - acc: 0.6694 - val_loss: 0.5788 - val_acc: 0.5000\n",
      "Epoch 91/200\n",
      "121/121 [==============================] - 0s 963us/step - loss: 0.4162 - acc: 0.6694 - val_loss: 0.5721 - val_acc: 0.5000\n",
      "Epoch 92/200\n",
      "121/121 [==============================] - 0s 929us/step - loss: 0.4085 - acc: 0.6694 - val_loss: 0.5669 - val_acc: 0.5000\n",
      "Epoch 93/200\n",
      "121/121 [==============================] - 0s 929us/step - loss: 0.4016 - acc: 0.6694 - val_loss: 0.5617 - val_acc: 0.5000\n",
      "Epoch 94/200\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.3953 - acc: 0.6694 - val_loss: 0.5572 - val_acc: 0.5000\n",
      "Epoch 95/200\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.3899 - acc: 0.6694 - val_loss: 0.5528 - val_acc: 0.5000\n",
      "Epoch 96/200\n",
      "121/121 [==============================] - 0s 914us/step - loss: 0.3848 - acc: 0.6694 - val_loss: 0.5491 - val_acc: 0.5000\n",
      "Epoch 97/200\n",
      "121/121 [==============================] - 0s 988us/step - loss: 0.3803 - acc: 0.6694 - val_loss: 0.5456 - val_acc: 0.5000\n",
      "Epoch 98/200\n",
      "121/121 [==============================] - 0s 913us/step - loss: 0.3763 - acc: 0.6694 - val_loss: 0.5420 - val_acc: 0.5000\n",
      "Epoch 99/200\n",
      "121/121 [==============================] - 0s 925us/step - loss: 0.3726 - acc: 0.6694 - val_loss: 0.5392 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "121/121 [==============================] - 0s 884us/step - loss: 0.3693 - acc: 0.6694 - val_loss: 0.5363 - val_acc: 0.5000\n",
      "Epoch 101/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.3663 - acc: 0.6694 - val_loss: 0.5335 - val_acc: 0.5000\n",
      "Epoch 102/200\n",
      "121/121 [==============================] - 0s 870us/step - loss: 0.3636 - acc: 0.6694 - val_loss: 0.5313 - val_acc: 0.5000\n",
      "Epoch 103/200\n",
      "121/121 [==============================] - 0s 945us/step - loss: 0.3612 - acc: 0.6694 - val_loss: 0.5291 - val_acc: 0.5000\n",
      "Epoch 104/200\n",
      "121/121 [==============================] - 0s 955us/step - loss: 0.3588 - acc: 0.6694 - val_loss: 0.5271 - val_acc: 0.5000\n",
      "Epoch 105/200\n",
      "121/121 [==============================] - 0s 916us/step - loss: 0.3568 - acc: 0.6694 - val_loss: 0.5253 - val_acc: 0.5000\n",
      "Epoch 106/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.3549 - acc: 0.6694 - val_loss: 0.5235 - val_acc: 0.5000\n",
      "Epoch 107/200\n",
      "121/121 [==============================] - 0s 932us/step - loss: 0.3531 - acc: 0.6694 - val_loss: 0.5220 - val_acc: 0.5000\n",
      "Epoch 108/200\n",
      "121/121 [==============================] - 0s 917us/step - loss: 0.3516 - acc: 0.6694 - val_loss: 0.5205 - val_acc: 0.5000\n",
      "Epoch 109/200\n",
      "121/121 [==============================] - 0s 955us/step - loss: 0.3501 - acc: 0.6694 - val_loss: 0.5192 - val_acc: 0.5000\n",
      "Epoch 110/200\n",
      "121/121 [==============================] - 0s 870us/step - loss: 0.3487 - acc: 0.6694 - val_loss: 0.5179 - val_acc: 0.5000\n",
      "Epoch 111/200\n",
      "121/121 [==============================] - 0s 959us/step - loss: 0.3475 - acc: 0.6694 - val_loss: 0.5167 - val_acc: 0.5000\n",
      "Epoch 112/200\n",
      "121/121 [==============================] - 0s 864us/step - loss: 0.3463 - acc: 0.6694 - val_loss: 0.5157 - val_acc: 0.5000\n",
      "Epoch 113/200\n",
      "121/121 [==============================] - 0s 925us/step - loss: 0.3453 - acc: 0.6694 - val_loss: 0.5146 - val_acc: 0.5000\n",
      "Epoch 114/200\n",
      "121/121 [==============================] - 0s 909us/step - loss: 0.3443 - acc: 0.6694 - val_loss: 0.5137 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "121/121 [==============================] - 0s 898us/step - loss: 0.3434 - acc: 0.6694 - val_loss: 0.5129 - val_acc: 0.5000\n",
      "Epoch 116/200\n",
      "121/121 [==============================] - 0s 923us/step - loss: 0.3426 - acc: 0.6694 - val_loss: 0.5121 - val_acc: 0.5000\n",
      "Epoch 117/200\n",
      "121/121 [==============================] - 0s 919us/step - loss: 0.3418 - acc: 0.6694 - val_loss: 0.5113 - val_acc: 0.5000\n",
      "Epoch 118/200\n",
      "121/121 [==============================] - 0s 926us/step - loss: 0.3411 - acc: 0.6694 - val_loss: 0.5106 - val_acc: 0.5000\n",
      "Epoch 119/200\n",
      "121/121 [==============================] - 0s 868us/step - loss: 0.3404 - acc: 0.6694 - val_loss: 0.5100 - val_acc: 0.5000\n",
      "Epoch 120/200\n",
      "121/121 [==============================] - 0s 896us/step - loss: 0.3398 - acc: 0.6694 - val_loss: 0.5094 - val_acc: 0.5000\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 928us/step - loss: 0.3392 - acc: 0.6694 - val_loss: 0.5088 - val_acc: 0.5000\n",
      "Epoch 122/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.3386 - acc: 0.6694 - val_loss: 0.5082 - val_acc: 0.5000\n",
      "Epoch 123/200\n",
      "121/121 [==============================] - 0s 990us/step - loss: 0.3381 - acc: 0.6694 - val_loss: 0.5077 - val_acc: 0.5000\n",
      "Epoch 124/200\n",
      "121/121 [==============================] - 0s 966us/step - loss: 0.3377 - acc: 0.6694 - val_loss: 0.5073 - val_acc: 0.5000\n",
      "Epoch 125/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.3372 - acc: 0.6694 - val_loss: 0.5068 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      "121/121 [==============================] - 0s 928us/step - loss: 0.3368 - acc: 0.6694 - val_loss: 0.5064 - val_acc: 0.5000\n",
      "Epoch 127/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3364 - acc: 0.6694 - val_loss: 0.5060 - val_acc: 0.5000\n",
      "Epoch 128/200\n",
      "121/121 [==============================] - 0s 880us/step - loss: 0.3361 - acc: 0.6694 - val_loss: 0.5057 - val_acc: 0.5000\n",
      "Epoch 129/200\n",
      "121/121 [==============================] - 0s 986us/step - loss: 0.3358 - acc: 0.6694 - val_loss: 0.5053 - val_acc: 0.5000\n",
      "Epoch 130/200\n",
      "121/121 [==============================] - 0s 998us/step - loss: 0.3354 - acc: 0.6694 - val_loss: 0.5050 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "121/121 [==============================] - 0s 966us/step - loss: 0.3351 - acc: 0.6694 - val_loss: 0.5047 - val_acc: 0.5000\n",
      "Epoch 132/200\n",
      "121/121 [==============================] - 0s 972us/step - loss: 0.3349 - acc: 0.6694 - val_loss: 0.5045 - val_acc: 0.5000\n",
      "Epoch 133/200\n",
      "121/121 [==============================] - 0s 999us/step - loss: 0.3346 - acc: 0.6694 - val_loss: 0.5042 - val_acc: 0.5000\n",
      "Epoch 134/200\n",
      "121/121 [==============================] - 0s 938us/step - loss: 0.3344 - acc: 0.6694 - val_loss: 0.5040 - val_acc: 0.5000\n",
      "Epoch 135/200\n",
      "121/121 [==============================] - 0s 913us/step - loss: 0.3342 - acc: 0.6694 - val_loss: 0.5037 - val_acc: 0.5000\n",
      "Epoch 136/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3339 - acc: 0.6694 - val_loss: 0.5035 - val_acc: 0.5000\n",
      "Epoch 137/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3337 - acc: 0.6694 - val_loss: 0.5033 - val_acc: 0.5000\n",
      "Epoch 138/200\n",
      "121/121 [==============================] - 0s 965us/step - loss: 0.3336 - acc: 0.6694 - val_loss: 0.5031 - val_acc: 0.5000\n",
      "Epoch 139/200\n",
      "121/121 [==============================] - 0s 978us/step - loss: 0.3334 - acc: 0.6694 - val_loss: 0.5029 - val_acc: 0.5000\n",
      "Epoch 140/200\n",
      "121/121 [==============================] - 0s 991us/step - loss: 0.3332 - acc: 0.6694 - val_loss: 0.5028 - val_acc: 0.5000\n",
      "Epoch 141/200\n",
      "121/121 [==============================] - 0s 953us/step - loss: 0.3331 - acc: 0.6694 - val_loss: 0.5026 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "121/121 [==============================] - 0s 998us/step - loss: 0.3329 - acc: 0.6694 - val_loss: 0.5025 - val_acc: 0.5000\n",
      "Epoch 143/200\n",
      "121/121 [==============================] - 0s 916us/step - loss: 0.3328 - acc: 0.6694 - val_loss: 0.5023 - val_acc: 0.5000\n",
      "Epoch 144/200\n",
      "121/121 [==============================] - 0s 843us/step - loss: 0.3327 - acc: 0.6694 - val_loss: 0.5022 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "121/121 [==============================] - 0s 968us/step - loss: 0.3325 - acc: 0.6694 - val_loss: 0.5021 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.3324 - acc: 0.6694 - val_loss: 0.5019 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.3323 - acc: 0.6694 - val_loss: 0.5018 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "121/121 [==============================] - 0s 982us/step - loss: 0.3322 - acc: 0.6694 - val_loss: 0.5017 - val_acc: 0.5000\n",
      "Epoch 149/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3321 - acc: 0.6694 - val_loss: 0.5016 - val_acc: 0.5000\n",
      "Epoch 150/200\n",
      "121/121 [==============================] - 0s 976us/step - loss: 0.3320 - acc: 0.6694 - val_loss: 0.5015 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "121/121 [==============================] - 0s 919us/step - loss: 0.3320 - acc: 0.6694 - val_loss: 0.5015 - val_acc: 0.5000\n",
      "Epoch 152/200\n",
      "121/121 [==============================] - 0s 970us/step - loss: 0.3319 - acc: 0.6694 - val_loss: 0.5014 - val_acc: 0.5000\n",
      "Epoch 153/200\n",
      "121/121 [==============================] - 0s 930us/step - loss: 0.3318 - acc: 0.6694 - val_loss: 0.5013 - val_acc: 0.5000\n",
      "Epoch 154/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.3317 - acc: 0.6694 - val_loss: 0.5012 - val_acc: 0.5000\n",
      "Epoch 155/200\n",
      "121/121 [==============================] - 0s 938us/step - loss: 0.3317 - acc: 0.6694 - val_loss: 0.5012 - val_acc: 0.5000\n",
      "Epoch 156/200\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.3316 - acc: 0.6694 - val_loss: 0.5011 - val_acc: 0.5000\n",
      "Epoch 157/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3316 - acc: 0.6694 - val_loss: 0.5010 - val_acc: 0.5000\n",
      "Epoch 158/200\n",
      "121/121 [==============================] - 0s 995us/step - loss: 0.3315 - acc: 0.6694 - val_loss: 0.5010 - val_acc: 0.5000\n",
      "Epoch 159/200\n",
      "121/121 [==============================] - 0s 964us/step - loss: 0.3314 - acc: 0.6694 - val_loss: 0.5009 - val_acc: 0.5000\n",
      "Epoch 160/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3314 - acc: 0.6694 - val_loss: 0.5009 - val_acc: 0.5000\n",
      "Epoch 161/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3314 - acc: 0.6694 - val_loss: 0.5008 - val_acc: 0.5000\n",
      "Epoch 162/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.3313 - acc: 0.6694 - val_loss: 0.5008 - val_acc: 0.5000\n",
      "Epoch 163/200\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.3313 - acc: 0.6694 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 164/200\n",
      "121/121 [==============================] - 0s 917us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 165/200\n",
      "121/121 [==============================] - 0s 921us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 166/200\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 167/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 168/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 169/200\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 170/200\n",
      "121/121 [==============================] - 0s 861us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 171/200\n",
      "121/121 [==============================] - 0s 901us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 172/200\n",
      "121/121 [==============================] - 0s 989us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 173/200\n",
      "121/121 [==============================] - 0s 928us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 174/200\n",
      "121/121 [==============================] - 0s 872us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 175/200\n",
      "121/121 [==============================] - 0s 954us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 176/200\n",
      "121/121 [==============================] - 0s 878us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 177/200\n",
      "121/121 [==============================] - 0s 908us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 178/200\n",
      "121/121 [==============================] - 0s 923us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 179/200\n",
      "121/121 [==============================] - 0s 879us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 180/200\n",
      "121/121 [==============================] - 0s 926us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 933us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 182/200\n",
      "121/121 [==============================] - 0s 971us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 183/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "121/121 [==============================] - 0s 939us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 185/200\n",
      "121/121 [==============================] - 0s 980us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 186/200\n",
      "121/121 [==============================] - 0s 981us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 187/200\n",
      "121/121 [==============================] - 0s 949us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 188/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 189/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "121/121 [==============================] - 0s 966us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 191/200\n",
      "121/121 [==============================] - 0s 938us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 192/200\n",
      "121/121 [==============================] - 0s 957us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 193/200\n",
      "121/121 [==============================] - 0s 916us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 194/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 195/200\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 196/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "121/121 [==============================] - 0s 920us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "121/121 [==============================] - 0s 886us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "121/121 [==============================] - 0s 933us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train, y_train, epochs=200, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 422us/step\n"
     ]
    }
   ],
   "source": [
    "score = network.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 20.006694315406246 %\n",
      "Accuracy 80.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(score[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen Data Categorization Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persiapan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal pertama yang kami lakukan adalah menggunakan data latih Weather Categorization dari WEKA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temperature  humidity  windy play\n",
       "0      sunny           85        85  False   no\n",
       "1      sunny           80        90   True   no\n",
       "2   overcast           83        86  False  yes\n",
       "3      rainy           70        96  False  yes\n",
       "4      rainy           68        80  False  yes\n",
       "5      rainy           65        70   True   no\n",
       "6   overcast           64        65   True  yes\n",
       "7      sunny           72        95  False   no\n",
       "8      sunny           69        70  False  yes\n",
       "9      rainy           75        80  False  yes\n",
       "10     sunny           75        70   True  yes\n",
       "11  overcast           72        90   True  yes\n",
       "12  overcast           81        75  False  yes\n",
       "13     rainy           71        91   True   no"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('dataset/weather.csv')\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat data latih terdiri dari data numerik dan data kategorikal. Diperlukan preprocessing dengan kakas scikit-learn yaitu LabelEncoder sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "weather_df['outlook'] = label_encoder.fit_transform(weather_df.outlook)\n",
    "weather_df['windy'] = label_encoder.fit_transform(weather_df.windy)\n",
    "weather_df['play'] = label_encoder.fit_transform(weather_df.play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0         2           85        85      0     0\n",
       "1         2           80        90      1     0\n",
       "2         0           83        86      0     1\n",
       "3         1           70        96      0     1\n",
       "4         1           68        80      0     1\n",
       "5         1           65        70      1     0\n",
       "6         0           64        65      1     1\n",
       "7         2           72        95      0     0\n",
       "8         2           69        70      0     1\n",
       "9         1           75        80      0     1\n",
       "10        2           75        70      1     1\n",
       "11        0           72        90      1     1\n",
       "12        0           81        75      0     1\n",
       "13        1           71        91      1     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1],\n",
       "       [ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weather = weather_df.iloc[:,:4].values\n",
    "X_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_weather = weather_df.play.values\n",
    "y_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian, setelah kami menjadikan data latih tersebut numerik, kami melakukan pemisahan sebagian data latih (10%) menjadi data uji dengan proporsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_weather, y_weather, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Batch = 1 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier Sendiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500 : 0.00019550323486328125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 2/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 3/500 : 0.00029349327087402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 4/500 : 0.0002949237823486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 5/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 6/500 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 7/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 8/500 : 0.0001766681671142578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 9/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 10/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 11/500 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 12/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 13/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 14/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 15/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 16/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 17/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 18/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 19/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 20/500 : 0.00016117095947265625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 21/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 22/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 23/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 24/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 25/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 26/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 27/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 28/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 29/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 30/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 31/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 32/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 33/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 34/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 35/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 36/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 37/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 38/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 39/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 40/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 41/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 42/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 43/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 44/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 45/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 46/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 47/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 48/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 49/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 50/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 51/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 52/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 53/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 54/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 55/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 56/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 57/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 58/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 59/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 60/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 61/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 62/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 63/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 64/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 65/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 66/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 67/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 68/500 : 0.0001761913299560547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 69/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 70/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 71/500 : 0.0001800060272216797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 72/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 73/500 : 0.0001914501190185547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 74/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 75/500 : 0.00018286705017089844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 76/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 77/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 78/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 79/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 80/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 81/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 82/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 83/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 84/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 85/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 86/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 87/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 88/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 89/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 90/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 91/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 92/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 93/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 94/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 95/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 97/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 98/500 : 0.0001881122589111328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 99/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 100/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 101/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 102/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 103/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 104/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 105/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 106/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 107/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 108/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 109/500 : 0.00017595291137695312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 110/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 111/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 112/500 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 113/500 : 0.0004062652587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 114/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 115/500 : 0.0001819133758544922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 116/500 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 117/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 118/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 119/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 120/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 121/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 122/500 : 0.00017690658569335938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 123/500 : 0.0001800060272216797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 124/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 125/500 : 0.0001819133758544922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 126/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 127/500 : 0.00018095970153808594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 128/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 129/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 130/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 131/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 132/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 133/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 134/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 135/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 136/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 137/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 138/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 139/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 140/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 141/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 142/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 143/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 144/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 145/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 146/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 147/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 148/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 149/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 150/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 151/500 : 0.0005393028259277344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 152/500 : 0.0003178119659423828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 153/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 154/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 155/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 156/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 157/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 158/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 159/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 160/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 161/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 162/500 : 0.00017118453979492188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 163/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 164/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 165/500 : 0.0001780986785888672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 166/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 167/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 168/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 169/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 170/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 171/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 172/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 173/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 174/500 : 0.00018167495727539062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 175/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 176/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 177/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 178/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 179/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 180/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 181/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 182/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 183/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 184/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 185/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 186/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 187/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 188/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 189/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 190/500 : 0.00017762184143066406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 191/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 192/500 : 0.00017690658569335938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 193/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 195/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 196/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 197/500 : 0.00018143653869628906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 198/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 199/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 200/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 201/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 202/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 203/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 204/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 205/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 206/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 207/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 208/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 209/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 210/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 211/500 : 0.00018405914306640625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 212/500 : 0.00019931793212890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 213/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 214/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 215/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 216/500 : 0.00018143653869628906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 217/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 218/500 : 0.00017595291137695312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 219/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 220/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 221/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 222/500 : 0.0002834796905517578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 223/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 224/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 225/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 226/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 227/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 228/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 229/500 : 0.0003147125244140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 230/500 : 0.00018787384033203125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 231/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 232/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 233/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 234/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 235/500 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 236/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 237/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 238/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 239/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 240/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 241/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 242/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 243/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 244/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 245/500 : 0.0001780986785888672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 246/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 247/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 248/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 249/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 250/500 : 0.0001704692840576172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 251/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 252/500 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 253/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 254/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 255/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 256/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 257/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 258/500 : 0.00018072128295898438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 259/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 260/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 261/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 262/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 263/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 264/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 265/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 266/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 267/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 268/500 : 0.0001709461212158203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 269/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 270/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 271/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 272/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 273/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 274/500 : 0.00017070770263671875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 275/500 : 0.00016999244689941406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 276/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 277/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 278/500 : 0.00017070770263671875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 279/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 280/500 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 281/500 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 282/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 283/500 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 284/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 285/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 286/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 287/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 288/500 : 0.00017118453979492188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 289/500 : 0.0002028942108154297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 290/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 292/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 293/500 : 0.00020575523376464844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 294/500 : 0.0002727508544921875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 295/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 296/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 297/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 298/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 299/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 300/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 301/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 302/500 : 0.00018072128295898438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 303/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 304/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 305/500 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 306/500 : 0.00018477439880371094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 307/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 308/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 309/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 310/500 : 0.0001838207244873047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 311/500 : 0.000171661376953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 312/500 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 313/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 314/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 315/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 316/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 317/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 318/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 319/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 320/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 321/500 : 0.00017118453979492188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 322/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 323/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 324/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 325/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 326/500 : 0.00035071372985839844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 327/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 328/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 329/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 330/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 331/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 332/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 333/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 334/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 335/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 336/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 337/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 338/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 339/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 340/500 : 0.00015234947204589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 341/500 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 342/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 343/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 344/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 345/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 346/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 347/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 348/500 : 0.00018644332885742188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 349/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 350/500 : 0.00017833709716796875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 351/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 352/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 353/500 : 0.0001800060272216797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 354/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 355/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 356/500 : 0.00017762184143066406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 357/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 358/500 : 0.00032448768615722656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 359/500 : 0.0001647472381591797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 360/500 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 361/500 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 362/500 : 0.0002791881561279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 363/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 364/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 365/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 366/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 367/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 368/500 : 0.0001823902130126953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 369/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 370/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 371/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 372/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 373/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 374/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 375/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 376/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 377/500 : 0.00018310546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 378/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 379/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 380/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 381/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 382/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 383/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 384/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 385/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500 : 0.0001881122589111328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 387/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 388/500 : 0.0001952648162841797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 389/500 : 0.0001811981201171875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 390/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 391/500 : 0.00018405914306640625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 392/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 393/500 : 0.00017762184143066406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 394/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 395/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 396/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 397/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 398/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 399/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 400/500 : 0.00017595291137695312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 401/500 : 0.0002219676971435547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 402/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 403/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 404/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 405/500 : 0.00017690658569335938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 406/500 : 0.0001747608184814453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 407/500 : 0.0008232593536376953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 408/500 : 0.0001621246337890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 409/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 410/500 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 411/500 : 0.000152587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 412/500 : 0.0001773834228515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 413/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 414/500 : 0.00017213821411132812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 415/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 416/500 : 0.00017714500427246094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 417/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 418/500 : 0.00018787384033203125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 419/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 420/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 421/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 422/500 : 0.00017571449279785156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 423/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 424/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 425/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 426/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 427/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 428/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 429/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 430/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 431/500 : 0.00036716461181640625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 432/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 433/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 434/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 435/500 : 0.00018358230590820312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 436/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 437/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 438/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 439/500 : 0.0001766681671142578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 440/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 441/500 : 0.0002751350402832031 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 442/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 443/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 444/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 445/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 446/500 : 0.00031566619873046875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 447/500 : 0.00015306472778320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 448/500 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 449/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 450/500 : 0.00015401840209960938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 451/500 : 0.00022411346435546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 452/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 453/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 454/500 : 0.0002455711364746094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 455/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 456/500 : 0.0001995563507080078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 457/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 458/500 : 0.0001544952392578125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 459/500 : 0.00015354156494140625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 460/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 461/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 462/500 : 0.0001621246337890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 463/500 : 0.00017714500427246094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 464/500 : 0.00017547607421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 465/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 466/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 467/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 468/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 469/500 : 0.00017309188842773438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 470/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 471/500 : 0.00021123886108398438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 472/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 473/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 474/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 475/500 : 0.0001761913299560547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 476/500 : 0.00017499923706054688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 477/500 : 0.00017452239990234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 478/500 : 0.0001544952392578125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 479/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 480/500 : 0.0001995563507080078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500 : 0.00017976760864257812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 482/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 483/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 484/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 485/500 : 0.00025272369384765625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 486/500 : 0.00017404556274414062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 487/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 488/500 : 0.00018405914306640625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 489/500 : 0.00017523765563964844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 490/500 : 0.00017189979553222656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 491/500 : 0.0001735687255859375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 492/500 : 0.0001723766326904297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 493/500 : 0.00017380714416503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 494/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 495/500 : 0.00017642974853515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 496/500 : 0.0001876354217529297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 497/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 498/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 499/500 : 0.00017333030700683594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 500/500 : 0.0001728534698486328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "neural_network1 = Network([4, 2, 3, 4, 1])\n",
    "neural_network1.fit(train_data, 500, 1, 0.1, momentum=0.0001, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network1.history['acc'])\n",
    "plt.plot(neural_network1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network1.history['loss'])\n",
    "plt.plot(neural_network1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 25.797724723815918 %\n",
      "Accuracy 50.0 %\n",
      "Time: 2.127739191055298 s\n"
     ]
    }
   ],
   "source": [
    "score1_CC = neural_network1.evaluate(test_data)\n",
    "\n",
    "print(\"Loss: {} %\".format(score2[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score2[1]*100.0))\n",
    "print(\"Time: {} s\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model keras untuk eksperimen pertama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential([\n",
    "    Dense(1, input_shape=(4,)),\n",
    "    Dense(2, activation='sigmoid'),\n",
    "    Dense(3, activation='sigmoid'),\n",
    "    Dense(4, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2625 - acc: 0.4000 - val_loss: 0.2989 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2611 - acc: 0.4000 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2604 - acc: 0.4000 - val_loss: 0.2930 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2598 - acc: 0.4000 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2587 - acc: 0.4000 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2583 - acc: 0.4000 - val_loss: 0.2820 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2571 - acc: 0.4000 - val_loss: 0.2794 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2565 - acc: 0.4000 - val_loss: 0.2766 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 931us/step - loss: 0.2557 - acc: 0.4000 - val_loss: 0.2744 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2552 - acc: 0.4000 - val_loss: 0.2713 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2546 - acc: 0.4000 - val_loss: 0.2684 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2537 - acc: 0.4000 - val_loss: 0.2669 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2534 - acc: 0.4000 - val_loss: 0.2639 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2527 - acc: 0.4000 - val_loss: 0.2615 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2522 - acc: 0.4000 - val_loss: 0.2593 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2517 - acc: 0.4000 - val_loss: 0.2574 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2514 - acc: 0.4000 - val_loss: 0.2544 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 962us/step - loss: 0.2507 - acc: 0.4000 - val_loss: 0.2522 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2504 - acc: 0.4000 - val_loss: 0.2496 - val_acc: 1.0000\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2498 - acc: 0.6000 - val_loss: 0.2478 - val_acc: 1.0000\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2494 - acc: 0.6000 - val_loss: 0.2461 - val_acc: 1.0000\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2493 - acc: 0.6000 - val_loss: 0.2431 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2486 - acc: 0.6000 - val_loss: 0.2425 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - acc: 0.6000 - val_loss: 0.2412 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - acc: 0.6000 - val_loss: 0.2378 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2476 - acc: 0.6000 - val_loss: 0.2361 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - acc: 0.6000 - val_loss: 0.2338 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2472 - acc: 0.6000 - val_loss: 0.2317 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2467 - acc: 0.6000 - val_loss: 0.2301 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2463 - acc: 0.6000 - val_loss: 0.2293 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2464 - acc: 0.6000 - val_loss: 0.2271 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2262 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2240 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2231 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2452 - acc: 0.6000 - val_loss: 0.2215 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - acc: 0.6000 - val_loss: 0.2200 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2447 - acc: 0.6000 - val_loss: 0.2189 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2175 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2155 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2148 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2133 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2126 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2437 - acc: 0.6000 - val_loss: 0.2112 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2106 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2094 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2081 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2065 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2046 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2038 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2026 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2013 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2005 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.1997 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1995 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1988 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.1968 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1963 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1961 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1954 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1934 - val_acc: 1.0000\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1920 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1913 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1906 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1904 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1894 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1879 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1882 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1876 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1864 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1850 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1859 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1828 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1825 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1827 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1823 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1821 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1801 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1804 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1794 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1795 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1778 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1780 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1766 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1749 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1738 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1738 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1730 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1735 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1715 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1715 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 950us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 963us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 964us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 947us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 927us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3594 - acc: 0.0000e+0 - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 962us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 946us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1585 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 936us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 962us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 490/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history1 = network1.fit(X_train, y_train, epochs=500, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 850us/step\n",
      "Loss: 25.985997915267944 %\n",
      "Accuracy 50.0 %\n",
      "Time: 7.62460470199585 s\n"
     ]
    }
   ],
   "source": [
    "score1 = network1.evaluate(X_test, y_test, batch_size=1)\n",
    "\n",
    "print(\"Loss: {} %\".format(score1[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score1[1]*100.0))\n",
    "print(\"Time: {} s\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Batch Size = Jumlah Data Latih</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier Sendiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model keras untuk eksperimen kedua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Sequential([\n",
    "    Dense(1, input_shape=(4,)),\n",
    "    Dense(2, activation='sigmoid'),\n",
    "    Dense(3, activation='sigmoid'),\n",
    "    Dense(4, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3240 - acc: 0.4000 - val_loss: 0.4744 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 258us/step - loss: 0.3234 - acc: 0.4000 - val_loss: 0.4730 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.3228 - acc: 0.4000 - val_loss: 0.4716 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.3222 - acc: 0.4000 - val_loss: 0.4703 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.3217 - acc: 0.4000 - val_loss: 0.4689 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.3211 - acc: 0.4000 - val_loss: 0.4675 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.3205 - acc: 0.4000 - val_loss: 0.4661 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.3199 - acc: 0.4000 - val_loss: 0.4647 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.3194 - acc: 0.4000 - val_loss: 0.4633 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.3188 - acc: 0.4000 - val_loss: 0.4619 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 419us/step - loss: 0.3182 - acc: 0.4000 - val_loss: 0.4605 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.3176 - acc: 0.4000 - val_loss: 0.4591 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.3171 - acc: 0.4000 - val_loss: 0.4577 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.3165 - acc: 0.4000 - val_loss: 0.4563 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.3159 - acc: 0.4000 - val_loss: 0.4549 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 382us/step - loss: 0.3153 - acc: 0.4000 - val_loss: 0.4536 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 320us/step - loss: 0.3148 - acc: 0.4000 - val_loss: 0.4522 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.3142 - acc: 0.4000 - val_loss: 0.4508 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.3137 - acc: 0.4000 - val_loss: 0.4494 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.3131 - acc: 0.4000 - val_loss: 0.4480 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.3125 - acc: 0.4000 - val_loss: 0.4466 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.3120 - acc: 0.4000 - val_loss: 0.4452 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 386us/step - loss: 0.3114 - acc: 0.4000 - val_loss: 0.4438 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 253us/step - loss: 0.3109 - acc: 0.4000 - val_loss: 0.4425 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.3103 - acc: 0.4000 - val_loss: 0.4411 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.3098 - acc: 0.4000 - val_loss: 0.4397 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.3092 - acc: 0.4000 - val_loss: 0.4383 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.3087 - acc: 0.4000 - val_loss: 0.4370 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.3081 - acc: 0.4000 - val_loss: 0.4356 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.3076 - acc: 0.4000 - val_loss: 0.4342 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.3071 - acc: 0.4000 - val_loss: 0.4329 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 269us/step - loss: 0.3065 - acc: 0.4000 - val_loss: 0.4315 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.3060 - acc: 0.4000 - val_loss: 0.4302 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.3055 - acc: 0.4000 - val_loss: 0.4288 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 289us/step - loss: 0.3049 - acc: 0.4000 - val_loss: 0.4275 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.3044 - acc: 0.4000 - val_loss: 0.4261 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.3039 - acc: 0.4000 - val_loss: 0.4247 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.3034 - acc: 0.4000 - val_loss: 0.4234 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.3029 - acc: 0.4000 - val_loss: 0.4221 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3023 - acc: 0.4000 - val_loss: 0.4207 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.3018 - acc: 0.4000 - val_loss: 0.4194 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.3013 - acc: 0.4000 - val_loss: 0.4181 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.3008 - acc: 0.4000 - val_loss: 0.4167 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.3003 - acc: 0.4000 - val_loss: 0.4154 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2998 - acc: 0.4000 - val_loss: 0.4141 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2993 - acc: 0.4000 - val_loss: 0.4128 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2988 - acc: 0.4000 - val_loss: 0.4115 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2983 - acc: 0.4000 - val_loss: 0.4102 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 406us/step - loss: 0.2978 - acc: 0.4000 - val_loss: 0.4088 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2973 - acc: 0.4000 - val_loss: 0.4075 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2968 - acc: 0.4000 - val_loss: 0.4062 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2963 - acc: 0.4000 - val_loss: 0.4049 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2959 - acc: 0.4000 - val_loss: 0.4036 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 265us/step - loss: 0.2954 - acc: 0.4000 - val_loss: 0.4023 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2949 - acc: 0.4000 - val_loss: 0.4011 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2944 - acc: 0.4000 - val_loss: 0.3998 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2940 - acc: 0.4000 - val_loss: 0.3985 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2935 - acc: 0.4000 - val_loss: 0.3972 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2930 - acc: 0.4000 - val_loss: 0.3960 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2926 - acc: 0.4000 - val_loss: 0.3947 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2921 - acc: 0.4000 - val_loss: 0.3934 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2916 - acc: 0.4000 - val_loss: 0.3921 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2912 - acc: 0.4000 - val_loss: 0.3909 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2907 - acc: 0.4000 - val_loss: 0.3896 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2903 - acc: 0.4000 - val_loss: 0.3884 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 327us/step - loss: 0.2898 - acc: 0.4000 - val_loss: 0.3871 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2894 - acc: 0.4000 - val_loss: 0.3859 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2889 - acc: 0.4000 - val_loss: 0.3846 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2885 - acc: 0.4000 - val_loss: 0.3834 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2880 - acc: 0.4000 - val_loss: 0.3822 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2876 - acc: 0.4000 - val_loss: 0.3809 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2872 - acc: 0.4000 - val_loss: 0.3797 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2867 - acc: 0.4000 - val_loss: 0.3785 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2863 - acc: 0.4000 - val_loss: 0.3773 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2859 - acc: 0.4000 - val_loss: 0.3760 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2855 - acc: 0.4000 - val_loss: 0.3748 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2850 - acc: 0.4000 - val_loss: 0.3736 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2846 - acc: 0.4000 - val_loss: 0.3724 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 284us/step - loss: 0.2842 - acc: 0.4000 - val_loss: 0.3712 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2838 - acc: 0.4000 - val_loss: 0.3700 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2834 - acc: 0.4000 - val_loss: 0.3688 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.2830 - acc: 0.4000 - val_loss: 0.3677 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2826 - acc: 0.4000 - val_loss: 0.3665 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 271us/step - loss: 0.2822 - acc: 0.4000 - val_loss: 0.3653 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2818 - acc: 0.4000 - val_loss: 0.3641 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2814 - acc: 0.4000 - val_loss: 0.3630 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2810 - acc: 0.4000 - val_loss: 0.3618 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2806 - acc: 0.4000 - val_loss: 0.3606 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2802 - acc: 0.4000 - val_loss: 0.3595 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 132us/step - loss: 0.2798 - acc: 0.4000 - val_loss: 0.3583 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 304us/step - loss: 0.2794 - acc: 0.4000 - val_loss: 0.3572 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 296us/step - loss: 0.2791 - acc: 0.4000 - val_loss: 0.3560 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2787 - acc: 0.4000 - val_loss: 0.3549 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 474us/step - loss: 0.2783 - acc: 0.4000 - val_loss: 0.3538 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 288us/step - loss: 0.2779 - acc: 0.4000 - val_loss: 0.3526 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2776 - acc: 0.4000 - val_loss: 0.3515 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2772 - acc: 0.4000 - val_loss: 0.3504 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2768 - acc: 0.4000 - val_loss: 0.3493 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2765 - acc: 0.4000 - val_loss: 0.3482 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2761 - acc: 0.4000 - val_loss: 0.3471 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2758 - acc: 0.4000 - val_loss: 0.3460 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2754 - acc: 0.4000 - val_loss: 0.3449 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2751 - acc: 0.4000 - val_loss: 0.3438 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2747 - acc: 0.4000 - val_loss: 0.3427 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2744 - acc: 0.4000 - val_loss: 0.3416 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2740 - acc: 0.4000 - val_loss: 0.3405 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2737 - acc: 0.4000 - val_loss: 0.3394 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2733 - acc: 0.4000 - val_loss: 0.3383 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2730 - acc: 0.4000 - val_loss: 0.3373 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2727 - acc: 0.4000 - val_loss: 0.3362 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2723 - acc: 0.4000 - val_loss: 0.3351 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2720 - acc: 0.4000 - val_loss: 0.3341 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2717 - acc: 0.4000 - val_loss: 0.3330 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2714 - acc: 0.4000 - val_loss: 0.3320 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2710 - acc: 0.4000 - val_loss: 0.3310 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2707 - acc: 0.4000 - val_loss: 0.3299 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2704 - acc: 0.4000 - val_loss: 0.3289 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2701 - acc: 0.4000 - val_loss: 0.3278 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2698 - acc: 0.4000 - val_loss: 0.3268 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2695 - acc: 0.4000 - val_loss: 0.3258 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2692 - acc: 0.4000 - val_loss: 0.3248 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 258us/step - loss: 0.2689 - acc: 0.4000 - val_loss: 0.3238 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2686 - acc: 0.4000 - val_loss: 0.3228 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2683 - acc: 0.4000 - val_loss: 0.3218 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2680 - acc: 0.4000 - val_loss: 0.3208 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2677 - acc: 0.4000 - val_loss: 0.3198 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2674 - acc: 0.4000 - val_loss: 0.3188 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2671 - acc: 0.4000 - val_loss: 0.3178 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2668 - acc: 0.4000 - val_loss: 0.3168 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2665 - acc: 0.4000 - val_loss: 0.3158 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2662 - acc: 0.4000 - val_loss: 0.3149 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2660 - acc: 0.4000 - val_loss: 0.3139 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2657 - acc: 0.4000 - val_loss: 0.3129 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2654 - acc: 0.4000 - val_loss: 0.3120 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 127us/step - loss: 0.2651 - acc: 0.4000 - val_loss: 0.3110 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2649 - acc: 0.4000 - val_loss: 0.3101 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2646 - acc: 0.4000 - val_loss: 0.3091 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2643 - acc: 0.4000 - val_loss: 0.3082 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2641 - acc: 0.4000 - val_loss: 0.3073 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2638 - acc: 0.4000 - val_loss: 0.3063 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2636 - acc: 0.4000 - val_loss: 0.3054 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2633 - acc: 0.4000 - val_loss: 0.3045 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2630 - acc: 0.4000 - val_loss: 0.3036 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2628 - acc: 0.4000 - val_loss: 0.3027 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2625 - acc: 0.4000 - val_loss: 0.3017 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2623 - acc: 0.4000 - val_loss: 0.3008 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2620 - acc: 0.4000 - val_loss: 0.2999 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2618 - acc: 0.4000 - val_loss: 0.2991 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2616 - acc: 0.4000 - val_loss: 0.2982 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2613 - acc: 0.4000 - val_loss: 0.2973 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2611 - acc: 0.4000 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2609 - acc: 0.4000 - val_loss: 0.2955 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2606 - acc: 0.4000 - val_loss: 0.2946 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2604 - acc: 0.4000 - val_loss: 0.2938 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2602 - acc: 0.4000 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 135us/step - loss: 0.2599 - acc: 0.4000 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 295us/step - loss: 0.2597 - acc: 0.4000 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2595 - acc: 0.4000 - val_loss: 0.2903 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2593 - acc: 0.4000 - val_loss: 0.2895 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 135us/step - loss: 0.2591 - acc: 0.4000 - val_loss: 0.2886 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2588 - acc: 0.4000 - val_loss: 0.2878 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2586 - acc: 0.4000 - val_loss: 0.2870 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2584 - acc: 0.4000 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2582 - acc: 0.4000 - val_loss: 0.2853 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2580 - acc: 0.4000 - val_loss: 0.2845 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2578 - acc: 0.4000 - val_loss: 0.2837 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2576 - acc: 0.4000 - val_loss: 0.2829 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2574 - acc: 0.4000 - val_loss: 0.2821 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2572 - acc: 0.4000 - val_loss: 0.2813 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2570 - acc: 0.4000 - val_loss: 0.2805 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2568 - acc: 0.4000 - val_loss: 0.2797 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2566 - acc: 0.4000 - val_loss: 0.2789 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2564 - acc: 0.4000 - val_loss: 0.2781 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2562 - acc: 0.4000 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2560 - acc: 0.4000 - val_loss: 0.2765 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2558 - acc: 0.4000 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2557 - acc: 0.4000 - val_loss: 0.2750 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2555 - acc: 0.4000 - val_loss: 0.2742 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2553 - acc: 0.4000 - val_loss: 0.2735 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2551 - acc: 0.4000 - val_loss: 0.2727 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2549 - acc: 0.4000 - val_loss: 0.2719 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2548 - acc: 0.4000 - val_loss: 0.2712 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2546 - acc: 0.4000 - val_loss: 0.2704 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2544 - acc: 0.4000 - val_loss: 0.2697 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2542 - acc: 0.4000 - val_loss: 0.2690 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2541 - acc: 0.4000 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2539 - acc: 0.4000 - val_loss: 0.2675 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 351us/step - loss: 0.2537 - acc: 0.4000 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 337us/step - loss: 0.2536 - acc: 0.4000 - val_loss: 0.2660 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2534 - acc: 0.4000 - val_loss: 0.2653 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2532 - acc: 0.4000 - val_loss: 0.2646 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2531 - acc: 0.4000 - val_loss: 0.2639 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2529 - acc: 0.4000 - val_loss: 0.2632 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2528 - acc: 0.4000 - val_loss: 0.2625 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2526 - acc: 0.4000 - val_loss: 0.2618 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2525 - acc: 0.4000 - val_loss: 0.2611 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 413us/step - loss: 0.2523 - acc: 0.4000 - val_loss: 0.2604 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2522 - acc: 0.4000 - val_loss: 0.2597 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2520 - acc: 0.4000 - val_loss: 0.2590 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2519 - acc: 0.4000 - val_loss: 0.2584 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2517 - acc: 0.4000 - val_loss: 0.2577 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2516 - acc: 0.4000 - val_loss: 0.2570 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2514 - acc: 0.4000 - val_loss: 0.2564 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2513 - acc: 0.4000 - val_loss: 0.2557 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 750us/step - loss: 0.2512 - acc: 0.4000 - val_loss: 0.2550 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2510 - acc: 0.4000 - val_loss: 0.2544 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2509 - acc: 0.4000 - val_loss: 0.2537 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2508 - acc: 0.4000 - val_loss: 0.2531 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 351us/step - loss: 0.2506 - acc: 0.4000 - val_loss: 0.2524 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 319us/step - loss: 0.2505 - acc: 0.4000 - val_loss: 0.2518 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2504 - acc: 0.4000 - val_loss: 0.2512 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2502 - acc: 0.4000 - val_loss: 0.2505 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2501 - acc: 0.4000 - val_loss: 0.2499 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2500 - acc: 0.6000 - val_loss: 0.2493 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2499 - acc: 0.6000 - val_loss: 0.2486 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2497 - acc: 0.6000 - val_loss: 0.2480 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2496 - acc: 0.6000 - val_loss: 0.2474 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 246us/step - loss: 0.2495 - acc: 0.6000 - val_loss: 0.2468 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2494 - acc: 0.6000 - val_loss: 0.2462 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2492 - acc: 0.6000 - val_loss: 0.2456 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 648us/step - loss: 0.2491 - acc: 0.6000 - val_loss: 0.2450 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 350us/step - loss: 0.2490 - acc: 0.6000 - val_loss: 0.2444 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 255us/step - loss: 0.2489 - acc: 0.6000 - val_loss: 0.2438 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2488 - acc: 0.6000 - val_loss: 0.2432 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2487 - acc: 0.6000 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2486 - acc: 0.6000 - val_loss: 0.2420 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2485 - acc: 0.6000 - val_loss: 0.2415 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2483 - acc: 0.6000 - val_loss: 0.2409 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2482 - acc: 0.6000 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2481 - acc: 0.6000 - val_loss: 0.2397 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2480 - acc: 0.6000 - val_loss: 0.2392 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2479 - acc: 0.6000 - val_loss: 0.2386 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2478 - acc: 0.6000 - val_loss: 0.2380 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 421us/step - loss: 0.2477 - acc: 0.6000 - val_loss: 0.2375 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 292us/step - loss: 0.2476 - acc: 0.6000 - val_loss: 0.2369 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2475 - acc: 0.6000 - val_loss: 0.2364 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2474 - acc: 0.6000 - val_loss: 0.2358 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2473 - acc: 0.6000 - val_loss: 0.2353 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.2472 - acc: 0.6000 - val_loss: 0.2348 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2471 - acc: 0.6000 - val_loss: 0.2342 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2471 - acc: 0.6000 - val_loss: 0.2337 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2470 - acc: 0.6000 - val_loss: 0.2332 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2469 - acc: 0.6000 - val_loss: 0.2326 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2468 - acc: 0.6000 - val_loss: 0.2321 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2467 - acc: 0.6000 - val_loss: 0.2316 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2466 - acc: 0.6000 - val_loss: 0.2311 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2465 - acc: 0.6000 - val_loss: 0.2306 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2464 - acc: 0.6000 - val_loss: 0.2301 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 658us/step - loss: 0.2463 - acc: 0.6000 - val_loss: 0.2295 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2463 - acc: 0.6000 - val_loss: 0.2290 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2462 - acc: 0.6000 - val_loss: 0.2285 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2461 - acc: 0.6000 - val_loss: 0.2280 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2460 - acc: 0.6000 - val_loss: 0.2275 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2459 - acc: 0.6000 - val_loss: 0.2271 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2459 - acc: 0.6000 - val_loss: 0.2266 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2261 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2457 - acc: 0.6000 - val_loss: 0.2256 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2456 - acc: 0.6000 - val_loss: 0.2251 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2455 - acc: 0.6000 - val_loss: 0.2246 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2455 - acc: 0.6000 - val_loss: 0.2242 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2454 - acc: 0.6000 - val_loss: 0.2237 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 577us/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2232 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 292us/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2228 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2452 - acc: 0.6000 - val_loss: 0.2223 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2451 - acc: 0.6000 - val_loss: 0.2219 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2450 - acc: 0.6000 - val_loss: 0.2214 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2450 - acc: 0.6000 - val_loss: 0.2209 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2449 - acc: 0.6000 - val_loss: 0.2205 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2200 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2196 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2447 - acc: 0.6000 - val_loss: 0.2192 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 548us/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2187 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 303us/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2183 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2445 - acc: 0.6000 - val_loss: 0.2179 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2445 - acc: 0.6000 - val_loss: 0.2174 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2170 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2443 - acc: 0.6000 - val_loss: 0.2166 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2443 - acc: 0.6000 - val_loss: 0.2161 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2157 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 335us/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2153 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2149 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2145 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2141 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2137 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2133 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2438 - acc: 0.6000 - val_loss: 0.2129 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2438 - acc: 0.6000 - val_loss: 0.2125 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2437 - acc: 0.6000 - val_loss: 0.2121 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2437 - acc: 0.6000 - val_loss: 0.2117 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 278us/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2113 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2109 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2105 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2101 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2098 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2094 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2090 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2086 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2083 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2079 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.2075 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 132us/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.2072 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2068 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2064 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2061 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2057 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 263us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2050 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2047 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 477us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2044 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2040 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2037 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2033 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2027 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2023 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2020 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2017 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2014 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 231us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2010 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2007 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2004 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2001 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1998 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1995 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1988 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1985 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1982 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1979 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1976 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 278us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1973 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1971 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1968 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1965 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1959 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1956 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1948 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 244us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1945 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1942 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1939 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1934 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1931 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1929 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1924 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1921 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 298us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1916 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1913 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1911 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1908 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1906 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1903 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 341us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1901 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1898 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1896 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1894 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1891 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1889 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1884 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1882 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1880 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1877 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1875 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1873 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1870 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1868 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1866 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1864 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1857 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1855 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 264us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1853 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1849 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1847 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 264us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1841 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1839 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1837 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1835 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1833 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1829 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1827 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1825 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1823 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1821 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1820 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1818 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1816 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1814 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1812 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1810 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1809 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1807 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1805 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1803 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1802 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1800 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1795 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1793 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1792 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1790 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1788 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 273us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1785 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1782 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1780 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1779 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1777 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1776 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1773 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1765 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 317us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1762 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1761 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1757 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1754 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1753 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1751 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 280us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1749 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1747 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1745 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 391us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1744 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 257us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1741 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1738 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1736 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1735 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 267us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1732 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1731 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1730 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 352us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1724 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1721 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1719 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1715 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 282us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1710 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1705 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = network2.fit(X_train, y_train, epochs=500, verbose=1, batch_size=len(X_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 269us/step\n",
      "Loss: 25.797724723815918 %\n",
      "Accuracy 50.0 %\n",
      "Time: 2.127739191055298 s\n"
     ]
    }
   ],
   "source": [
    "score2 = network2.evaluate(X_test, y_test, batch_size=len(X_train))\n",
    "\n",
    "print(\"Loss: {} %\".format(score2[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score2[1]*100.0))\n",
    "print(\"Time: {} s\".format(end))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

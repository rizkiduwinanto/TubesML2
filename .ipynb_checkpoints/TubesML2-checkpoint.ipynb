{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar Pembelajaran Mesin 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persiapan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal pertama yang kami lakukan adalah menggunakan data latih Weather Categorization dari WEKA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temperature  humidity  windy play\n",
       "0      sunny           85        85  False   no\n",
       "1      sunny           80        90   True   no\n",
       "2   overcast           83        86  False  yes\n",
       "3      rainy           70        96  False  yes\n",
       "4      rainy           68        80  False  yes\n",
       "5      rainy           65        70   True   no\n",
       "6   overcast           64        65   True  yes\n",
       "7      sunny           72        95  False   no\n",
       "8      sunny           69        70  False  yes\n",
       "9      rainy           75        80  False  yes\n",
       "10     sunny           75        70   True  yes\n",
       "11  overcast           72        90   True  yes\n",
       "12  overcast           81        75  False  yes\n",
       "13     rainy           71        91   True   no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('dataset/weather.csv')\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat data latih terdiri dari data numerik dan data kategorikal. Diperlukan preprocessing dengan kakas scikit-learn yaitu LabelEncoder sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "weather_df['outlook'] = label_encoder.fit_transform(weather_df.outlook)\n",
    "weather_df['windy'] = label_encoder.fit_transform(weather_df.windy)\n",
    "weather_df['play'] = label_encoder.fit_transform(weather_df.play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0         2           85        85      0     0\n",
       "1         2           80        90      1     0\n",
       "2         0           83        86      0     1\n",
       "3         1           70        96      0     1\n",
       "4         1           68        80      0     1\n",
       "5         1           65        70      1     0\n",
       "6         0           64        65      1     1\n",
       "7         2           72        95      0     0\n",
       "8         2           69        70      0     1\n",
       "9         1           75        80      0     1\n",
       "10        2           75        70      1     1\n",
       "11        0           72        90      1     1\n",
       "12        0           81        75      0     1\n",
       "13        1           71        91      1     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1],\n",
       "       [ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weather = weather_df.iloc[:,:4].values\n",
    "X_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_weather = weather_df.play.values\n",
    "y_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian, setelah kami menjadikan data latih tersebut numerik, kami melakukan pemisahan sebagian data latih (10%) menjadi data uji dengan proporsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_weather, y_weather, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorasi Keras (1.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembelajaran akan menggunakan kakas keras dengan model <i>sequential</i> dan lapisan <i>dense</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan memakai input layer sebanyak 1 neuron dengan bentuk input 4 sesuai jumlah attribute data latih, kemudian dengan 3 hidden layer masing-masing 2 neuron kemudian 3 neuron, dan 4 neuron dan 1 output layer dengan 1 neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential()\n",
    "network1.add(Dense(1, activation='sigmoid', input_shape=(4,)))\n",
    "network1.add(Dense(2, activation='sigmoid'))\n",
    "network1.add(Dense(3, activation='sigmoid'))\n",
    "network1.add(Dense(4, activation='sigmoid'))\n",
    "network1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer yang dipakai adalah Adam (Adaptive Moment Estimation), dengan perhitungan loss dengan Mean Squared Error, dan Metrics Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah summary dari model yang akan dipakai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah eksperimen yang dilakukan dengan batch = 1 dan sesuai jumlah data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Batch = 1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2647 - acc: 0.4000 - val_loss: 0.3062 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.4000 - val_loss: 0.3021 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2622 - acc: 0.4000 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2613 - acc: 0.4000 - val_loss: 0.2971 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2606 - acc: 0.4000 - val_loss: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2600 - acc: 0.4000 - val_loss: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2593 - acc: 0.4000 - val_loss: 0.2875 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2589 - acc: 0.4000 - val_loss: 0.2833 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2575 - acc: 0.4000 - val_loss: 0.2825 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2569 - acc: 0.4000 - val_loss: 0.2795 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2565 - acc: 0.4000 - val_loss: 0.2760 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2556 - acc: 0.4000 - val_loss: 0.2733 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2549 - acc: 0.4000 - val_loss: 0.2707 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2543 - acc: 0.4000 - val_loss: 0.2682 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2536 - acc: 0.4000 - val_loss: 0.2665 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2537 - acc: 0.4000 - val_loss: 0.2629 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2526 - acc: 0.4000 - val_loss: 0.2608 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2522 - acc: 0.4000 - val_loss: 0.2583 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2516 - acc: 0.4000 - val_loss: 0.2563 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2515 - acc: 0.4000 - val_loss: 0.2533 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2505 - acc: 0.4000 - val_loss: 0.2519 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2503 - acc: 0.4000 - val_loss: 0.2494 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2498 - acc: 0.6000 - val_loss: 0.2478 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2494 - acc: 0.6000 - val_loss: 0.2464 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2495 - acc: 0.6000 - val_loss: 0.2431 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2487 - acc: 0.6000 - val_loss: 0.2412 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2484 - acc: 0.6000 - val_loss: 0.2388 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - acc: 0.6000 - val_loss: 0.2382 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2481 - acc: 0.6000 - val_loss: 0.2353 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2473 - acc: 0.6000 - val_loss: 0.2340 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2470 - acc: 0.6000 - val_loss: 0.2322 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - acc: 0.6000 - val_loss: 0.2301 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2466 - acc: 0.6000 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.6000 - val_loss: 0.2263 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2254 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2235 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2231 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2451 - acc: 0.6000 - val_loss: 0.2217 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2450 - acc: 0.6000 - val_loss: 0.2200 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2183 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2168 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2167 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - acc: 0.6000 - val_loss: 0.2161 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2136 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2124 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2101 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2091 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2082 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2068 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2064 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2055 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2039 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2035 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2018 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2002 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.1987 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1984 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1971 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 958us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1957 - val_acc: 1.0000\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1955 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1942 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1934 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1924 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1917 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1912 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1904 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1892 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1887 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1891 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1875 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1855 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1854 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1835 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1834 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1826 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1835 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1818 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1822 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1804 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1802 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1800 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1793 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1788 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1772 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1765 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1763 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1753 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1751 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1736 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1739 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1733 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 968us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1682 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 937us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 923us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 923us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 913us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 956us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 941us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 963us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 933us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 901us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 949us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 971us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 949us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 929us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 490/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 927us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 902us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 892us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 911us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 906us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 890us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history1 = network1.fit(X_train, y_train, epochs=500, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 955us/step\n",
      "Loss: 26.022163033485413%\n",
      "Accuracy: 50.0%\n",
      "Time: 6.884313344955444 ms\n"
     ]
    }
   ],
   "source": [
    "score1 = network1.evaluate(X_test, y_test, batch_size=1)\n",
    "\n",
    "print(\"Loss: \" + str(score1[0]*100.0) + \"%\")\n",
    "print(\"Accuracy: \" + str(score1[1]*100.0) + \"%\")\n",
    "print(\"Time: \" + str(end) +\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Batch Size = Jumlah Data Latih</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model untuk eksperimen kedua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Sequential()\n",
    "network2.add(Dense(1, activation='sigmoid', input_shape=(4,)))\n",
    "network2.add(Dense(2, activation='sigmoid'))\n",
    "network2.add(Dense(3, activation='sigmoid'))\n",
    "network2.add(Dense(4, activation='sigmoid'))\n",
    "network2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.1171 - val_acc: 1.0000\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.1179 - val_acc: 1.0000\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.1185 - val_acc: 1.0000\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.1193 - val_acc: 1.0000\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.1200 - val_acc: 1.0000\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.1214 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.1222 - val_acc: 1.0000\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.1229 - val_acc: 1.0000\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 326us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.1244 - val_acc: 1.0000\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 305us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1251 - val_acc: 1.0000\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1258 - val_acc: 1.0000\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1266 - val_acc: 1.0000\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1273 - val_acc: 1.0000\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1280 - val_acc: 1.0000\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1287 - val_acc: 1.0000\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 246us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1295 - val_acc: 1.0000\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1302 - val_acc: 1.0000\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1309 - val_acc: 1.0000\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1316 - val_acc: 1.0000\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1323 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 318us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1330 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 244us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1337 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1344 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1351 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 272us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1358 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1365 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1378 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1385 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1392 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1398 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1404 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 400us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1411 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 253us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1417 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1423 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1429 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1435 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1441 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1447 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1452 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 304us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1458 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1463 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1468 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 279us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 234us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1479 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1484 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1489 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1493 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 133us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1503 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1507 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1511 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1516 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1524 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1527 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 295us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1531 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1535 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 377us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1538 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 257us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1542 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1545 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1548 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 276us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1551 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 319us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1554 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1557 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 127us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1559 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 131us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1565 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 138us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1571 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1575 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 301us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1577 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 273us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1581 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 373us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1584 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 129us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 125us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 281us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 247us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 243us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 129us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 295us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 127us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 291us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 316us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 303us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 322us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 336us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 418us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 292us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 399us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 328us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 240us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 491us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 306us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 320us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 307us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 437us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 326us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 424us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 257us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 481us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 270us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 234us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 365us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 225us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 314us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 265us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 125us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 331us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 315us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 302us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 325us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 317us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 404us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 271us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 319us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 137us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 460us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 298us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 298us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 528us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 238us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 282us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 266us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 243us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 232us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 711us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 375us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 527us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 281us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 375us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 412us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 242us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 296us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 260us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 280us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 306us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 514us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 310us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 413us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 265us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 458us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 378us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 691us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 273us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 503us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 238us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 341us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 353us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 294us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 232us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 382us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = network2.fit(X_train, y_train, epochs=500, verbose=1, batch_size=len(X_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 412us/step\n",
      "Loss: 25.999999046325684%\n",
      "Accuracy: 50.0%\n",
      "Time: 2.0241498947143555 ms\n"
     ]
    }
   ],
   "source": [
    "score2 = network2.evaluate(X_test, y_test, batch_size=len(X_train))\n",
    "\n",
    "print(\"Loss: \" + str(score2[0]*100.0) + \"%\")\n",
    "print(\"Accuracy: \" + str(score2[1]*100.0) + \"%\")\n",
    "print(\"Time: \" + str(end) +\" s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

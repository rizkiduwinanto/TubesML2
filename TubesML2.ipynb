{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar Pembelajaran Mesin 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pustaka Terkait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, metrics\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a. Create a Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deskripsi Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritma ini menghitung.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Code Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.history = d = {'acc': [], 'val_acc': [], 'loss': [], 'val_loss': []}\n",
    "    \n",
    "    def feed_forward(self, activation):\n",
    "        for bias, weight in zip(self.biases, self.weights):\n",
    "            activation = sigmoid(np.dot(weight, activation) + bias.transpose()[0])\n",
    "        return activation\n",
    "    \n",
    "    def fit(self, training_data, epochs, mini_batch_size, learning_rate,\n",
    "            momentum=0, validation_data=None, validation_split=0.0):\n",
    "        if validation_split != 0.0 and not validation_data :\n",
    "            training_data, validation_data = train_test_split(training_data, test_size=validation_split, random_state=42)\n",
    "        n_training = len(training_data)\n",
    "        if validation_data or validation_split != 0.0: \n",
    "            n_validation = len(validation_data)\n",
    "            print(\"Train on {} samples, validate on {} samples\".format(n_training, n_validation))\n",
    "        for epoch in range(epochs):\n",
    "            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n_training, mini_batch_size)]\n",
    "            previous_weights = self.weights\n",
    "            previous_biases =self.biases\n",
    "            first = True\n",
    "            for mini_batch in mini_batches:\n",
    "                if first: previous_weights, previous_biases = self.weights, self.biases\n",
    "                start = time.time()\n",
    "                previous_weights, previous_biases = self.update_mini_batch(mini_batch, \n",
    "                                                                           learning_rate,\n",
    "                                                                           momentum, \n",
    "                                                                           previous_weights, \n",
    "                                                                           previous_biases)\n",
    "                end = time.time() - start\n",
    "            if validation_data or validation_split != 0:\n",
    "                training_accuracy, training_loss = self.evaluate(mini_batches[0])\n",
    "                validation_accuracy, validation_loss = self.evaluate(validation_data)\n",
    "                self.history['acc'].append(training_accuracy)\n",
    "                self.history['val_acc'].append(validation_accuracy)\n",
    "                self.history['loss'].append(training_loss)\n",
    "                self.history['val_loss'].append(validation_loss)\n",
    "                print(\"Epoch {}/{} : {} s - loss: {} - acc: {} - val_loss: {} - val_acc: {}\".format(epoch + 1, \n",
    "                                                                                                    epochs,\n",
    "                                                                                                    end,\n",
    "                                                                                                    training_loss,\n",
    "                                                                                                    training_accuracy,\n",
    "                                                                                                    validation_loss,\n",
    "                                                                                                    validation_accuracy))\n",
    "            else :\n",
    "                print(\"Epoch {} complete.\".format(epoch + 1))\n",
    "        \n",
    "    def update_mini_batch(self, mini_batch, learning_rate, momentum, previous_weights, previous_biases):\n",
    "        nabla_biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        nabla_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_bias, delta_nabla_weights = self.backpropagation(x, y)\n",
    "            nabla_biases = [nb + dnb for nb, dnb in zip(nabla_biases, delta_nabla_bias)]\n",
    "            nabla_weights = [nw + dnw for nw, dnw in zip(nabla_weights, delta_nabla_weights)]\n",
    "        temp_weights = self.weights\n",
    "        temp_biases = self.biases\n",
    "        self.weights = [w + momentum * pw + (learning_rate/len(mini_batch)) * nw \n",
    "                        for w, nw, pw in zip(self.weights, nabla_weights, previous_weights)]\n",
    "        self.biases = [b + momentum * pb + (learning_rate/len(mini_batch)) * nb \n",
    "                       for b, nb, pb in zip(self.biases, nabla_biases, previous_biases)]\n",
    "        return (temp_weights, temp_biases)\n",
    "        \n",
    "    def backpropagation(self, x, y):\n",
    "        nabla_bias = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        nabla_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        z_vectors = []\n",
    "        \n",
    "        for bias, weight in zip(self.biases, self.weights):\n",
    "            z = np.dot(weight, activation) + bias.transpose()[0]\n",
    "            z_vectors.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(z_vectors[-1])\n",
    "        nabla_bias[-1] = delta\n",
    "        delta_newaxis = delta[:, np.newaxis]\n",
    "        m = len(activations[-2])\n",
    "        activations_newaxis = activations[-2][:, np.newaxis].reshape(1, m)\n",
    "        nabla_weights[-1] = np.dot(delta_newaxis, activations_newaxis)\n",
    "        \n",
    "        for layer in range(2, self.num_layers):\n",
    "            z = z_vectors[-layer]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-layer+1].transpose(), delta) * sp\n",
    "            nabla_bias[-layer] = delta\n",
    "            delta_newaxis = delta[:, np.newaxis]\n",
    "            m = len(activations[-layer-1].transpose())\n",
    "            activations_newaxis = activations[-layer-1].transpose()[:, np.newaxis].reshape(1, m)\n",
    "            nabla_weights[-layer] = np.dot(delta_newaxis, activations_newaxis)\n",
    "        \n",
    "        return (nabla_bias, nabla_weights)\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(1 if self.feed_forward(x) * 2 >= 1 else 0, y) for x, y in test_data]\n",
    "        accuracy = sum(int(x == y) for x, y in test_results)/len(test_results)\n",
    "        loss = sum(pow(int(y - x), 2) for x, y in test_results)/len(test_results)\n",
    "        return accuracy, loss\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        test_results = [1 if self.feed_forward(x) * 2 >= 1 else 0 for x, y in test_data]\n",
    "        return (test_results)\n",
    "    \n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return np.squeeze(y - output_activations)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percobaan pada Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/200 : 8.845329284667969e-05 s - loss: 0.0 - acc: 1.0 - val_loss: 1.6428571428571428 - val_acc: 0.21428571428571427\n",
      "Epoch 2/200 : 8.893013000488281e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 3/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 4/200 : 8.893013000488281e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 5/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 6/200 : 8.559226989746094e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 7/200 : 8.606910705566406e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 8/200 : 8.535385131835938e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 9/200 : 8.630752563476562e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 10/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 11/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 12/200 : 8.916854858398438e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 13/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 14/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 15/200 : 8.654594421386719e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 16/200 : 8.940696716308594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 17/200 : 8.893013000488281e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 18/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 19/200 : 0.0001678466796875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 20/200 : 8.893013000488281e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 21/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 22/200 : 8.916854858398438e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 23/200 : 9.274482727050781e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 24/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 25/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 26/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 27/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 28/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 29/200 : 8.845329284667969e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 30/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 31/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 32/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 33/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 34/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 35/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 36/200 : 9.942054748535156e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 37/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 38/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 39/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 40/200 : 9.202957153320312e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 41/200 : 9.1552734375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 42/200 : 9.34600830078125e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 43/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 44/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 45/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 46/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 47/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 48/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 49/200 : 9.655952453613281e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 50/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 51/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 52/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 53/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 54/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 55/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 56/200 : 0.00011372566223144531 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 57/200 : 0.00012302398681640625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 58/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 59/200 : 8.797645568847656e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 60/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 61/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 62/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 63/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 64/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 65/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 66/200 : 8.702278137207031e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 67/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 68/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 69/200 : 8.702278137207031e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 70/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 71/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 72/200 : 9.369850158691406e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 73/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 74/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 75/200 : 8.916854858398438e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 76/200 : 8.749961853027344e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 77/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 78/200 : 0.00014138221740722656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 79/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 80/200 : 0.00010037422180175781 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 81/200 : 9.1552734375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 82/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 83/200 : 9.1552734375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 84/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 85/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 86/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 87/200 : 8.940696716308594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 89/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 90/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 91/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 92/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 93/200 : 0.00019598007202148438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 94/200 : 9.870529174804688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 95/200 : 0.0001537799835205078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 96/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 97/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 98/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 99/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 100/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 101/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 102/200 : 8.940696716308594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 103/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 104/200 : 8.749961853027344e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 105/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 106/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 107/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 108/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 109/200 : 9.679794311523438e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 110/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 111/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 112/200 : 0.0001361370086669922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 113/200 : 0.00014209747314453125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 114/200 : 0.00010156631469726562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 115/200 : 0.00011515617370605469 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 116/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 117/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 118/200 : 0.0001659393310546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 119/200 : 0.0001857280731201172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 120/200 : 0.00019884109497070312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 121/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 122/200 : 0.00033974647521972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 123/200 : 0.00010800361633300781 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 124/200 : 9.179115295410156e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 125/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 126/200 : 9.703636169433594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 127/200 : 9.5367431640625e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 128/200 : 9.202957153320312e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 129/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 130/200 : 8.654594421386719e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 131/200 : 8.869171142578125e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 132/200 : 8.7738037109375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 133/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 134/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 135/200 : 8.7738037109375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 136/200 : 8.749961853027344e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 137/200 : 9.775161743164062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 138/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 139/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 140/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 141/200 : 8.749961853027344e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 142/200 : 8.797645568847656e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 143/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 144/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 145/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 146/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 147/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 148/200 : 8.940696716308594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 149/200 : 9.250640869140625e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 150/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 151/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 152/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 153/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 154/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 155/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 156/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 157/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 158/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 159/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 160/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 161/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 162/200 : 8.96453857421875e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 163/200 : 8.940696716308594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 164/200 : 9.179115295410156e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 165/200 : 8.988380432128906e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 166/200 : 8.916854858398438e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 167/200 : 8.7738037109375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 168/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 169/200 : 8.702278137207031e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 170/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 171/200 : 0.00010895729064941406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 172/200 : 0.00011968612670898438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 173/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 174/200 : 9.059906005859375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 175/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 176/200 : 0.00018548965454101562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 177/200 : 9.417533874511719e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 178/200 : 9.703636169433594e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 179/200 : 0.00020265579223632812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 180/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200 : 9.131431579589844e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 182/200 : 0.0001163482666015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 183/200 : 9.322166442871094e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 184/200 : 9.012222290039062e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 185/200 : 9.1552734375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 186/200 : 9.799003601074219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 187/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 188/200 : 9.608268737792969e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 189/200 : 9.822845458984375e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 190/200 : 0.00012087821960449219 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 191/200 : 0.00016069412231445312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 192/200 : 9.870529174804688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 193/200 : 0.00017905235290527344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 194/200 : 0.00017881393432617188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 195/200 : 9.036064147949219e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 196/200 : 9.250640869140625e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 197/200 : 9.083747863769531e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 198/200 : 9.107589721679688e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 199/200 : 0.00014901161193847656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n",
      "Epoch 200/200 : 8.726119995117188e-05 s - loss: 1.0 - acc: 0.0 - val_loss: 0.5 - val_acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "neural_network = Network([4, 1, 10, 1])\n",
    "neural_network.fit(train_data, 200, 1, 0.1, momentum=0.0001, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, loss = neural_network.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.0 %\n",
      "Accuracy 60.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(accuracy*100.0))\n",
    "print(\"Accuracy {} %\".format(loss*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network.history['acc'])\n",
    "plt.plot(neural_network.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network.history['loss'])\n",
    "plt.plot(neural_network.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Explorasi Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deskripsi Algoritma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembelajaran akan menggunakan kakas keras dengan model <i>sequential</i> dan lapisan <i>dense</i> .Model akan memakai input layer sebanyak 1 neuron dengan bentuk input 4 sesuai jumlah attribute data latih, kemudian dengan 3 hidden layer masing-masing 2 neuron kemudian 3 neuron, dan 4 neuron dan 1 output layer dengan 1 neuron. Optimizer yang dipakai adalah Adam (Adaptive Moment Estimation), dengan perhitungan loss dengan Mean Squared Error, dan Metrics Accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Code Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(4, activation='sigmoid', input_shape=(4,)))\n",
    "network.add(Dense(1, activation='sigmoid'))\n",
    "network.add(Dense(10, activation='sigmoid'))\n",
    "network.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percobaan pada Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.8542 - acc: 0.3223 - val_loss: 1.0613 - val_acc: 0.3571\n",
      "Epoch 2/200\n",
      "121/121 [==============================] - 0s 823us/step - loss: 0.7856 - acc: 0.3223 - val_loss: 0.9569 - val_acc: 0.3571\n",
      "Epoch 3/200\n",
      "121/121 [==============================] - 0s 947us/step - loss: 0.7461 - acc: 0.3223 - val_loss: 0.8879 - val_acc: 0.3571\n",
      "Epoch 4/200\n",
      "121/121 [==============================] - 0s 951us/step - loss: 0.7234 - acc: 0.3223 - val_loss: 0.8397 - val_acc: 0.3571\n",
      "Epoch 5/200\n",
      "121/121 [==============================] - 0s 933us/step - loss: 0.7089 - acc: 0.3223 - val_loss: 0.8086 - val_acc: 0.3571\n",
      "Epoch 6/200\n",
      "121/121 [==============================] - 0s 839us/step - loss: 0.6987 - acc: 0.3223 - val_loss: 0.7863 - val_acc: 0.3571\n",
      "Epoch 7/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.6902 - acc: 0.3223 - val_loss: 0.7654 - val_acc: 0.3571\n",
      "Epoch 8/200\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.6822 - acc: 0.3223 - val_loss: 0.7521 - val_acc: 0.3571\n",
      "Epoch 9/200\n",
      "121/121 [==============================] - 0s 926us/step - loss: 0.6747 - acc: 0.3223 - val_loss: 0.7394 - val_acc: 0.3571\n",
      "Epoch 10/200\n",
      "121/121 [==============================] - 0s 903us/step - loss: 0.6691 - acc: 0.3223 - val_loss: 0.7269 - val_acc: 0.3571\n",
      "Epoch 11/200\n",
      "121/121 [==============================] - 0s 792us/step - loss: 0.6639 - acc: 0.3223 - val_loss: 0.7221 - val_acc: 0.3571\n",
      "Epoch 12/200\n",
      "121/121 [==============================] - 0s 837us/step - loss: 0.6599 - acc: 0.3223 - val_loss: 0.7143 - val_acc: 0.3571\n",
      "Epoch 13/200\n",
      "121/121 [==============================] - 0s 858us/step - loss: 0.6561 - acc: 0.3223 - val_loss: 0.7099 - val_acc: 0.3571\n",
      "Epoch 14/200\n",
      "121/121 [==============================] - 0s 878us/step - loss: 0.6527 - acc: 0.3223 - val_loss: 0.7038 - val_acc: 0.3571\n",
      "Epoch 15/200\n",
      "121/121 [==============================] - 0s 840us/step - loss: 0.6488 - acc: 0.3223 - val_loss: 0.7012 - val_acc: 0.3571\n",
      "Epoch 16/200\n",
      "121/121 [==============================] - 0s 917us/step - loss: 0.6456 - acc: 0.3223 - val_loss: 0.6959 - val_acc: 0.3571\n",
      "Epoch 17/200\n",
      "121/121 [==============================] - 0s 926us/step - loss: 0.6412 - acc: 0.3223 - val_loss: 0.6948 - val_acc: 0.3571\n",
      "Epoch 18/200\n",
      "121/121 [==============================] - 0s 869us/step - loss: 0.6370 - acc: 0.3223 - val_loss: 0.6923 - val_acc: 0.3571\n",
      "Epoch 19/200\n",
      "121/121 [==============================] - 0s 876us/step - loss: 0.6323 - acc: 0.3223 - val_loss: 0.6895 - val_acc: 0.3571\n",
      "Epoch 20/200\n",
      "121/121 [==============================] - 0s 843us/step - loss: 0.6267 - acc: 0.3223 - val_loss: 0.6870 - val_acc: 0.3571\n",
      "Epoch 21/200\n",
      "121/121 [==============================] - 0s 812us/step - loss: 0.6209 - acc: 0.3223 - val_loss: 0.6833 - val_acc: 0.3571\n",
      "Epoch 22/200\n",
      "121/121 [==============================] - 0s 869us/step - loss: 0.6140 - acc: 0.3223 - val_loss: 0.6857 - val_acc: 0.3571\n",
      "Epoch 23/200\n",
      "121/121 [==============================] - 0s 874us/step - loss: 0.6062 - acc: 0.3223 - val_loss: 0.6808 - val_acc: 0.3571\n",
      "Epoch 24/200\n",
      "121/121 [==============================] - 0s 859us/step - loss: 0.5971 - acc: 0.3223 - val_loss: 0.6770 - val_acc: 0.3571\n",
      "Epoch 25/200\n",
      "121/121 [==============================] - 0s 842us/step - loss: 0.5873 - acc: 0.3223 - val_loss: 0.6759 - val_acc: 0.3571\n",
      "Epoch 26/200\n",
      "121/121 [==============================] - 0s 837us/step - loss: 0.5760 - acc: 0.3223 - val_loss: 0.6717 - val_acc: 0.3571\n",
      "Epoch 27/200\n",
      "121/121 [==============================] - 0s 830us/step - loss: 0.5638 - acc: 0.3223 - val_loss: 0.6663 - val_acc: 0.3571\n",
      "Epoch 28/200\n",
      "121/121 [==============================] - 0s 866us/step - loss: 0.5501 - acc: 0.3223 - val_loss: 0.6605 - val_acc: 0.3571\n",
      "Epoch 29/200\n",
      "121/121 [==============================] - 0s 914us/step - loss: 0.5361 - acc: 0.3223 - val_loss: 0.6530 - val_acc: 0.3571\n",
      "Epoch 30/200\n",
      "121/121 [==============================] - 0s 868us/step - loss: 0.5214 - acc: 0.3223 - val_loss: 0.6452 - val_acc: 0.3571\n",
      "Epoch 31/200\n",
      "121/121 [==============================] - 0s 865us/step - loss: 0.5065 - acc: 0.3223 - val_loss: 0.6383 - val_acc: 0.3571\n",
      "Epoch 32/200\n",
      "121/121 [==============================] - 0s 943us/step - loss: 0.4915 - acc: 0.3223 - val_loss: 0.6290 - val_acc: 0.3571\n",
      "Epoch 33/200\n",
      "121/121 [==============================] - 0s 912us/step - loss: 0.4773 - acc: 0.4132 - val_loss: 0.6195 - val_acc: 0.5000\n",
      "Epoch 34/200\n",
      "121/121 [==============================] - 0s 994us/step - loss: 0.4637 - acc: 0.6694 - val_loss: 0.6111 - val_acc: 0.5000\n",
      "Epoch 35/200\n",
      "121/121 [==============================] - 0s 950us/step - loss: 0.4512 - acc: 0.6694 - val_loss: 0.6022 - val_acc: 0.5000\n",
      "Epoch 36/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4391 - acc: 0.6694 - val_loss: 0.5926 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "121/121 [==============================] - 0s 849us/step - loss: 0.4284 - acc: 0.6694 - val_loss: 0.5855 - val_acc: 0.5000\n",
      "Epoch 38/200\n",
      "121/121 [==============================] - 0s 860us/step - loss: 0.4183 - acc: 0.6694 - val_loss: 0.5778 - val_acc: 0.5000\n",
      "Epoch 39/200\n",
      "121/121 [==============================] - 0s 917us/step - loss: 0.4095 - acc: 0.6694 - val_loss: 0.5700 - val_acc: 0.5000\n",
      "Epoch 40/200\n",
      "121/121 [==============================] - 0s 866us/step - loss: 0.4013 - acc: 0.6694 - val_loss: 0.5631 - val_acc: 0.5000\n",
      "Epoch 41/200\n",
      "121/121 [==============================] - 0s 881us/step - loss: 0.3942 - acc: 0.6694 - val_loss: 0.5572 - val_acc: 0.5000\n",
      "Epoch 42/200\n",
      "121/121 [==============================] - 0s 825us/step - loss: 0.3877 - acc: 0.6694 - val_loss: 0.5521 - val_acc: 0.5000\n",
      "Epoch 43/200\n",
      "121/121 [==============================] - 0s 916us/step - loss: 0.3821 - acc: 0.6694 - val_loss: 0.5474 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "121/121 [==============================] - 0s 915us/step - loss: 0.3769 - acc: 0.6694 - val_loss: 0.5432 - val_acc: 0.5000\n",
      "Epoch 45/200\n",
      "121/121 [==============================] - 0s 775us/step - loss: 0.3724 - acc: 0.6694 - val_loss: 0.5393 - val_acc: 0.5000\n",
      "Epoch 46/200\n",
      "121/121 [==============================] - 0s 817us/step - loss: 0.3683 - acc: 0.6694 - val_loss: 0.5357 - val_acc: 0.5000\n",
      "Epoch 47/200\n",
      "121/121 [==============================] - 0s 813us/step - loss: 0.3648 - acc: 0.6694 - val_loss: 0.5324 - val_acc: 0.5000\n",
      "Epoch 48/200\n",
      "121/121 [==============================] - 0s 781us/step - loss: 0.3615 - acc: 0.6694 - val_loss: 0.5296 - val_acc: 0.5000\n",
      "Epoch 49/200\n",
      "121/121 [==============================] - 0s 822us/step - loss: 0.3586 - acc: 0.6694 - val_loss: 0.5269 - val_acc: 0.5000\n",
      "Epoch 50/200\n",
      "121/121 [==============================] - 0s 836us/step - loss: 0.3561 - acc: 0.6694 - val_loss: 0.5245 - val_acc: 0.5000\n",
      "Epoch 51/200\n",
      "121/121 [==============================] - 0s 855us/step - loss: 0.3538 - acc: 0.6694 - val_loss: 0.5227 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "121/121 [==============================] - 0s 796us/step - loss: 0.3517 - acc: 0.6694 - val_loss: 0.5206 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "121/121 [==============================] - 0s 866us/step - loss: 0.3499 - acc: 0.6694 - val_loss: 0.5192 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "121/121 [==============================] - 0s 868us/step - loss: 0.3482 - acc: 0.6694 - val_loss: 0.5174 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.3467 - acc: 0.6694 - val_loss: 0.5160 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "121/121 [==============================] - 0s 848us/step - loss: 0.3453 - acc: 0.6694 - val_loss: 0.5147 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "121/121 [==============================] - 0s 929us/step - loss: 0.3441 - acc: 0.6694 - val_loss: 0.5135 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "121/121 [==============================] - 0s 888us/step - loss: 0.3430 - acc: 0.6694 - val_loss: 0.5124 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "121/121 [==============================] - 0s 911us/step - loss: 0.3420 - acc: 0.6694 - val_loss: 0.5115 - val_acc: 0.5000\n",
      "Epoch 60/200\n",
      "121/121 [==============================] - 0s 841us/step - loss: 0.3411 - acc: 0.6694 - val_loss: 0.5106 - val_acc: 0.5000\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 804us/step - loss: 0.3402 - acc: 0.6694 - val_loss: 0.5098 - val_acc: 0.5000\n",
      "Epoch 62/200\n",
      "121/121 [==============================] - 0s 810us/step - loss: 0.3395 - acc: 0.6694 - val_loss: 0.5090 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "121/121 [==============================] - 0s 802us/step - loss: 0.3388 - acc: 0.6694 - val_loss: 0.5083 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      "121/121 [==============================] - 0s 842us/step - loss: 0.3381 - acc: 0.6694 - val_loss: 0.5078 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "121/121 [==============================] - 0s 846us/step - loss: 0.3376 - acc: 0.6694 - val_loss: 0.5072 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "121/121 [==============================] - 0s 848us/step - loss: 0.3370 - acc: 0.6694 - val_loss: 0.5066 - val_acc: 0.5000\n",
      "Epoch 67/200\n",
      "121/121 [==============================] - 0s 905us/step - loss: 0.3366 - acc: 0.6694 - val_loss: 0.5061 - val_acc: 0.5000\n",
      "Epoch 68/200\n",
      "121/121 [==============================] - 0s 879us/step - loss: 0.3361 - acc: 0.6694 - val_loss: 0.5057 - val_acc: 0.5000\n",
      "Epoch 69/200\n",
      "121/121 [==============================] - 0s 821us/step - loss: 0.3357 - acc: 0.6694 - val_loss: 0.5053 - val_acc: 0.5000\n",
      "Epoch 70/200\n",
      "121/121 [==============================] - 0s 861us/step - loss: 0.3353 - acc: 0.6694 - val_loss: 0.5049 - val_acc: 0.5000\n",
      "Epoch 71/200\n",
      "121/121 [==============================] - 0s 895us/step - loss: 0.3350 - acc: 0.6694 - val_loss: 0.5046 - val_acc: 0.5000\n",
      "Epoch 72/200\n",
      "121/121 [==============================] - 0s 848us/step - loss: 0.3347 - acc: 0.6694 - val_loss: 0.5043 - val_acc: 0.5000\n",
      "Epoch 73/200\n",
      "121/121 [==============================] - 0s 932us/step - loss: 0.3344 - acc: 0.6694 - val_loss: 0.5039 - val_acc: 0.5000\n",
      "Epoch 74/200\n",
      "121/121 [==============================] - 0s 861us/step - loss: 0.3341 - acc: 0.6694 - val_loss: 0.5037 - val_acc: 0.5000\n",
      "Epoch 75/200\n",
      "121/121 [==============================] - 0s 843us/step - loss: 0.3339 - acc: 0.6694 - val_loss: 0.5034 - val_acc: 0.5000\n",
      "Epoch 76/200\n",
      "121/121 [==============================] - 0s 893us/step - loss: 0.3336 - acc: 0.6694 - val_loss: 0.5032 - val_acc: 0.5000\n",
      "Epoch 77/200\n",
      "121/121 [==============================] - 0s 874us/step - loss: 0.3334 - acc: 0.6694 - val_loss: 0.5030 - val_acc: 0.5000\n",
      "Epoch 78/200\n",
      "121/121 [==============================] - 0s 844us/step - loss: 0.3332 - acc: 0.6694 - val_loss: 0.5028 - val_acc: 0.5000\n",
      "Epoch 79/200\n",
      "121/121 [==============================] - 0s 868us/step - loss: 0.3330 - acc: 0.6694 - val_loss: 0.5026 - val_acc: 0.5000\n",
      "Epoch 80/200\n",
      "121/121 [==============================] - 0s 945us/step - loss: 0.3329 - acc: 0.6694 - val_loss: 0.5024 - val_acc: 0.5000\n",
      "Epoch 81/200\n",
      "121/121 [==============================] - 0s 843us/step - loss: 0.3327 - acc: 0.6694 - val_loss: 0.5022 - val_acc: 0.5000\n",
      "Epoch 82/200\n",
      "121/121 [==============================] - 0s 912us/step - loss: 0.3326 - acc: 0.6694 - val_loss: 0.5021 - val_acc: 0.5000\n",
      "Epoch 83/200\n",
      "121/121 [==============================] - 0s 836us/step - loss: 0.3324 - acc: 0.6694 - val_loss: 0.5020 - val_acc: 0.5000\n",
      "Epoch 84/200\n",
      "121/121 [==============================] - 0s 869us/step - loss: 0.3323 - acc: 0.6694 - val_loss: 0.5018 - val_acc: 0.5000\n",
      "Epoch 85/200\n",
      "121/121 [==============================] - 0s 863us/step - loss: 0.3322 - acc: 0.6694 - val_loss: 0.5017 - val_acc: 0.5000\n",
      "Epoch 86/200\n",
      "121/121 [==============================] - 0s 808us/step - loss: 0.3321 - acc: 0.6694 - val_loss: 0.5016 - val_acc: 0.5000\n",
      "Epoch 87/200\n",
      "121/121 [==============================] - 0s 845us/step - loss: 0.3320 - acc: 0.6694 - val_loss: 0.5015 - val_acc: 0.5000\n",
      "Epoch 88/200\n",
      "121/121 [==============================] - 0s 804us/step - loss: 0.3319 - acc: 0.6694 - val_loss: 0.5014 - val_acc: 0.5000\n",
      "Epoch 89/200\n",
      "121/121 [==============================] - 0s 813us/step - loss: 0.3318 - acc: 0.6694 - val_loss: 0.5013 - val_acc: 0.5000\n",
      "Epoch 90/200\n",
      "121/121 [==============================] - 0s 871us/step - loss: 0.3317 - acc: 0.6694 - val_loss: 0.5012 - val_acc: 0.5000\n",
      "Epoch 91/200\n",
      "121/121 [==============================] - 0s 878us/step - loss: 0.3316 - acc: 0.6694 - val_loss: 0.5011 - val_acc: 0.5000\n",
      "Epoch 92/200\n",
      "121/121 [==============================] - 0s 794us/step - loss: 0.3316 - acc: 0.6694 - val_loss: 0.5011 - val_acc: 0.5000\n",
      "Epoch 93/200\n",
      "121/121 [==============================] - 0s 785us/step - loss: 0.3315 - acc: 0.6694 - val_loss: 0.5010 - val_acc: 0.5000\n",
      "Epoch 94/200\n",
      "121/121 [==============================] - 0s 828us/step - loss: 0.3315 - acc: 0.6694 - val_loss: 0.5009 - val_acc: 0.5000\n",
      "Epoch 95/200\n",
      "121/121 [==============================] - 0s 818us/step - loss: 0.3314 - acc: 0.6694 - val_loss: 0.5009 - val_acc: 0.5000\n",
      "Epoch 96/200\n",
      "121/121 [==============================] - 0s 839us/step - loss: 0.3313 - acc: 0.6694 - val_loss: 0.5008 - val_acc: 0.5000\n",
      "Epoch 97/200\n",
      "121/121 [==============================] - 0s 878us/step - loss: 0.3313 - acc: 0.6694 - val_loss: 0.5008 - val_acc: 0.5000\n",
      "Epoch 98/200\n",
      "121/121 [==============================] - 0s 899us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 99/200\n",
      "121/121 [==============================] - 0s 848us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "121/121 [==============================] - 0s 825us/step - loss: 0.3312 - acc: 0.6694 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 101/200\n",
      "121/121 [==============================] - 0s 909us/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 102/200\n",
      "121/121 [==============================] - 0s 861us/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 103/200\n",
      "121/121 [==============================] - 0s 920us/step - loss: 0.3311 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 104/200\n",
      "121/121 [==============================] - 0s 815us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 105/200\n",
      "121/121 [==============================] - 0s 870us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5005 - val_acc: 0.5000\n",
      "Epoch 106/200\n",
      "121/121 [==============================] - 0s 863us/step - loss: 0.3310 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 107/200\n",
      "121/121 [==============================] - 0s 871us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 108/200\n",
      "121/121 [==============================] - 0s 807us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 109/200\n",
      "121/121 [==============================] - 0s 859us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5004 - val_acc: 0.5000\n",
      "Epoch 110/200\n",
      "121/121 [==============================] - 0s 820us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 111/200\n",
      "121/121 [==============================] - 0s 823us/step - loss: 0.3309 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 112/200\n",
      "121/121 [==============================] - 0s 871us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 113/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 114/200\n",
      "121/121 [==============================] - 0s 851us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5003 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "121/121 [==============================] - 0s 957us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 116/200\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 117/200\n",
      "121/121 [==============================] - 0s 899us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 118/200\n",
      "121/121 [==============================] - 0s 944us/step - loss: 0.3308 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 119/200\n",
      "121/121 [==============================] - 0s 910us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 120/200\n",
      "121/121 [==============================] - 0s 842us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 795us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 122/200\n",
      "121/121 [==============================] - 0s 874us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 123/200\n",
      "121/121 [==============================] - 0s 852us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 124/200\n",
      "121/121 [==============================] - 0s 837us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 125/200\n",
      "121/121 [==============================] - 0s 853us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      "121/121 [==============================] - 0s 852us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 127/200\n",
      "121/121 [==============================] - 0s 817us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 128/200\n",
      "121/121 [==============================] - 0s 822us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 129/200\n",
      "121/121 [==============================] - 0s 832us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 130/200\n",
      "121/121 [==============================] - 0s 982us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "121/121 [==============================] - 0s 874us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 132/200\n",
      "121/121 [==============================] - 0s 840us/step - loss: 0.3307 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 133/200\n",
      "121/121 [==============================] - 0s 841us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 134/200\n",
      "121/121 [==============================] - 0s 905us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 135/200\n",
      "121/121 [==============================] - 0s 845us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 136/200\n",
      "121/121 [==============================] - 0s 828us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 137/200\n",
      "121/121 [==============================] - 0s 872us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 138/200\n",
      "121/121 [==============================] - 0s 955us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 139/200\n",
      "121/121 [==============================] - 0s 953us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 140/200\n",
      "121/121 [==============================] - 0s 845us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 141/200\n",
      "121/121 [==============================] - 0s 900us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "121/121 [==============================] - 0s 779us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 143/200\n",
      "121/121 [==============================] - 0s 852us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 144/200\n",
      "121/121 [==============================] - 0s 827us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "121/121 [==============================] - 0s 827us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "121/121 [==============================] - 0s 919us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "121/121 [==============================] - 0s 945us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 149/200\n",
      "121/121 [==============================] - 0s 817us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 150/200\n",
      "121/121 [==============================] - 0s 830us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "121/121 [==============================] - 0s 827us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 152/200\n",
      "121/121 [==============================] - 0s 934us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 153/200\n",
      "121/121 [==============================] - 0s 927us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 154/200\n",
      "121/121 [==============================] - 0s 826us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 155/200\n",
      "121/121 [==============================] - 0s 785us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 156/200\n",
      "121/121 [==============================] - 0s 849us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 157/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 158/200\n",
      "121/121 [==============================] - 0s 903us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 159/200\n",
      "121/121 [==============================] - 0s 845us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 160/200\n",
      "121/121 [==============================] - 0s 825us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 161/200\n",
      "121/121 [==============================] - 0s 832us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 162/200\n",
      "121/121 [==============================] - 0s 779us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 163/200\n",
      "121/121 [==============================] - 0s 819us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 164/200\n",
      "121/121 [==============================] - 0s 786us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 165/200\n",
      "121/121 [==============================] - 0s 811us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 166/200\n",
      "121/121 [==============================] - 0s 800us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 167/200\n",
      "121/121 [==============================] - 0s 851us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 168/200\n",
      "121/121 [==============================] - 0s 844us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 169/200\n",
      "121/121 [==============================] - 0s 812us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 170/200\n",
      "121/121 [==============================] - 0s 814us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 171/200\n",
      "121/121 [==============================] - 0s 777us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 172/200\n",
      "121/121 [==============================] - 0s 804us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 173/200\n",
      "121/121 [==============================] - 0s 805us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 174/200\n",
      "121/121 [==============================] - 0s 813us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 175/200\n",
      "121/121 [==============================] - 0s 835us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 176/200\n",
      "121/121 [==============================] - 0s 808us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 177/200\n",
      "121/121 [==============================] - 0s 912us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 178/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 179/200\n",
      "121/121 [==============================] - 0s 801us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 180/200\n",
      "121/121 [==============================] - 0s 851us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "121/121 [==============================] - 0s 822us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 182/200\n",
      "121/121 [==============================] - 0s 864us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 183/200\n",
      "121/121 [==============================] - 0s 834us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "121/121 [==============================] - 0s 851us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 185/200\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 186/200\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 187/200\n",
      "121/121 [==============================] - 0s 831us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 188/200\n",
      "121/121 [==============================] - 0s 862us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 189/200\n",
      "121/121 [==============================] - 0s 812us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "121/121 [==============================] - 0s 873us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 191/200\n",
      "121/121 [==============================] - 0s 855us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 192/200\n",
      "121/121 [==============================] - 0s 872us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 193/200\n",
      "121/121 [==============================] - 0s 848us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 194/200\n",
      "121/121 [==============================] - 0s 934us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 195/200\n",
      "121/121 [==============================] - 0s 852us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 196/200\n",
      "121/121 [==============================] - 0s 870us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "121/121 [==============================] - 0s 954us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "121/121 [==============================] - 0s 895us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "121/121 [==============================] - 0s 819us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "121/121 [==============================] - 0s 839us/step - loss: 0.3306 - acc: 0.6694 - val_loss: 0.5000 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train, y_train, epochs=200, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 373us/step\n"
     ]
    }
   ],
   "source": [
    "score = network.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 20.00008637411933 %\n",
      "Accuracy 80.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(score[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen Data Categorization Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persiapan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal pertama yang kami lakukan adalah menggunakan data latih Weather Categorization dari WEKA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temperature  humidity  windy play\n",
       "0      sunny           85        85  False   no\n",
       "1      sunny           80        90   True   no\n",
       "2   overcast           83        86  False  yes\n",
       "3      rainy           70        96  False  yes\n",
       "4      rainy           68        80  False  yes\n",
       "5      rainy           65        70   True   no\n",
       "6   overcast           64        65   True  yes\n",
       "7      sunny           72        95  False   no\n",
       "8      sunny           69        70  False  yes\n",
       "9      rainy           75        80  False  yes\n",
       "10     sunny           75        70   True  yes\n",
       "11  overcast           72        90   True  yes\n",
       "12  overcast           81        75  False  yes\n",
       "13     rainy           71        91   True   no"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('dataset/weather.csv')\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat data latih terdiri dari data numerik dan data kategorikal. Diperlukan preprocessing dengan kakas scikit-learn yaitu LabelEncoder sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "weather_df['outlook'] = label_encoder.fit_transform(weather_df.outlook)\n",
    "weather_df['windy'] = label_encoder.fit_transform(weather_df.windy)\n",
    "weather_df['play'] = label_encoder.fit_transform(weather_df.play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0         2           85        85      0     0\n",
       "1         2           80        90      1     0\n",
       "2         0           83        86      0     1\n",
       "3         1           70        96      0     1\n",
       "4         1           68        80      0     1\n",
       "5         1           65        70      1     0\n",
       "6         0           64        65      1     1\n",
       "7         2           72        95      0     0\n",
       "8         2           69        70      0     1\n",
       "9         1           75        80      0     1\n",
       "10        2           75        70      1     1\n",
       "11        0           72        90      1     1\n",
       "12        0           81        75      0     1\n",
       "13        1           71        91      1     0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1],\n",
       "       [ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weather = weather_df.iloc[:,:4].values\n",
    "X_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_weather = weather_df.play.values\n",
    "y_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian, setelah kami menjadikan data latih tersebut numerik, kami melakukan pemisahan sebagian data latih (10%) menjadi data uji dengan proporsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_weather, y_weather, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x, y) for x, y in zip(X_train, y_train)]\n",
    "test_data = [(x, y) for x, y in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Batch = 1 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier Sendiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500 : 0.00015592575073242188 s - loss: 0.0 - acc: 1.0 - val_loss: 1.0 - val_acc: 0.0\n",
      "Epoch 2/500 : 0.00015687942504882812 s - loss: 0.0 - acc: 1.0 - val_loss: 1.0 - val_acc: 0.0\n",
      "Epoch 3/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 4/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 5/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 6/500 : 0.0001628398895263672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 7/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 8/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 9/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 10/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 11/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 12/500 : 0.00020074844360351562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 13/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 14/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 15/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 16/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 17/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 18/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 19/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 20/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 21/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 22/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 23/500 : 0.0001666545867919922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 24/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 25/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 26/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 27/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 28/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 29/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 30/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 31/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 32/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 33/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 34/500 : 0.0001552104949951172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 35/500 : 0.00026416778564453125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 36/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 37/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 38/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 39/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 40/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 41/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 42/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 43/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 44/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 45/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 46/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 47/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 48/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 49/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 50/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 51/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 52/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 53/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 54/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 55/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 56/500 : 0.0003604888916015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 57/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 58/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 59/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 60/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 61/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 62/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 63/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 64/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 65/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 66/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 67/500 : 0.00015425682067871094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 68/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 69/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 70/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 71/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 72/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 73/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 74/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 75/500 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 76/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 77/500 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 78/500 : 0.00015497207641601562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 79/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 80/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 81/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 82/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 83/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 84/500 : 0.0002288818359375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 85/500 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 86/500 : 0.0001404285430908203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 87/500 : 0.0001385211944580078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 88/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 89/500 : 0.00013589859008789062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 90/500 : 0.00016689300537109375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 91/500 : 0.00031375885009765625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 92/500 : 0.0003421306610107422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 93/500 : 0.0002751350402832031 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 94/500 : 0.00027489662170410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 95/500 : 0.0002734661102294922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 96/500 : 0.0002989768981933594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 97/500 : 0.0002930164337158203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/500 : 0.0002701282501220703 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 99/500 : 0.00028014183044433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 100/500 : 0.0002701282501220703 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 101/500 : 0.0002696514129638672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 102/500 : 0.00022077560424804688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 103/500 : 0.0001423358917236328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 104/500 : 0.00014090538024902344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 105/500 : 0.00013875961303710938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 106/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 107/500 : 0.00014209747314453125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 108/500 : 0.00013685226440429688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 109/500 : 0.0001480579376220703 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 110/500 : 0.00013875961303710938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 111/500 : 0.00013685226440429688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 112/500 : 0.00013756752014160156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 113/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 114/500 : 0.00019788742065429688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 115/500 : 0.00014138221740722656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 116/500 : 0.00014162063598632812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 117/500 : 0.00020933151245117188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 118/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 119/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 120/500 : 0.0002624988555908203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 121/500 : 0.00013875961303710938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 122/500 : 0.00030040740966796875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 123/500 : 0.0003726482391357422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 124/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 125/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 126/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 127/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 128/500 : 0.00023746490478515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 129/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 130/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 131/500 : 0.00014853477478027344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 132/500 : 0.00025963783264160156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 133/500 : 0.00014019012451171875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 134/500 : 0.0001380443572998047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 135/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 136/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 137/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 138/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 139/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 140/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 141/500 : 0.0001385211944580078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 142/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 143/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 144/500 : 0.0002713203430175781 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 145/500 : 0.0002639293670654297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 146/500 : 0.00013899803161621094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 147/500 : 0.00013780593872070312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 148/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 149/500 : 0.00016021728515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 150/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 151/500 : 0.00024366378784179688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 152/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 153/500 : 0.00013756752014160156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 154/500 : 0.0002808570861816406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 155/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 156/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 157/500 : 0.0001404285430908203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 158/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 159/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 160/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 161/500 : 0.0001518726348876953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 162/500 : 0.00014710426330566406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 163/500 : 0.00016164779663085938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 164/500 : 0.00015974044799804688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 165/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 166/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 167/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 168/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 169/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 170/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 171/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 172/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 173/500 : 0.00021004676818847656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 174/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 175/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 176/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 177/500 : 0.00015974044799804688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 178/500 : 0.0001418590545654297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 179/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 180/500 : 0.00016069412231445312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 181/500 : 0.0001614093780517578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 182/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 183/500 : 0.00014066696166992188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 184/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 185/500 : 0.00048065185546875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 186/500 : 0.00013875961303710938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 187/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 188/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 189/500 : 0.00013709068298339844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 190/500 : 0.00013756752014160156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/500 : 0.00014066696166992188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 192/500 : 0.0001385211944580078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 193/500 : 0.0002810955047607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 194/500 : 0.0002799034118652344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 195/500 : 0.0002732276916503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 196/500 : 0.0002720355987548828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 197/500 : 0.0002715587615966797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 198/500 : 0.00013780593872070312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 199/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 200/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 201/500 : 0.00016045570373535156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 202/500 : 0.00013709068298339844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 203/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 204/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 205/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 206/500 : 0.00016164779663085938 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 207/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 208/500 : 0.00016236305236816406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 209/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 210/500 : 0.00013709068298339844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 211/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 212/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 213/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 214/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 215/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 216/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 217/500 : 0.00024890899658203125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 218/500 : 0.00014400482177734375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 219/500 : 0.0001995563507080078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 220/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 221/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 222/500 : 0.0001666545867919922 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 223/500 : 0.00028228759765625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 224/500 : 0.0001366138458251953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 225/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 226/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 227/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 228/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 229/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 230/500 : 0.00016736984252929688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 231/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 232/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 233/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 234/500 : 0.00025391578674316406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 235/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 236/500 : 0.00017142295837402344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 237/500 : 0.00013685226440429688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 238/500 : 0.0001366138458251953 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 239/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 240/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 241/500 : 0.00016021728515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 242/500 : 0.00017023086547851562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 243/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 244/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 245/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 246/500 : 0.0001690387725830078 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 247/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 248/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 249/500 : 0.00021409988403320312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 250/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 251/500 : 0.0001595020294189453 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 252/500 : 0.0001628398895263672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 253/500 : 0.00016069412231445312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 254/500 : 0.00018787384033203125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 255/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 256/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 257/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 258/500 : 0.00016045570373535156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 259/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 260/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 261/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 262/500 : 0.00016188621520996094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 263/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 264/500 : 0.0002701282501220703 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 265/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 266/500 : 0.0005671977996826172 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 267/500 : 0.00014495849609375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 268/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 269/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 270/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 271/500 : 0.00014209747314453125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 272/500 : 0.0001373291015625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 273/500 : 0.0001614093780517578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 274/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 275/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 276/500 : 0.0001742839813232422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 277/500 : 0.00016260147094726562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 278/500 : 0.0001380443572998047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 279/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 280/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 281/500 : 0.00018644332885742188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 282/500 : 0.00016188621520996094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 283/500 : 0.000141143798828125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 284/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 285/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500 : 0.00016188621520996094 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 287/500 : 0.00016236305236816406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 288/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 289/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 290/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 291/500 : 0.0004544258117675781 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 292/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 293/500 : 0.00016117095947265625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 294/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 295/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 296/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 297/500 : 0.00016498565673828125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 298/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 299/500 : 0.00017261505126953125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 300/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 301/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 302/500 : 0.00016450881958007812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 303/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 304/500 : 0.00014138221740722656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 305/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 306/500 : 0.00013637542724609375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 307/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 308/500 : 0.00013971328735351562 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 309/500 : 0.00013947486877441406 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 310/500 : 0.00013828277587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 311/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 312/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 313/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 314/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 315/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 316/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 317/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 318/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 319/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 320/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 321/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 322/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 323/500 : 0.0001609325408935547 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 324/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 325/500 : 0.00016069412231445312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 326/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 327/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 328/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 329/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 330/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 331/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 332/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 333/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 334/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 335/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 336/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 337/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 338/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 339/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 340/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 341/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 342/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 343/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 344/500 : 0.0001804828643798828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 345/500 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 346/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 347/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 348/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 349/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 350/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 351/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 352/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 353/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 354/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 355/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 356/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 357/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 358/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 359/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 360/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 361/500 : 0.0001647472381591797 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 362/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 363/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 364/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 365/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 366/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 367/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 368/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 369/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 370/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 371/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 372/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 373/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 374/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 375/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 376/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 377/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 378/500 : 0.00016069412231445312 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 379/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 380/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 381/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 382/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 383/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 384/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 385/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 386/500 : 0.00016021728515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 387/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 388/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 389/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 390/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 392/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 393/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 394/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 395/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 396/500 : 0.0001628398895263672 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 397/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 398/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 399/500 : 0.00015974044799804688 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 400/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 401/500 : 0.0001652240753173828 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 402/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 403/500 : 0.00017881393432617188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 404/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 405/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 406/500 : 0.0001556873321533203 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 407/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 408/500 : 0.0003018379211425781 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 409/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 410/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 411/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 412/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 413/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 414/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 415/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 416/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 417/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 418/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 419/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 420/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 421/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 422/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 423/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 424/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 425/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 426/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 427/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 428/500 : 0.00015878677368164062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 429/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 430/500 : 0.00017952919006347656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 431/500 : 0.00015544891357421875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 432/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 433/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 434/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 435/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 436/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 437/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 438/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 439/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 440/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 441/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 442/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 443/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 444/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 445/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 446/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 447/500 : 0.00017905235290527344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 448/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 449/500 : 0.00015997886657714844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 450/500 : 0.00015854835510253906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 451/500 : 0.00016021728515625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 452/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 453/500 : 0.0001614093780517578 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 454/500 : 0.0001380443572998047 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 455/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 456/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 457/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 458/500 : 0.00015282630920410156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 459/500 : 0.000263214111328125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 460/500 : 0.00014352798461914062 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 461/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 462/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 463/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 464/500 : 0.00015687942504882812 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 465/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 466/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 467/500 : 0.0001583099365234375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 468/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 469/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 470/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 471/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 472/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 473/500 : 0.00016379356384277344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 474/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 475/500 : 0.00015664100646972656 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 476/500 : 0.00015592575073242188 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 477/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 478/500 : 0.0001575946807861328 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 479/500 : 0.0001590251922607422 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 480/500 : 0.00015926361083984375 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 481/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 482/500 : 0.000156402587890625 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 483/500 : 0.0001571178436279297 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 484/500 : 0.00015616416931152344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 485/500 : 0.00020194053649902344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 486/500 : 0.0004019737243652344 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 487/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 488/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 489/500 : 0.00015807151794433594 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 490/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 491/500 : 0.00015735626220703125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 492/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 493/500 : 0.00015783309936523438 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 494/500 : 0.00029277801513671875 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 495/500 : 0.00026726722717285156 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500 : 0.00027441978454589844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 497/500 : 0.0002703666687011719 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 498/500 : 0.0002732276916503906 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 499/500 : 0.00028967857360839844 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 500/500 : 0.00028705596923828125 s - loss: 1.0 - acc: 0.0 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "neural_network1 = Network([4, 3, 5, 10, 1])\n",
    "neural_network1.fit(train_data, 500, 1, 0.1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network1.history['acc'])\n",
    "plt.plot(neural_network1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network1.history['loss'])\n",
    "plt.plot(neural_network1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1, loss1 = neural_network1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.0 %\n",
      "Accuracy 50.0 %\n",
      "Time: 2.0775177478790283 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(loss1*100.0))\n",
    "print(\"Accuracy {} %\".format(accuracy1*100.0))\n",
    "print(\"Time: {} ms\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model keras untuk eksperimen pertama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential([\n",
    "    Dense(4, input_shape=(4,)),\n",
    "    Dense(3, activation='sigmoid'),\n",
    "    Dense(5, activation='sigmoid'),\n",
    "    Dense(10, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.1215 - val_acc: 1.0000\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.1210 - val_acc: 1.0000\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.1238 - val_acc: 1.0000\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.1256 - val_acc: 1.0000\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1271 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1278 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1289 - val_acc: 1.0000\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1305 - val_acc: 1.0000\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1320 - val_acc: 1.0000\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1328 - val_acc: 1.0000\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1335 - val_acc: 1.0000\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 976us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1338 - val_acc: 1.0000\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1355 - val_acc: 1.0000\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1356 - val_acc: 1.0000\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1381 - val_acc: 1.0000\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1408 - val_acc: 1.0000\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1405 - val_acc: 1.0000\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1405 - val_acc: 1.0000\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1416 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1414 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1412 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1415 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1453 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1435 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1448 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 932us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1452 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1475 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1466 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1469 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1461 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1464 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1475 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1499 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1493 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1501 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 922us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1512 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1509 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 933us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1508 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1512 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1515 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1503 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1523 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1528 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 927us/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1539 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1527 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1531 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1548 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 939us/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1541 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1554 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1535 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 936us/step - loss: 0.2398 - acc: 0.6000 - val_loss: 0.1553 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1557 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2398 - acc: 0.6000 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2397 - acc: 0.6000 - val_loss: 0.1559 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1551 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 877us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1552 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1560 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1568 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1563 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1576 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1547 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1557 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1585 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1568 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1581 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 934us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 982us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 922us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 939us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 954us/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2365 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 952us/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 933us/step - loss: 0.2367 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2360 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2360 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 931us/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 954us/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2358 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2361 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 932us/step - loss: 0.2354 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2358 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2363 - acc: 0.6000 - val_loss: 0.1570 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 938us/step - loss: 0.2351 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2353 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1565 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2346 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2361 - acc: 0.6000 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2347 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.2343 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2339 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2338 - acc: 0.6000 - val_loss: 0.1587 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.6000 - val_loss: 0.1585 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2338 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.2339 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.2333 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2334 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2336 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2328 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 986us/step - loss: 0.2327 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2332 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2327 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2325 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2323 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2321 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 934us/step - loss: 0.2319 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2314 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 878us/step - loss: 0.2314 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2314 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2313 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.2307 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2316 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2305 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2305 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2313 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2306 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2299 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 918us/step - loss: 0.2306 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2297 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2303 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 952us/step - loss: 0.2294 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2298 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2296 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2291 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2292 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2291 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2293 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2281 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 953us/step - loss: 0.2295 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2272 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2288 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.2287 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2273 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2284 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2270 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2268 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2264 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2265 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2273 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2268 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 963us/step - loss: 0.2257 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2288 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 955us/step - loss: 0.2256 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 937us/step - loss: 0.2267 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2263 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2253 - acc: 0.6000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2245 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2257 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2260 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.2243 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 947us/step - loss: 0.2242 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2234 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2250 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2228 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2231 - acc: 0.6000 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2225 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2229 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2231 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 986us/step - loss: 0.2222 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2228 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.2265 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2230 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.2228 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 973us/step - loss: 0.2204 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2213 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2203 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2201 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2195 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.2200 - acc: 0.6000 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2187 - acc: 0.6000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2210 - acc: 0.6000 - val_loss: 0.1686 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2187 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2202 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2199 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2171 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.2198 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 976us/step - loss: 0.2179 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.2193 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2154 - acc: 0.6000 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2186 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2185 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2152 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2157 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 915us/step - loss: 0.2160 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2179 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2152 - acc: 0.6000 - val_loss: 0.1677 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 941us/step - loss: 0.2152 - acc: 0.6000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2145 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2139 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2126 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2167 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2115 - acc: 0.6000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 900us/step - loss: 0.2135 - acc: 0.6000 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2119 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2116 - acc: 0.6000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2110 - acc: 0.6000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2105 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2111 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2098 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2116 - acc: 0.6000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2105 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2128 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2089 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2079 - acc: 0.6000 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2082 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2070 - acc: 0.6000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2173 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2050 - acc: 0.6000 - val_loss: 0.1741 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2103 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2050 - acc: 0.6000 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 955us/step - loss: 0.2067 - acc: 0.6000 - val_loss: 0.1715 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 952us/step - loss: 0.2047 - acc: 0.6000 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2039 - acc: 0.6000 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2043 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2034 - acc: 0.6000 - val_loss: 0.1710 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2049 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2031 - acc: 0.6000 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2026 - acc: 0.6000 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 950us/step - loss: 0.2020 - acc: 0.6000 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2039 - acc: 0.6000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2013 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2020 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2068 - acc: 0.6000 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2069 - acc: 0.6000 - val_loss: 0.1774 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 982us/step - loss: 0.1990 - acc: 0.6000 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2024 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1999 - acc: 0.6000 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1981 - acc: 0.6000 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1968 - acc: 0.6000 - val_loss: 0.1744 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1980 - acc: 0.6000 - val_loss: 0.1752 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 914us/step - loss: 0.1970 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1964 - acc: 0.6000 - val_loss: 0.1754 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1954 - acc: 0.6000 - val_loss: 0.1763 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1946 - acc: 0.6000 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1959 - acc: 0.6000 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1947 - acc: 0.6000 - val_loss: 0.1744 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1977 - acc: 0.6000 - val_loss: 0.1799 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1952 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.1934 - acc: 0.6000 - val_loss: 0.1779 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1956 - acc: 0.6000 - val_loss: 0.1781 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1902 - acc: 0.6000 - val_loss: 0.1758 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1909 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1906 - acc: 0.6000 - val_loss: 0.1762 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1913 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1929 - acc: 0.6000 - val_loss: 0.1759 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.1927 - acc: 0.6000 - val_loss: 0.1817 - val_acc: 0.5000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.1995 - acc: 0.6000 - val_loss: 0.1741 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1840 - acc: 0.6000 - val_loss: 0.1776 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.1916 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 0.5000\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1868 - acc: 0.6000 - val_loss: 0.1772 - val_acc: 0.5000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1858 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 0.5000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1848 - acc: 0.7000 - val_loss: 0.1792 - val_acc: 0.5000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.1872 - acc: 0.6000 - val_loss: 0.1794 - val_acc: 0.5000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1828 - acc: 0.7000 - val_loss: 0.1793 - val_acc: 0.5000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 925us/step - loss: 0.1862 - acc: 0.7000 - val_loss: 0.1801 - val_acc: 0.5000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1827 - acc: 0.6000 - val_loss: 0.1796 - val_acc: 0.5000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1818 - acc: 0.6000 - val_loss: 0.1807 - val_acc: 0.5000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1884 - acc: 0.7000 - val_loss: 0.1837 - val_acc: 0.5000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1917 - acc: 0.7000 - val_loss: 0.1777 - val_acc: 0.5000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 946us/step - loss: 0.1807 - acc: 0.7000 - val_loss: 0.1852 - val_acc: 0.5000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1842 - acc: 0.8000 - val_loss: 0.1815 - val_acc: 0.5000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1779 - acc: 0.6000 - val_loss: 0.1814 - val_acc: 0.5000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1803 - acc: 0.6000 - val_loss: 0.1817 - val_acc: 0.5000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1781 - acc: 0.6000 - val_loss: 0.1832 - val_acc: 0.5000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1797 - acc: 0.7000 - val_loss: 0.1802 - val_acc: 0.5000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1780 - acc: 0.7000 - val_loss: 0.1847 - val_acc: 0.5000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1775 - acc: 0.6000 - val_loss: 0.1811 - val_acc: 0.5000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1757 - acc: 0.6000 - val_loss: 0.1818 - val_acc: 0.5000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1170 - acc: 1.000 - 0s 1ms/step - loss: 0.1739 - acc: 0.8000 - val_loss: 0.1827 - val_acc: 0.5000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1785 - acc: 0.9000 - val_loss: 0.1865 - val_acc: 0.5000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1787 - acc: 0.7000 - val_loss: 0.1829 - val_acc: 0.5000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1737 - acc: 0.7000 - val_loss: 0.1857 - val_acc: 0.5000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1759 - acc: 0.9000 - val_loss: 0.1861 - val_acc: 0.5000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1704 - acc: 0.8000 - val_loss: 0.1854 - val_acc: 0.5000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1729 - acc: 0.6000 - val_loss: 0.1850 - val_acc: 0.5000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1709 - acc: 0.8000 - val_loss: 0.1852 - val_acc: 0.5000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1697 - acc: 0.8000 - val_loss: 0.1863 - val_acc: 0.5000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1708 - acc: 0.9000 - val_loss: 0.1880 - val_acc: 0.5000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1689 - acc: 0.8000 - val_loss: 0.1863 - val_acc: 0.5000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1688 - acc: 0.8000 - val_loss: 0.1873 - val_acc: 0.5000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.1679 - acc: 0.9000 - val_loss: 0.1887 - val_acc: 0.5000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1697 - acc: 0.9000 - val_loss: 0.1898 - val_acc: 0.5000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1679 - acc: 0.8000 - val_loss: 0.1881 - val_acc: 0.5000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1700 - acc: 0.9000 - val_loss: 0.1914 - val_acc: 0.5000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1693 - acc: 0.7000 - val_loss: 0.1867 - val_acc: 0.5000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 917us/step - loss: 0.1668 - acc: 0.9000 - val_loss: 0.1921 - val_acc: 0.5000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1660 - acc: 0.9000 - val_loss: 0.1887 - val_acc: 0.5000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1677 - acc: 0.8000 - val_loss: 0.1919 - val_acc: 0.5000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.1639 - acc: 0.9000 - val_loss: 0.1910 - val_acc: 0.5000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1651 - acc: 0.8000 - val_loss: 0.1917 - val_acc: 0.5000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1616 - acc: 0.9000 - val_loss: 0.1918 - val_acc: 0.5000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1647 - acc: 0.8000 - val_loss: 0.1905 - val_acc: 0.5000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1636 - acc: 0.9000 - val_loss: 0.1926 - val_acc: 0.5000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.1610 - acc: 0.9000 - val_loss: 0.1939 - val_acc: 0.5000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 900us/step - loss: 0.1640 - acc: 0.7000 - val_loss: 0.1922 - val_acc: 0.5000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1579 - acc: 0.9000 - val_loss: 0.1927 - val_acc: 0.5000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.1597 - acc: 0.9000 - val_loss: 0.1926 - val_acc: 0.5000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1570 - acc: 0.9000 - val_loss: 0.1937 - val_acc: 0.5000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.1569 - acc: 0.9000 - val_loss: 0.1930 - val_acc: 0.5000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 899us/step - loss: 0.1562 - acc: 0.9000 - val_loss: 0.1957 - val_acc: 0.5000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1555 - acc: 0.9000 - val_loss: 0.1951 - val_acc: 0.5000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.1555 - acc: 0.9000 - val_loss: 0.1959 - val_acc: 0.5000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.1539 - acc: 0.9000 - val_loss: 0.1956 - val_acc: 0.5000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.1545 - acc: 0.9000 - val_loss: 0.1947 - val_acc: 0.5000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.1511 - acc: 0.9000 - val_loss: 0.1968 - val_acc: 0.5000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1581 - acc: 0.9000 - val_loss: 0.1990 - val_acc: 0.5000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1573 - acc: 0.7000 - val_loss: 0.1960 - val_acc: 0.5000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 945us/step - loss: 0.1545 - acc: 0.9000 - val_loss: 0.1996 - val_acc: 0.5000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1517 - acc: 0.9000 - val_loss: 0.1976 - val_acc: 0.5000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1499 - acc: 0.9000 - val_loss: 0.1987 - val_acc: 0.5000\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1485 - acc: 0.9000 - val_loss: 0.2000 - val_acc: 0.5000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9000 - val_loss: 0.1996 - val_acc: 0.5000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1479 - acc: 0.9000 - val_loss: 0.1990 - val_acc: 0.5000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1469 - acc: 0.9000 - val_loss: 0.2021 - val_acc: 0.5000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9000 - val_loss: 0.2023 - val_acc: 0.5000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1458 - acc: 0.9000 - val_loss: 0.2006 - val_acc: 0.5000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1482 - acc: 0.9000 - val_loss: 0.2048 - val_acc: 0.5000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1453 - acc: 0.9000 - val_loss: 0.2023 - val_acc: 0.5000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1468 - acc: 0.9000 - val_loss: 0.2025 - val_acc: 0.5000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9000 - val_loss: 0.2036 - val_acc: 0.5000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1414 - acc: 0.9000 - val_loss: 0.2042 - val_acc: 0.5000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 891us/step - loss: 0.1435 - acc: 0.9000 - val_loss: 0.2051 - val_acc: 0.5000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1403 - acc: 0.9000 - val_loss: 0.2067 - val_acc: 0.5000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1467 - acc: 0.9000 - val_loss: 0.2051 - val_acc: 0.5000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1455 - acc: 0.9000 - val_loss: 0.2084 - val_acc: 0.5000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1434 - acc: 0.9000 - val_loss: 0.2050 - val_acc: 0.5000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1376 - acc: 0.9000 - val_loss: 0.2086 - val_acc: 0.5000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.1473 - acc: 0.9000 - val_loss: 0.2079 - val_acc: 0.5000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1459 - acc: 0.8000 - val_loss: 0.2066 - val_acc: 0.5000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1345 - acc: 0.9000 - val_loss: 0.2117 - val_acc: 0.5000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 931us/step - loss: 0.1430 - acc: 0.9000 - val_loss: 0.2091 - val_acc: 0.5000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1416 - acc: 0.9000 - val_loss: 0.2086 - val_acc: 0.5000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1345 - acc: 0.9000 - val_loss: 0.2099 - val_acc: 0.5000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1362 - acc: 0.9000 - val_loss: 0.2097 - val_acc: 0.5000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1345 - acc: 0.9000 - val_loss: 0.2111 - val_acc: 0.5000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 955us/step - loss: 0.1351 - acc: 0.9000 - val_loss: 0.2137 - val_acc: 0.5000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1335 - acc: 0.9000 - val_loss: 0.2127 - val_acc: 0.5000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 971us/step - loss: 0.1351 - acc: 0.9000 - val_loss: 0.2135 - val_acc: 0.5000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1325 - acc: 0.9000 - val_loss: 0.2140 - val_acc: 0.5000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1339 - acc: 0.9000 - val_loss: 0.2128 - val_acc: 0.5000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1322 - acc: 0.9000 - val_loss: 0.2140 - val_acc: 0.5000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 999us/step - loss: 0.1343 - acc: 0.9000 - val_loss: 0.2134 - val_acc: 0.5000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9000 - val_loss: 0.2158 - val_acc: 0.5000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1288 - acc: 0.9000 - val_loss: 0.2161 - val_acc: 0.5000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1397 - acc: 0.9000 - val_loss: 0.2153 - val_acc: 0.5000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1574 - acc: 0.9000 - val_loss: 0.2243 - val_acc: 0.5000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1264 - acc: 0.9000 - val_loss: 0.2166 - val_acc: 0.5000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 896us/step - loss: 0.1361 - acc: 0.9000 - val_loss: 0.2184 - val_acc: 0.5000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1302 - acc: 0.9000 - val_loss: 0.2212 - val_acc: 0.5000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.1302 - acc: 0.9000 - val_loss: 0.2170 - val_acc: 0.5000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1278 - acc: 0.9000 - val_loss: 0.2193 - val_acc: 0.5000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1265 - acc: 0.9000 - val_loss: 0.2205 - val_acc: 0.5000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1245 - acc: 0.9000 - val_loss: 0.2209 - val_acc: 0.5000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1264 - acc: 0.9000 - val_loss: 0.2212 - val_acc: 0.5000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1258 - acc: 0.9000 - val_loss: 0.2237 - val_acc: 0.5000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.1275 - acc: 0.9000 - val_loss: 0.2211 - val_acc: 0.5000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1234 - acc: 0.9000 - val_loss: 0.2237 - val_acc: 0.5000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.1245 - acc: 0.9000 - val_loss: 0.2233 - val_acc: 0.5000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1228 - acc: 0.9000 - val_loss: 0.2253 - val_acc: 0.5000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1232 - acc: 0.9000 - val_loss: 0.2237 - val_acc: 0.5000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 999us/step - loss: 0.1213 - acc: 0.9000 - val_loss: 0.2246 - val_acc: 0.5000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1207 - acc: 0.9000 - val_loss: 0.2261 - val_acc: 0.5000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.1220 - acc: 0.9000 - val_loss: 0.2253 - val_acc: 0.5000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1200 - acc: 0.9000 - val_loss: 0.2261 - val_acc: 0.5000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.1228 - acc: 0.9000 - val_loss: 0.2282 - val_acc: 0.5000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1189 - acc: 0.9000 - val_loss: 0.2274 - val_acc: 0.5000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1205 - acc: 0.9000 - val_loss: 0.2294 - val_acc: 0.5000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1188 - acc: 0.9000 - val_loss: 0.2291 - val_acc: 0.5000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1204 - acc: 0.9000 - val_loss: 0.2287 - val_acc: 0.5000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 947us/step - loss: 0.1243 - acc: 0.9000 - val_loss: 0.2319 - val_acc: 0.5000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1199 - acc: 0.9000 - val_loss: 0.2292 - val_acc: 0.5000\n",
      "Epoch 490/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9000 - val_loss: 0.2312 - val_acc: 0.5000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1179 - acc: 0.9000 - val_loss: 0.2325 - val_acc: 0.5000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1150 - acc: 0.9000 - val_loss: 0.2331 - val_acc: 0.5000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 921us/step - loss: 0.1153 - acc: 0.9000 - val_loss: 0.2340 - val_acc: 0.5000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1161 - acc: 0.9000 - val_loss: 0.2355 - val_acc: 0.5000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9000 - val_loss: 0.2343 - val_acc: 0.5000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1151 - acc: 0.9000 - val_loss: 0.2354 - val_acc: 0.5000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1147 - acc: 0.9000 - val_loss: 0.2366 - val_acc: 0.5000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1146 - acc: 0.9000 - val_loss: 0.2355 - val_acc: 0.5000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1154 - acc: 0.9000 - val_loss: 0.2377 - val_acc: 0.5000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 973us/step - loss: 0.1117 - acc: 0.9000 - val_loss: 0.2376 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history1 = network1.fit(X_train, y_train, epochs=500, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = network1.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "Loss: 11.186236515641212 %\n",
      "Accuracy 100.0 %\n",
      "Time: 6.760767936706543 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(score1[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score1[1]*100.0))\n",
    "print(\"Time: {} ms\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Batch Size = Jumlah Data Latih</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier Sendiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500 : 0.0015811920166015625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 2/500 : 0.0013401508331298828 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 3/500 : 0.0013382434844970703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 4/500 : 0.0011441707611083984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 5/500 : 0.001310586929321289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 6/500 : 0.0012900829315185547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 7/500 : 0.0013155937194824219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 8/500 : 0.0013492107391357422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 9/500 : 0.0013518333435058594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 10/500 : 0.0013277530670166016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 11/500 : 0.0012962818145751953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 12/500 : 0.0013339519500732422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 13/500 : 0.0013337135314941406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 14/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 15/500 : 0.0013113021850585938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 16/500 : 0.0013263225555419922 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 17/500 : 0.001474618911743164 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 18/500 : 0.0012857913970947266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 19/500 : 0.0014147758483886719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 20/500 : 0.0012776851654052734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 21/500 : 0.0013151168823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 22/500 : 0.0014066696166992188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 23/500 : 0.0012843608856201172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 24/500 : 0.001329183578491211 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 25/500 : 0.0014789104461669922 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 26/500 : 0.0012919902801513672 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 27/500 : 0.001316070556640625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 28/500 : 0.0013213157653808594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 29/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 30/500 : 0.0013911724090576172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 31/500 : 0.0012824535369873047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 32/500 : 0.0018699169158935547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 33/500 : 0.003058910369873047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 34/500 : 0.0021500587463378906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 35/500 : 0.0023016929626464844 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 36/500 : 0.0022094249725341797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 37/500 : 0.0022535324096679688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 38/500 : 0.0024368762969970703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 39/500 : 0.002249479293823242 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 40/500 : 0.0021965503692626953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 41/500 : 0.0021615028381347656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 42/500 : 0.0017170906066894531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 43/500 : 0.001665353775024414 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 44/500 : 0.0014848709106445312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 45/500 : 0.0013492107391357422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 46/500 : 0.001329660415649414 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 47/500 : 0.0013267993927001953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 48/500 : 0.0015590190887451172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 49/500 : 0.002201080322265625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 50/500 : 0.002345561981201172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 51/500 : 0.0022857189178466797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 52/500 : 0.002211332321166992 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 53/500 : 0.0022916793823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 54/500 : 0.0022497177124023438 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 55/500 : 0.001329660415649414 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 56/500 : 0.0013272762298583984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 57/500 : 0.0013763904571533203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 58/500 : 0.001378774642944336 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 59/500 : 0.002868175506591797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 60/500 : 0.0012972354888916016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 61/500 : 0.0014028549194335938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 62/500 : 0.0013997554779052734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 63/500 : 0.0014772415161132812 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 64/500 : 0.0014939308166503906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 65/500 : 0.0013434886932373047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 66/500 : 0.0013284683227539062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 67/500 : 0.0013294219970703125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 68/500 : 0.0013208389282226562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 69/500 : 0.0013339519500732422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 70/500 : 0.001325845718383789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 71/500 : 0.0013356208801269531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 72/500 : 0.0013294219970703125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 73/500 : 0.0013766288757324219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 74/500 : 0.0013265609741210938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 75/500 : 0.0013146400451660156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 76/500 : 0.0013065338134765625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 77/500 : 0.0013275146484375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 78/500 : 0.001417398452758789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 79/500 : 0.0013272762298583984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 80/500 : 0.001340627670288086 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 81/500 : 0.001302957534790039 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 82/500 : 0.0013217926025390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 83/500 : 0.0013248920440673828 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 84/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 85/500 : 0.0013360977172851562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 86/500 : 0.0013210773468017578 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 87/500 : 0.0013318061828613281 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 88/500 : 0.0013210773468017578 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 89/500 : 0.00131988525390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 90/500 : 0.0013303756713867188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 91/500 : 0.0013196468353271484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 92/500 : 0.0013322830200195312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 93/500 : 0.0013256072998046875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 94/500 : 0.0013234615325927734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 95/500 : 0.0013265609741210938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 96/500 : 0.0012981891632080078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 97/500 : 0.0013360977172851562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 98/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 99/500 : 0.0013310909271240234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500 : 0.001325368881225586 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 101/500 : 0.002583026885986328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 102/500 : 0.001352071762084961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 103/500 : 0.0012736320495605469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 104/500 : 0.0013151168823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 105/500 : 0.0013232231140136719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 106/500 : 0.0015361309051513672 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 107/500 : 0.0013222694396972656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 108/500 : 0.0013208389282226562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 109/500 : 0.0013194084167480469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 110/500 : 0.0013115406036376953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 111/500 : 0.0013175010681152344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 112/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 113/500 : 0.0016224384307861328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 114/500 : 0.0021626949310302734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 115/500 : 0.00142669677734375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 116/500 : 0.0014507770538330078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 117/500 : 0.001314401626586914 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 118/500 : 0.0013332366943359375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 119/500 : 0.0012540817260742188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 120/500 : 0.0013005733489990234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 121/500 : 0.0013074874877929688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 122/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 123/500 : 0.0013380050659179688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 124/500 : 0.001360177993774414 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 125/500 : 0.0013153553009033203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 126/500 : 0.0014333724975585938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 127/500 : 0.001341104507446289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 128/500 : 0.0013985633850097656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 129/500 : 0.0016391277313232422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 130/500 : 0.0013382434844970703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 131/500 : 0.0012683868408203125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 132/500 : 0.0014195442199707031 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 133/500 : 0.0012531280517578125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 134/500 : 0.001453399658203125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 135/500 : 0.0012569427490234375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 136/500 : 0.0013632774353027344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 137/500 : 0.0012552738189697266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 138/500 : 0.0012714862823486328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 139/500 : 0.0012514591217041016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 140/500 : 0.0012707710266113281 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 141/500 : 0.001253366470336914 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 142/500 : 0.0012705326080322266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 143/500 : 0.0016336441040039062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 144/500 : 0.004268646240234375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 145/500 : 0.0034971237182617188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 146/500 : 0.0015277862548828125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 147/500 : 0.001298666000366211 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 148/500 : 0.001378774642944336 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 149/500 : 0.0011734962463378906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 150/500 : 0.0013248920440673828 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 151/500 : 0.0012562274932861328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 152/500 : 0.0012946128845214844 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 153/500 : 0.0014181137084960938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 154/500 : 0.0013885498046875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 155/500 : 0.0015363693237304688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 156/500 : 0.0012362003326416016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 157/500 : 0.0014495849609375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 158/500 : 0.0011506080627441406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 159/500 : 0.0014531612396240234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 160/500 : 0.0011234283447265625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 161/500 : 0.0014255046844482422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 162/500 : 0.0010716915130615234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 163/500 : 0.0020842552185058594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 164/500 : 0.0013728141784667969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 165/500 : 0.0016014575958251953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 166/500 : 0.0013523101806640625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 167/500 : 0.0012891292572021484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 168/500 : 0.0016491413116455078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 169/500 : 0.0019338130950927734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 170/500 : 0.0017886161804199219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 171/500 : 0.0017418861389160156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 172/500 : 0.0013878345489501953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 173/500 : 0.0014638900756835938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 174/500 : 0.0014734268188476562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 175/500 : 0.0014338493347167969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 176/500 : 0.0014312267303466797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 177/500 : 0.001680612564086914 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 178/500 : 0.0014901161193847656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 179/500 : 0.0014290809631347656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 180/500 : 0.0014367103576660156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 181/500 : 0.0016930103302001953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 182/500 : 0.0016264915466308594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 183/500 : 0.0013308525085449219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 184/500 : 0.0012891292572021484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 185/500 : 0.0013136863708496094 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 186/500 : 0.0013272762298583984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 187/500 : 0.0013132095336914062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 188/500 : 0.0012805461883544922 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 189/500 : 0.0013158321380615234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 190/500 : 0.0013227462768554688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 191/500 : 0.0012898445129394531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 192/500 : 0.0013079643249511719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 193/500 : 0.0013723373413085938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 194/500 : 0.00130462646484375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 195/500 : 0.0012934207916259766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 196/500 : 0.0015628337860107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 197/500 : 0.001323699951171875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 198/500 : 0.0013060569763183594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 199/500 : 0.001295328140258789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 200/500 : 0.0014019012451171875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 201/500 : 0.0013175010681152344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/500 : 0.0013151168823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 203/500 : 0.0015902519226074219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 204/500 : 0.0012841224670410156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 205/500 : 0.0013082027435302734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 206/500 : 0.0014040470123291016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 207/500 : 0.0015344619750976562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 208/500 : 0.0013751983642578125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 209/500 : 0.0013823509216308594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 210/500 : 0.001348733901977539 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 211/500 : 0.0013167858123779297 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 212/500 : 0.00140380859375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 213/500 : 0.0013401508331298828 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 214/500 : 0.0014505386352539062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 215/500 : 0.0013899803161621094 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 216/500 : 0.0013511180877685547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 217/500 : 0.0013349056243896484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 218/500 : 0.0013384819030761719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 219/500 : 0.0013303756713867188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 220/500 : 0.00133514404296875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 221/500 : 0.0013303756713867188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 222/500 : 0.0013341903686523438 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 223/500 : 0.0012848377227783203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 224/500 : 0.001316070556640625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 225/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 226/500 : 0.0013115406036376953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 227/500 : 0.0013315677642822266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 228/500 : 0.0013265609741210938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 229/500 : 0.0013306140899658203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 230/500 : 0.0014400482177734375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 231/500 : 0.0013244152069091797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 232/500 : 0.0013244152069091797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 233/500 : 0.0013246536254882812 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 234/500 : 0.0013282299041748047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 235/500 : 0.001369476318359375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 236/500 : 0.001280069351196289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 237/500 : 0.0012700557708740234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 238/500 : 0.0017194747924804688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 239/500 : 0.0013387203216552734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 240/500 : 0.0013353824615478516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 241/500 : 0.0014247894287109375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 242/500 : 0.0017440319061279297 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 243/500 : 0.0021893978118896484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 244/500 : 0.0018758773803710938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 245/500 : 0.0013451576232910156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 246/500 : 0.0013134479522705078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 247/500 : 0.0013272762298583984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 248/500 : 0.0013315677642822266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 249/500 : 0.0013282299041748047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 250/500 : 0.0013356208801269531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 251/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 252/500 : 0.0013132095336914062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 253/500 : 0.001322031021118164 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 254/500 : 0.0013365745544433594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 255/500 : 0.0013289451599121094 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 256/500 : 0.0013496875762939453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 257/500 : 0.001399993896484375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 258/500 : 0.001314401626586914 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 259/500 : 0.001333475112915039 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 260/500 : 0.0013277530670166016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 261/500 : 0.0013203620910644531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 262/500 : 0.0013813972473144531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 263/500 : 0.0013208389282226562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 264/500 : 0.0013306140899658203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 265/500 : 0.00131988525390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 266/500 : 0.0013384819030761719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 267/500 : 0.0013227462768554688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 268/500 : 0.00133514404296875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 269/500 : 0.001329183578491211 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 270/500 : 0.0013766288757324219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 271/500 : 0.0013391971588134766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 272/500 : 0.0013301372528076172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 273/500 : 0.001386880874633789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 274/500 : 0.0013349056243896484 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 275/500 : 0.0013346672058105469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 276/500 : 0.0013267993927001953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 277/500 : 0.0013217926025390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 278/500 : 0.0013298988342285156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 279/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 280/500 : 0.0013401508331298828 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 281/500 : 0.0013103485107421875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 282/500 : 0.0013217926025390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 283/500 : 0.0013010501861572266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 284/500 : 0.0013151168823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 285/500 : 0.001341104507446289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 286/500 : 0.001316070556640625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 287/500 : 0.0013270378112792969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 288/500 : 0.0013189315795898438 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 289/500 : 0.0013303756713867188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 290/500 : 0.001359701156616211 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 291/500 : 0.0013506412506103516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 292/500 : 0.0012354850769042969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 293/500 : 0.0013048648834228516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 294/500 : 0.0013370513916015625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 295/500 : 0.0013201236724853516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 296/500 : 0.0013358592987060547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 297/500 : 0.0013179779052734375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 298/500 : 0.001291036605834961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 299/500 : 0.0013077259063720703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 300/500 : 0.0013027191162109375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 301/500 : 0.0014295578002929688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 302/500 : 0.0013039112091064453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 303/500 : 0.0012421607971191406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 304/500 : 0.0013499259948730469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 305/500 : 0.0013387203216552734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 306/500 : 0.0013217926025390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 307/500 : 0.0012807846069335938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 308/500 : 0.0013134479522705078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 309/500 : 0.001316070556640625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 310/500 : 0.0013129711151123047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 311/500 : 0.0013191699981689453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 312/500 : 0.0013141632080078125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500 : 0.0012698173522949219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 314/500 : 0.0017828941345214844 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 315/500 : 0.0013284683227539062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 316/500 : 0.0012726783752441406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 317/500 : 0.00225067138671875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 318/500 : 0.002255678176879883 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 319/500 : 0.002268075942993164 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 320/500 : 0.002265453338623047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 321/500 : 0.0023031234741210938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 322/500 : 0.002290487289428711 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 323/500 : 0.0021321773529052734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 324/500 : 0.002240896224975586 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 325/500 : 0.0017991065979003906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 326/500 : 0.0013270378112792969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 327/500 : 0.0014960765838623047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 328/500 : 0.001356363296508789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 329/500 : 0.0012867450714111328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 330/500 : 0.001325368881225586 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 331/500 : 0.0012612342834472656 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 332/500 : 0.0012731552124023438 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 333/500 : 0.0012819766998291016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 334/500 : 0.0013661384582519531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 335/500 : 0.0013353824615478516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 336/500 : 0.001382589340209961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 337/500 : 0.0013179779052734375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 338/500 : 0.0013275146484375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 339/500 : 0.001313924789428711 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 340/500 : 0.00133514404296875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 341/500 : 0.0012743473052978516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 342/500 : 0.00141143798828125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 343/500 : 0.0012805461883544922 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 344/500 : 0.0033524036407470703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 345/500 : 0.0014545917510986328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 346/500 : 0.0013577938079833984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 347/500 : 0.001331329345703125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 348/500 : 0.0013358592987060547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 349/500 : 0.001344919204711914 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 350/500 : 0.0013115406036376953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 351/500 : 0.002235889434814453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 352/500 : 0.001329183578491211 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 353/500 : 0.0014679431915283203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 354/500 : 0.0017006397247314453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 355/500 : 0.0014064311981201172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 356/500 : 0.001348733901977539 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 357/500 : 0.0013358592987060547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 358/500 : 0.0014765262603759766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 359/500 : 0.0013298988342285156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 360/500 : 0.001470804214477539 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 361/500 : 0.0013134479522705078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 362/500 : 0.0013403892517089844 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 363/500 : 0.001329660415649414 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 364/500 : 0.0013353824615478516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 365/500 : 0.001332998275756836 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 366/500 : 0.0013260841369628906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 367/500 : 0.0016324520111083984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 368/500 : 0.0014154911041259766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 369/500 : 0.0015614032745361328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 370/500 : 0.0014543533325195312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 371/500 : 0.0013091564178466797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 372/500 : 0.0014667510986328125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 373/500 : 0.0013360977172851562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 374/500 : 0.0013000965118408203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 375/500 : 0.0013194084167480469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 376/500 : 0.0013172626495361328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 377/500 : 0.0013763904571533203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 378/500 : 0.0013012886047363281 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 379/500 : 0.0013031959533691406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 380/500 : 0.0013079643249511719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 381/500 : 0.0013132095336914062 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 382/500 : 0.0013320446014404297 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 383/500 : 0.0014922618865966797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 384/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 385/500 : 0.0013260841369628906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 386/500 : 0.0013203620910644531 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 387/500 : 0.0013332366943359375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 388/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 389/500 : 0.0013360977172851562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 390/500 : 0.001287221908569336 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 391/500 : 0.001321554183959961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 392/500 : 0.0013155937194824219 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 393/500 : 0.0013225078582763672 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 394/500 : 0.0013260841369628906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 395/500 : 0.0012977123260498047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 396/500 : 0.0013020038604736328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 397/500 : 0.0013020038604736328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 398/500 : 0.0013124942779541016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 399/500 : 0.0013191699981689453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 400/500 : 0.0012924671173095703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 401/500 : 0.0013265609741210938 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 402/500 : 0.001321554183959961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 403/500 : 0.0013163089752197266 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 404/500 : 0.0013151168823242188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 405/500 : 0.0013034343719482422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 406/500 : 0.001312255859375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 407/500 : 0.0013234615325927734 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 408/500 : 0.001310110092163086 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 409/500 : 0.0013039112091064453 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 410/500 : 0.0013065338134765625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 411/500 : 0.0013186931610107422 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 412/500 : 0.0013136863708496094 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 413/500 : 0.0013227462768554688 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 414/500 : 0.001378774642944336 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 415/500 : 0.0013289451599121094 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 416/500 : 0.0013189315795898438 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 417/500 : 0.0013365745544433594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 418/500 : 0.0013213157653808594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 419/500 : 0.0013241767883300781 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 420/500 : 0.0013091564178466797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500 : 0.002047300338745117 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 422/500 : 0.001477956771850586 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 423/500 : 0.0013055801391601562 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 424/500 : 0.0013201236724853516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 425/500 : 0.0013206005096435547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 426/500 : 0.001338958740234375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 427/500 : 0.0013301372528076172 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 428/500 : 0.0013780593872070312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 429/500 : 0.0013127326965332031 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 430/500 : 0.0013098716735839844 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 431/500 : 0.001367807388305664 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 432/500 : 0.0013682842254638672 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 433/500 : 0.0015213489532470703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 434/500 : 0.001323699951171875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 435/500 : 0.0013310909271240234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 436/500 : 0.001321554183959961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 437/500 : 0.0013184547424316406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 438/500 : 0.0013272762298583984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 439/500 : 0.0013017654418945312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 440/500 : 0.0013842582702636719 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 441/500 : 0.0013327598571777344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 442/500 : 0.0014786720275878906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 443/500 : 0.0012717247009277344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 444/500 : 0.0013158321380615234 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 445/500 : 0.0013129711151123047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 446/500 : 0.0013060569763183594 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 447/500 : 0.0013217926025390625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 448/500 : 0.0012772083282470703 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 449/500 : 0.0013270378112792969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 450/500 : 0.001306772232055664 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 451/500 : 0.0013287067413330078 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 452/500 : 0.0013153553009033203 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 453/500 : 0.001293182373046875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 454/500 : 0.0013048648834228516 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 455/500 : 0.001508951187133789 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 456/500 : 0.0012753009796142578 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 457/500 : 0.0015070438385009766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 458/500 : 0.0013017654418945312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 459/500 : 0.0013573169708251953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 460/500 : 0.00156402587890625 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 461/500 : 0.0012824535369873047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 462/500 : 0.0023124217987060547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 463/500 : 0.003225564956665039 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 464/500 : 0.002162933349609375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 465/500 : 0.0022895336151123047 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 466/500 : 0.0022242069244384766 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 467/500 : 0.0021343231201171875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 468/500 : 0.0016474723815917969 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 469/500 : 0.0013530254364013672 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 470/500 : 0.0012822151184082031 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 471/500 : 0.0013937950134277344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 472/500 : 0.0013210773468017578 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 473/500 : 0.0017728805541992188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 474/500 : 0.002238035202026367 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 475/500 : 0.0023069381713867188 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 476/500 : 0.002309560775756836 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 477/500 : 0.0023179054260253906 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 478/500 : 0.002244234085083008 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 479/500 : 0.0017418861389160156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 480/500 : 0.0014672279357910156 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 481/500 : 0.0013794898986816406 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 482/500 : 0.0012714862823486328 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 483/500 : 0.001280069351196289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 484/500 : 0.001338958740234375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 485/500 : 0.0012717247009277344 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 486/500 : 0.0012969970703125 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 487/500 : 0.001249551773071289 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 488/500 : 0.001260519027709961 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 489/500 : 0.001336812973022461 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 490/500 : 0.0013277530670166016 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 491/500 : 0.0013120174407958984 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 492/500 : 0.0013206005096435547 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 493/500 : 0.0013408660888671875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 494/500 : 0.001312255859375 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 495/500 : 0.0013194084167480469 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 496/500 : 0.0013267993927001953 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 497/500 : 0.0013322830200195312 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 498/500 : 0.0022246837615966797 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 499/500 : 0.0020275115966796875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n",
      "Epoch 500/500 : 0.0013885498046875 s - loss: 0.4 - acc: 0.6 - val_loss: 0.0 - val_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "neural_network2 = Network([4, 3, 5, 10, 1])\n",
    "neural_network2.fit(train_data, 500, len(X_train), 0.1, momentum=0.0001, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network2.history['acc'])\n",
    "plt.plot(neural_network2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neural_network2.history['acc'])\n",
    "plt.plot(neural_network2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2, loss2 = neural_network2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50.0 %\n",
      "Accuracy 50.0 %\n",
      "Time: 2.0775177478790283 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(loss2*100.0))\n",
    "print(\"Accuracy {} %\".format(accuracy2*100.0))\n",
    "print(\"Time: {} ms\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model keras untuk eksperimen kedua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Sequential([\n",
    "    Dense(4, input_shape=(4,)),\n",
    "    Dense(3, activation='sigmoid'),\n",
    "    Dense(5, activation='sigmoid'),\n",
    "    Dense(10, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2438 - acc: 0.6000 - val_loss: 0.2137 - val_acc: 1.0000\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2114 - val_acc: 1.0000\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2092 - val_acc: 1.0000\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2071 - val_acc: 1.0000\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2051 - val_acc: 1.0000\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2031 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1993 - val_acc: 1.0000\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1974 - val_acc: 1.0000\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1955 - val_acc: 1.0000\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 538us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 244us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1882 - val_acc: 1.0000\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1864 - val_acc: 1.0000\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1846 - val_acc: 1.0000\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1829 - val_acc: 1.0000\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1813 - val_acc: 1.0000\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1782 - val_acc: 1.0000\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 263us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1754 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 299us/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2399 - acc: 0.6000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2398 - acc: 0.6000 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2398 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2397 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2397 - acc: 0.6000 - val_loss: 0.1679 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2397 - acc: 0.6000 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2396 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1585 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1577 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1576 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 137us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1575 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1574 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1575 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2395 - acc: 0.6000 - val_loss: 0.1576 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1577 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1585 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2394 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 137us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2393 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 142us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2392 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2391 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 135us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 135us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2390 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 486us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2389 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1611 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2388 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2387 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 504us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 289us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2386 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2385 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 250us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2384 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 138us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2383 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2382 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 125us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 133us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2381 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 425us/step - loss: 0.2380 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 234us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 283us/step - loss: 0.2379 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2378 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 314us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2377 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 333us/step - loss: 0.2376 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2375 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 324us/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2374 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 276us/step - loss: 0.2373 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 341us/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2372 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 284us/step - loss: 0.2371 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 325us/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2370 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2369 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2368 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2367 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2367 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2367 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 242us/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 338us/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2366 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2365 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2365 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2365 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2364 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 357us/step - loss: 0.2363 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2363 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 260us/step - loss: 0.2363 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2362 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2361 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2361 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 356us/step - loss: 0.2361 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2360 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2360 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2360 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2359 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2359 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2359 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2358 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 262us/step - loss: 0.2358 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 280us/step - loss: 0.2358 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 381us/step - loss: 0.2357 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2357 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2357 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 834us/step - loss: 0.2356 - acc: 0.6000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2355 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2354 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2354 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2354 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2353 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2353 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2352 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2352 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2352 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2351 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2351 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2350 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2350 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2350 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2349 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2349 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 250us/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2348 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2347 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2347 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2346 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2346 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2345 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2345 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2344 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2344 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 131us/step - loss: 0.2343 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2343 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2343 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2342 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2342 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 225us/step - loss: 0.2341 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2341 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2340 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 314us/step - loss: 0.2340 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2339 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2339 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2338 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2337 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2337 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2336 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2336 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2335 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2335 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2334 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2334 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2333 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2333 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2332 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 419us/step - loss: 0.2331 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2331 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 238us/step - loss: 0.2330 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2330 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2329 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2329 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2328 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2327 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 250us/step - loss: 0.2327 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2326 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2326 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 277us/step - loss: 0.2325 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 247us/step - loss: 0.2324 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2324 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2323 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2322 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2322 - acc: 0.6000 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2321 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2320 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2320 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2319 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2318 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 393us/step - loss: 0.2318 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 238us/step - loss: 0.2317 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2316 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2316 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2315 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2314 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2314 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2313 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2312 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2312 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2311 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2310 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2309 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2309 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2308 - acc: 0.6000 - val_loss: 0.1645 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 258us/step - loss: 0.2307 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2306 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2306 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2305 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2304 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2303 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2303 - acc: 0.6000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2302 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2301 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2300 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2300 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2299 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2298 - acc: 0.6000 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2297 - acc: 0.6000 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2296 - acc: 0.6000 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2295 - acc: 0.6000 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2295 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2294 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2293 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2292 - acc: 0.6000 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2291 - acc: 0.6000 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2290 - acc: 0.6000 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2290 - acc: 0.6000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2289 - acc: 0.6000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2288 - acc: 0.6000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2287 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2286 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2285 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2284 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2284 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2283 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2282 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 138us/step - loss: 0.2281 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 244us/step - loss: 0.2280 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2279 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2278 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2277 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2276 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2275 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2274 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2273 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.2273 - acc: 0.6000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2272 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2271 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 254us/step - loss: 0.2270 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 247us/step - loss: 0.2269 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2268 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2267 - acc: 0.6000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2266 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2265 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2264 - acc: 0.6000 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2263 - acc: 0.6000 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2262 - acc: 0.6000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2261 - acc: 0.6000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2260 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2259 - acc: 0.6000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2258 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.2257 - acc: 0.6000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2256 - acc: 0.6000 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2255 - acc: 0.6000 - val_loss: 0.1669 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 132us/step - loss: 0.2254 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2253 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2252 - acc: 0.6000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2251 - acc: 0.6000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2250 - acc: 0.6000 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2248 - acc: 0.6000 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 420us/step - loss: 0.2247 - acc: 0.6000 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2246 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2245 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2244 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2243 - acc: 0.6000 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2242 - acc: 0.6000 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2241 - acc: 0.6000 - val_loss: 0.1677 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2240 - acc: 0.6000 - val_loss: 0.1677 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2239 - acc: 0.6000 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2238 - acc: 0.6000 - val_loss: 0.1679 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2237 - acc: 0.6000 - val_loss: 0.1679 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 259us/step - loss: 0.2236 - acc: 0.6000 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 240us/step - loss: 0.2234 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2233 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2232 - acc: 0.6000 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2231 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2230 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2229 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2228 - acc: 0.6000 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 146us/step - loss: 0.2227 - acc: 0.6000 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2226 - acc: 0.6000 - val_loss: 0.1686 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2224 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2223 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2222 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2221 - acc: 0.6000 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2220 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2219 - acc: 0.6000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2218 - acc: 0.6000 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2216 - acc: 0.6000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2215 - acc: 0.6000 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2214 - acc: 0.6000 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2213 - acc: 0.6000 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2212 - acc: 0.6000 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2211 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2210 - acc: 0.6000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2208 - acc: 0.6000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2207 - acc: 0.6000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2206 - acc: 0.6000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2205 - acc: 0.6000 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 317us/step - loss: 0.2204 - acc: 0.6000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2203 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2202 - acc: 0.6000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2200 - acc: 0.6000 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2199 - acc: 0.6000 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2198 - acc: 0.6000 - val_loss: 0.1705 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2197 - acc: 0.6000 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2196 - acc: 0.6000 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2195 - acc: 0.6000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2193 - acc: 0.6000 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2192 - acc: 0.6000 - val_loss: 0.1710 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2191 - acc: 0.6000 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2190 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2189 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2188 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2186 - acc: 0.6000 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2185 - acc: 0.6000 - val_loss: 0.1715 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 306us/step - loss: 0.2184 - acc: 0.6000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 278us/step - loss: 0.2183 - acc: 0.6000 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 283us/step - loss: 0.2182 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.6000 - val_loss: 0.1719 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 397us/step - loss: 0.2180 - acc: 0.6000 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.2178 - acc: 0.6000 - val_loss: 0.1721 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 666us/step - loss: 0.2177 - acc: 0.6000 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 351us/step - loss: 0.2176 - acc: 0.6000 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2175 - acc: 0.6000 - val_loss: 0.1724 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 750us/step - loss: 0.2174 - acc: 0.6000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 338us/step - loss: 0.2173 - acc: 0.6000 - val_loss: 0.1726 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2171 - acc: 0.6000 - val_loss: 0.1727 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = network2.fit(X_train, y_train, epochs=500, verbose=1, batch_size=len(X_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = network2.evaluate(X_test, y_test, batch_size=len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 467us/step\n",
      "Loss: 17.407499253749847 %\n",
      "Accuracy 50.0 %\n",
      "Time: 2.0775177478790283 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: {} %\".format(score2[0]*100.0))\n",
    "print(\"Accuracy {} %\".format(score2[1]*100.0))\n",
    "print(\"Time: {} ms\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembagian Kerja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar Pembelajaran Mesin 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persiapan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal pertama yang kami lakukan adalah menggunakan data latih Weather Categorization dari WEKA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temperature  humidity  windy play\n",
       "0      sunny           85        85  False   no\n",
       "1      sunny           80        90   True   no\n",
       "2   overcast           83        86  False  yes\n",
       "3      rainy           70        96  False  yes\n",
       "4      rainy           68        80  False  yes\n",
       "5      rainy           65        70   True   no\n",
       "6   overcast           64        65   True  yes\n",
       "7      sunny           72        95  False   no\n",
       "8      sunny           69        70  False  yes\n",
       "9      rainy           75        80  False  yes\n",
       "10     sunny           75        70   True  yes\n",
       "11  overcast           72        90   True  yes\n",
       "12  overcast           81        75  False  yes\n",
       "13     rainy           71        91   True   no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('dataset/weather.csv')\n",
    "\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat data latih terdiri dari data numerik dan data kategorikal. Diperlukan preprocessing dengan kakas scikit-learn yaitu LabelEncoder sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "weather_df['outlook'] = label_encoder.fit_transform(weather_df.outlook)\n",
    "weather_df['windy'] = label_encoder.fit_transform(weather_df.windy)\n",
    "weather_df['play'] = label_encoder.fit_transform(weather_df.play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0         2           85        85      0     0\n",
       "1         2           80        90      1     0\n",
       "2         0           83        86      0     1\n",
       "3         1           70        96      0     1\n",
       "4         1           68        80      0     1\n",
       "5         1           65        70      1     0\n",
       "6         0           64        65      1     1\n",
       "7         2           72        95      0     0\n",
       "8         2           69        70      0     1\n",
       "9         1           75        80      0     1\n",
       "10        2           75        70      1     1\n",
       "11        0           72        90      1     1\n",
       "12        0           81        75      0     1\n",
       "13        1           71        91      1     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1],\n",
       "       [ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weather = weather_df.iloc[:,:4].values\n",
    "X_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_weather = weather_df.play.values\n",
    "y_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian, setelah kami menjadikan data latih tersebut numerik, kami melakukan pemisahan sebagian data latih (10%) menjadi data uji dengan proporsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_weather, y_weather, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 85, 85,  0],\n",
       "       [ 2, 80, 90,  1],\n",
       "       [ 0, 83, 86,  0],\n",
       "       [ 1, 70, 96,  0],\n",
       "       [ 1, 68, 80,  0],\n",
       "       [ 1, 65, 70,  1],\n",
       "       [ 0, 64, 65,  1],\n",
       "       [ 2, 72, 95,  0],\n",
       "       [ 2, 69, 70,  0],\n",
       "       [ 1, 75, 80,  0],\n",
       "       [ 2, 75, 70,  1],\n",
       "       [ 0, 72, 90,  1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 81, 75,  0],\n",
       "       [ 1, 71, 91,  1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorasi Keras (1.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembelajaran akan menggunakan kakas keras dengan model <i>sequential</i> dan lapisan <i>dense</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan memakai input layer sebanyak 1 neuron dengan bentuk input 4 sesuai jumlah attribute data latih, kemudian dengan 3 hidden layer masing-masing 2 neuron kemudian 3 neuron, dan 4 neuron dan 1 output layer dengan 1 neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = Sequential()\n",
    "network1.add(Dense(1, activation='sigmoid', input_shape=(4,)))\n",
    "network1.add(Dense(2, activation='sigmoid'))\n",
    "network1.add(Dense(3, activation='sigmoid'))\n",
    "network1.add(Dense(4, activation='sigmoid'))\n",
    "network1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer yang dipakai adalah Adam (Adaptive Moment Estimation), dengan perhitungan loss dengan Mean Squared Error, dan Metrics Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah summary dari model yang akan dipakai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah eksperimen yang dilakukan dengan batch = 1 dan sesuai jumlah data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Batch = 1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3832 - acc: 0.4000 - val_loss: 0.5991 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3782 - acc: 0.4000 - val_loss: 0.5929 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3749 - acc: 0.4000 - val_loss: 0.5853 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3718 - acc: 0.4000 - val_loss: 0.5769 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3676 - acc: 0.4000 - val_loss: 0.5695 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3643 - acc: 0.4000 - val_loss: 0.5616 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3605 - acc: 0.4000 - val_loss: 0.5544 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3570 - acc: 0.4000 - val_loss: 0.5473 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3547 - acc: 0.4000 - val_loss: 0.5384 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3500 - acc: 0.4000 - val_loss: 0.5319 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3473 - acc: 0.4000 - val_loss: 0.5242 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3443 - acc: 0.4000 - val_loss: 0.5161 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3403 - acc: 0.4000 - val_loss: 0.5096 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3369 - acc: 0.4000 - val_loss: 0.5040 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3351 - acc: 0.4000 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3308 - acc: 0.4000 - val_loss: 0.4898 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3282 - acc: 0.4000 - val_loss: 0.4833 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 976us/step - loss: 0.3258 - acc: 0.4000 - val_loss: 0.4759 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3229 - acc: 0.4000 - val_loss: 0.4683 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3196 - acc: 0.4000 - val_loss: 0.4618 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3174 - acc: 0.4000 - val_loss: 0.4545 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3148 - acc: 0.4000 - val_loss: 0.4475 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3115 - acc: 0.4000 - val_loss: 0.4419 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3090 - acc: 0.4000 - val_loss: 0.4366 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3072 - acc: 0.4000 - val_loss: 0.4298 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3049 - acc: 0.4000 - val_loss: 0.4229 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.4000 - val_loss: 0.4178 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.4000 - val_loss: 0.4125 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 934us/step - loss: 0.2977 - acc: 0.4000 - val_loss: 0.4067 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2956 - acc: 0.4000 - val_loss: 0.4012 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2940 - acc: 0.4000 - val_loss: 0.3949 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2918 - acc: 0.4000 - val_loss: 0.3893 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2894 - acc: 0.4000 - val_loss: 0.3860 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2881 - acc: 0.4000 - val_loss: 0.3802 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2861 - acc: 0.4000 - val_loss: 0.3750 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2841 - acc: 0.4000 - val_loss: 0.3711 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 969us/step - loss: 0.2827 - acc: 0.4000 - val_loss: 0.3661 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2813 - acc: 0.4000 - val_loss: 0.3605 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2799 - acc: 0.4000 - val_loss: 0.3550 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2779 - acc: 0.4000 - val_loss: 0.3506 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2765 - acc: 0.4000 - val_loss: 0.3464 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2749 - acc: 0.4000 - val_loss: 0.3433 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2737 - acc: 0.4000 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 982us/step - loss: 0.2727 - acc: 0.4000 - val_loss: 0.3351 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 949us/step - loss: 0.2714 - acc: 0.4000 - val_loss: 0.3309 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2704 - acc: 0.4000 - val_loss: 0.3262 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2687 - acc: 0.4000 - val_loss: 0.3231 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2678 - acc: 0.4000 - val_loss: 0.3199 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.4000 - val_loss: 0.3146 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2657 - acc: 0.4000 - val_loss: 0.3112 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2645 - acc: 0.4000 - val_loss: 0.3089 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2640 - acc: 0.4000 - val_loss: 0.3049 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2629 - acc: 0.4000 - val_loss: 0.3016 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2620 - acc: 0.4000 - val_loss: 0.2983 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2620 - acc: 0.4000 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.2601 - acc: 0.4000 - val_loss: 0.2929 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2599 - acc: 0.4000 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2587 - acc: 0.4000 - val_loss: 0.2866 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2581 - acc: 0.4000 - val_loss: 0.2840 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2573 - acc: 0.4000 - val_loss: 0.2821 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2570 - acc: 0.4000 - val_loss: 0.2786 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.2567 - acc: 0.4000 - val_loss: 0.2748 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2554 - acc: 0.4000 - val_loss: 0.2725 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2547 - acc: 0.4000 - val_loss: 0.2711 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.2544 - acc: 0.4000 - val_loss: 0.2685 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2541 - acc: 0.4000 - val_loss: 0.2654 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2531 - acc: 0.4000 - val_loss: 0.2642 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 939us/step - loss: 0.2527 - acc: 0.4000 - val_loss: 0.2623 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2523 - acc: 0.4000 - val_loss: 0.2601 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 952us/step - loss: 0.2519 - acc: 0.4000 - val_loss: 0.2581 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2524 - acc: 0.4000 - val_loss: 0.2541 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2508 - acc: 0.4000 - val_loss: 0.2534 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2506 - acc: 0.4000 - val_loss: 0.2524 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2503 - acc: 0.4000 - val_loss: 0.2499 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2502 - acc: 0.6000 - val_loss: 0.2469 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2493 - acc: 0.6000 - val_loss: 0.2458 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2491 - acc: 0.6000 - val_loss: 0.2443 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2487 - acc: 0.6000 - val_loss: 0.2428 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2485 - acc: 0.6000 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2482 - acc: 0.6000 - val_loss: 0.2397 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2479 - acc: 0.6000 - val_loss: 0.2375 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2475 - acc: 0.6000 - val_loss: 0.2358 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2474 - acc: 0.6000 - val_loss: 0.2336 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2469 - acc: 0.6000 - val_loss: 0.2330 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2468 - acc: 0.6000 - val_loss: 0.2310 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2465 - acc: 0.6000 - val_loss: 0.2296 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.6000 - val_loss: 0.2287 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2460 - acc: 0.6000 - val_loss: 0.2271 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 968us/step - loss: 0.2460 - acc: 0.6000 - val_loss: 0.2248 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - acc: 0.6000 - val_loss: 0.2235 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2455 - acc: 0.6000 - val_loss: 0.2236 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2456 - acc: 0.6000 - val_loss: 0.2211 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2191 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2182 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2177 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2167 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2443 - acc: 0.6000 - val_loss: 0.2159 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2152 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2139 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 946us/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2118 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2111 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2104 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2093 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2083 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2079 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2061 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.2039 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2046 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 958us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2041 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2024 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 969us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2019 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2004 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 884us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.1996 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1990 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 973us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.1979 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1970 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1967 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1963 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1958 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1945 - val_acc: 1.0000\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1934 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1917 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1914 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1895 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1884 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1879 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1876 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1865 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1865 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1863 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1859 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1855 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 918us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1848 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1837 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1825 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1828 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1824 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1815 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1820 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1810 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1806 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1807 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1803 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1798 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1794 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1788 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.6000 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1778 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1766 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1762 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1753 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 904us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1759 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 884us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1751 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1735 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1733 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1724 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1730 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1724 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1721 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 980us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 967us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1687 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1677 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1674 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1665 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1655 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1656 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 971us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1646 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1644 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 912us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1631 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1637 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1636 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1632 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1630 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1627 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1621 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 942us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1612 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 963us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 911us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 925us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1617 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 947us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1616 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 366/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 983us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 932us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1607 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 932us/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1592 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 956us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 986us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 891us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1604 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 990us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1593 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 918us/step - loss: 0.2405 - acc: 0.6000 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1605 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1598 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2402 - acc: 0.6000 - val_loss: 0.1596 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6000 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1601 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.6000 - val_loss: 0.1600 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history1 = network1.fit(X_train, y_train, epochs=500, verbose=1, batch_size=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "Loss: 25.99998190999031%\n",
      "Accuracy: 50.0%\n",
      "Time: 6.6286375522613525 s\n"
     ]
    }
   ],
   "source": [
    "score1 = network1.evaluate(X_test, y_test, batch_size=1)\n",
    "\n",
    "print(\"Loss: \" + str(score1[0]*100.0) + \"%\")\n",
    "print(\"Accuracy: \" + str(score1[1]*100.0) + \"%\")\n",
    "print(\"Time: \" + str(end) +\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Batch Size = Jumlah Data Latih</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinitialisasi model untuk eksperimen kedua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Sequential()\n",
    "network2.add(Dense(1, activation='sigmoid', input_shape=(4,)))\n",
    "network2.add(Dense(2, activation='sigmoid'))\n",
    "network2.add(Dense(3, activation='sigmoid'))\n",
    "network2.add(Dense(4, activation='sigmoid'))\n",
    "network2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 4         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.3458 - acc: 0.4000 - val_loss: 0.5248 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.3453 - acc: 0.4000 - val_loss: 0.5238 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.3448 - acc: 0.4000 - val_loss: 0.5225 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.3442 - acc: 0.4000 - val_loss: 0.5214 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 261us/step - loss: 0.3437 - acc: 0.4000 - val_loss: 0.5201 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 346us/step - loss: 0.3432 - acc: 0.4000 - val_loss: 0.5189 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.3426 - acc: 0.4000 - val_loss: 0.5177 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.3421 - acc: 0.4000 - val_loss: 0.5164 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.3415 - acc: 0.4000 - val_loss: 0.5152 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.3410 - acc: 0.4000 - val_loss: 0.5140 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.3404 - acc: 0.4000 - val_loss: 0.5127 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.3399 - acc: 0.4000 - val_loss: 0.5115 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 323us/step - loss: 0.3393 - acc: 0.4000 - val_loss: 0.5102 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.3388 - acc: 0.4000 - val_loss: 0.5090 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.3382 - acc: 0.4000 - val_loss: 0.5078 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.3377 - acc: 0.4000 - val_loss: 0.5065 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.3372 - acc: 0.4000 - val_loss: 0.5053 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.3366 - acc: 0.4000 - val_loss: 0.5040 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.3361 - acc: 0.4000 - val_loss: 0.5028 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 331us/step - loss: 0.3355 - acc: 0.4000 - val_loss: 0.5016 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 380us/step - loss: 0.3350 - acc: 0.4000 - val_loss: 0.5003 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.3345 - acc: 0.4000 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.3339 - acc: 0.4000 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.3334 - acc: 0.4000 - val_loss: 0.4966 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.3329 - acc: 0.4000 - val_loss: 0.4954 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 320us/step - loss: 0.3323 - acc: 0.4000 - val_loss: 0.4941 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 281us/step - loss: 0.3318 - acc: 0.4000 - val_loss: 0.4929 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.3313 - acc: 0.4000 - val_loss: 0.4917 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.3307 - acc: 0.4000 - val_loss: 0.4905 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.3302 - acc: 0.4000 - val_loss: 0.4892 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.3297 - acc: 0.4000 - val_loss: 0.4880 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.3291 - acc: 0.4000 - val_loss: 0.4868 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.3286 - acc: 0.4000 - val_loss: 0.4855 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.3281 - acc: 0.4000 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.3276 - acc: 0.4000 - val_loss: 0.4831 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.3270 - acc: 0.4000 - val_loss: 0.4819 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.3265 - acc: 0.4000 - val_loss: 0.4806 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.3260 - acc: 0.4000 - val_loss: 0.4794 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.3255 - acc: 0.4000 - val_loss: 0.4782 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 158us/step - loss: 0.3250 - acc: 0.4000 - val_loss: 0.4770 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.3245 - acc: 0.4000 - val_loss: 0.4757 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.3240 - acc: 0.4000 - val_loss: 0.4745 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.3234 - acc: 0.4000 - val_loss: 0.4733 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.3229 - acc: 0.4000 - val_loss: 0.4721 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3224 - acc: 0.4000 - val_loss: 0.4709 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.3219 - acc: 0.4000 - val_loss: 0.4697 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.3214 - acc: 0.4000 - val_loss: 0.4685 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.3209 - acc: 0.4000 - val_loss: 0.4673 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.3204 - acc: 0.4000 - val_loss: 0.4660 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.3199 - acc: 0.4000 - val_loss: 0.4648 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3194 - acc: 0.4000 - val_loss: 0.4636 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.3189 - acc: 0.4000 - val_loss: 0.4624 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.3184 - acc: 0.4000 - val_loss: 0.4612 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.3179 - acc: 0.4000 - val_loss: 0.4600 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3174 - acc: 0.4000 - val_loss: 0.4588 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.3169 - acc: 0.4000 - val_loss: 0.4576 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.3164 - acc: 0.4000 - val_loss: 0.4564 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.3159 - acc: 0.4000 - val_loss: 0.4552 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.3155 - acc: 0.4000 - val_loss: 0.4540 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.3150 - acc: 0.4000 - val_loss: 0.4528 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.3145 - acc: 0.4000 - val_loss: 0.4516 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.3140 - acc: 0.4000 - val_loss: 0.4504 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.3135 - acc: 0.4000 - val_loss: 0.4493 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.3130 - acc: 0.4000 - val_loss: 0.4481 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.3126 - acc: 0.4000 - val_loss: 0.4469 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.3121 - acc: 0.4000 - val_loss: 0.4457 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.3116 - acc: 0.4000 - val_loss: 0.4445 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.3111 - acc: 0.4000 - val_loss: 0.4433 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.3107 - acc: 0.4000 - val_loss: 0.4422 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3102 - acc: 0.4000 - val_loss: 0.4410 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.3097 - acc: 0.4000 - val_loss: 0.4398 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.3093 - acc: 0.4000 - val_loss: 0.4386 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.3088 - acc: 0.4000 - val_loss: 0.4375 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.3083 - acc: 0.4000 - val_loss: 0.4363 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.3079 - acc: 0.4000 - val_loss: 0.4351 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.3074 - acc: 0.4000 - val_loss: 0.4340 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.3070 - acc: 0.4000 - val_loss: 0.4328 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.3065 - acc: 0.4000 - val_loss: 0.4316 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.3060 - acc: 0.4000 - val_loss: 0.4305 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.3056 - acc: 0.4000 - val_loss: 0.4293 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.3051 - acc: 0.4000 - val_loss: 0.4282 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.3047 - acc: 0.4000 - val_loss: 0.4270 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 130us/step - loss: 0.3042 - acc: 0.4000 - val_loss: 0.4259 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.3038 - acc: 0.4000 - val_loss: 0.4247 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.3033 - acc: 0.4000 - val_loss: 0.4236 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.3029 - acc: 0.4000 - val_loss: 0.4224 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.3025 - acc: 0.4000 - val_loss: 0.4213 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.3020 - acc: 0.4000 - val_loss: 0.4201 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.3016 - acc: 0.4000 - val_loss: 0.4190 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.3012 - acc: 0.4000 - val_loss: 0.4179 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.3007 - acc: 0.4000 - val_loss: 0.4167 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 318us/step - loss: 0.3003 - acc: 0.4000 - val_loss: 0.4156 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 246us/step - loss: 0.2999 - acc: 0.4000 - val_loss: 0.4145 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2994 - acc: 0.4000 - val_loss: 0.4133 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 202us/step - loss: 0.2990 - acc: 0.4000 - val_loss: 0.4122 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2986 - acc: 0.4000 - val_loss: 0.4111 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2982 - acc: 0.4000 - val_loss: 0.4100 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2977 - acc: 0.4000 - val_loss: 0.4088 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2973 - acc: 0.4000 - val_loss: 0.4077 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 225us/step - loss: 0.2969 - acc: 0.4000 - val_loss: 0.4066 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2965 - acc: 0.4000 - val_loss: 0.4055 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2961 - acc: 0.4000 - val_loss: 0.4044 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2957 - acc: 0.4000 - val_loss: 0.4033 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2952 - acc: 0.4000 - val_loss: 0.4022 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2948 - acc: 0.4000 - val_loss: 0.4011 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2944 - acc: 0.4000 - val_loss: 0.4000 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2940 - acc: 0.4000 - val_loss: 0.3989 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 266us/step - loss: 0.2936 - acc: 0.4000 - val_loss: 0.3978 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2932 - acc: 0.4000 - val_loss: 0.3967 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2928 - acc: 0.4000 - val_loss: 0.3956 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 211us/step - loss: 0.2924 - acc: 0.4000 - val_loss: 0.3945 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2920 - acc: 0.4000 - val_loss: 0.3934 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2916 - acc: 0.4000 - val_loss: 0.3924 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2913 - acc: 0.4000 - val_loss: 0.3913 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 260us/step - loss: 0.2909 - acc: 0.4000 - val_loss: 0.3902 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 238us/step - loss: 0.2905 - acc: 0.4000 - val_loss: 0.3891 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2901 - acc: 0.4000 - val_loss: 0.3881 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2897 - acc: 0.4000 - val_loss: 0.3870 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2893 - acc: 0.4000 - val_loss: 0.3859 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2889 - acc: 0.4000 - val_loss: 0.3849 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2886 - acc: 0.4000 - val_loss: 0.3838 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2882 - acc: 0.4000 - val_loss: 0.3828 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2878 - acc: 0.4000 - val_loss: 0.3817 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2874 - acc: 0.4000 - val_loss: 0.3806 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2871 - acc: 0.4000 - val_loss: 0.3796 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 140us/step - loss: 0.2867 - acc: 0.4000 - val_loss: 0.3786 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2863 - acc: 0.4000 - val_loss: 0.3775 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2860 - acc: 0.4000 - val_loss: 0.3765 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2856 - acc: 0.4000 - val_loss: 0.3754 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2853 - acc: 0.4000 - val_loss: 0.3744 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2849 - acc: 0.4000 - val_loss: 0.3734 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2845 - acc: 0.4000 - val_loss: 0.3723 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2842 - acc: 0.4000 - val_loss: 0.3713 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2838 - acc: 0.4000 - val_loss: 0.3703 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 128us/step - loss: 0.2835 - acc: 0.4000 - val_loss: 0.3693 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2831 - acc: 0.4000 - val_loss: 0.3683 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 290us/step - loss: 0.2828 - acc: 0.4000 - val_loss: 0.3672 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2824 - acc: 0.4000 - val_loss: 0.3662 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2821 - acc: 0.4000 - val_loss: 0.3652 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2818 - acc: 0.4000 - val_loss: 0.3642 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2814 - acc: 0.4000 - val_loss: 0.3632 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2811 - acc: 0.4000 - val_loss: 0.3622 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 309us/step - loss: 0.2807 - acc: 0.4000 - val_loss: 0.3612 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2804 - acc: 0.4000 - val_loss: 0.3602 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2801 - acc: 0.4000 - val_loss: 0.3592 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2797 - acc: 0.4000 - val_loss: 0.3583 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2794 - acc: 0.4000 - val_loss: 0.3573 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2791 - acc: 0.4000 - val_loss: 0.3563 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2788 - acc: 0.4000 - val_loss: 0.3553 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2784 - acc: 0.4000 - val_loss: 0.3543 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2781 - acc: 0.4000 - val_loss: 0.3534 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2778 - acc: 0.4000 - val_loss: 0.3524 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2775 - acc: 0.4000 - val_loss: 0.3514 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2772 - acc: 0.4000 - val_loss: 0.3505 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2769 - acc: 0.4000 - val_loss: 0.3495 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2766 - acc: 0.4000 - val_loss: 0.3486 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2762 - acc: 0.4000 - val_loss: 0.3476 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2759 - acc: 0.4000 - val_loss: 0.3467 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2756 - acc: 0.4000 - val_loss: 0.3457 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2753 - acc: 0.4000 - val_loss: 0.3448 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2750 - acc: 0.4000 - val_loss: 0.3438 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2747 - acc: 0.4000 - val_loss: 0.3429 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2744 - acc: 0.4000 - val_loss: 0.3419 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2741 - acc: 0.4000 - val_loss: 0.3410 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 319us/step - loss: 0.2738 - acc: 0.4000 - val_loss: 0.3401 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 322us/step - loss: 0.2736 - acc: 0.4000 - val_loss: 0.3392 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 246us/step - loss: 0.2733 - acc: 0.4000 - val_loss: 0.3382 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 254us/step - loss: 0.2730 - acc: 0.4000 - val_loss: 0.3373 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2727 - acc: 0.4000 - val_loss: 0.3364 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2724 - acc: 0.4000 - val_loss: 0.3355 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2721 - acc: 0.4000 - val_loss: 0.3346 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2718 - acc: 0.4000 - val_loss: 0.3337 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2716 - acc: 0.4000 - val_loss: 0.3328 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2713 - acc: 0.4000 - val_loss: 0.3319 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2710 - acc: 0.4000 - val_loss: 0.3310 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2707 - acc: 0.4000 - val_loss: 0.3301 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2705 - acc: 0.4000 - val_loss: 0.3292 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2702 - acc: 0.4000 - val_loss: 0.3283 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2699 - acc: 0.4000 - val_loss: 0.3275 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2697 - acc: 0.4000 - val_loss: 0.3266 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 344us/step - loss: 0.2694 - acc: 0.4000 - val_loss: 0.3257 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 295us/step - loss: 0.2691 - acc: 0.4000 - val_loss: 0.3248 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 299us/step - loss: 0.2689 - acc: 0.4000 - val_loss: 0.3240 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 311us/step - loss: 0.2686 - acc: 0.4000 - val_loss: 0.3231 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 344us/step - loss: 0.2684 - acc: 0.4000 - val_loss: 0.3222 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 267us/step - loss: 0.2681 - acc: 0.4000 - val_loss: 0.3214 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2679 - acc: 0.4000 - val_loss: 0.3205 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2676 - acc: 0.4000 - val_loss: 0.3197 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2674 - acc: 0.4000 - val_loss: 0.3188 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2671 - acc: 0.4000 - val_loss: 0.3180 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2669 - acc: 0.4000 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2666 - acc: 0.4000 - val_loss: 0.3163 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 397us/step - loss: 0.2664 - acc: 0.4000 - val_loss: 0.3155 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 299us/step - loss: 0.2661 - acc: 0.4000 - val_loss: 0.3146 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 420us/step - loss: 0.2659 - acc: 0.4000 - val_loss: 0.3138 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 350us/step - loss: 0.2657 - acc: 0.4000 - val_loss: 0.3130 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2654 - acc: 0.4000 - val_loss: 0.3121 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2652 - acc: 0.4000 - val_loss: 0.3113 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2650 - acc: 0.4000 - val_loss: 0.3105 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2647 - acc: 0.4000 - val_loss: 0.3097 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 141us/step - loss: 0.2645 - acc: 0.4000 - val_loss: 0.3089 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 475us/step - loss: 0.2643 - acc: 0.4000 - val_loss: 0.3081 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 263us/step - loss: 0.2640 - acc: 0.4000 - val_loss: 0.3073 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2638 - acc: 0.4000 - val_loss: 0.3065 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2636 - acc: 0.4000 - val_loss: 0.3057 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2634 - acc: 0.4000 - val_loss: 0.3049 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2632 - acc: 0.4000 - val_loss: 0.3041 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2629 - acc: 0.4000 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 154us/step - loss: 0.2627 - acc: 0.4000 - val_loss: 0.3025 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2625 - acc: 0.4000 - val_loss: 0.3018 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2623 - acc: 0.4000 - val_loss: 0.3010 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 328us/step - loss: 0.2621 - acc: 0.4000 - val_loss: 0.3002 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 311us/step - loss: 0.2619 - acc: 0.4000 - val_loss: 0.2994 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2617 - acc: 0.4000 - val_loss: 0.2987 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2615 - acc: 0.4000 - val_loss: 0.2979 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2613 - acc: 0.4000 - val_loss: 0.2971 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2611 - acc: 0.4000 - val_loss: 0.2964 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2609 - acc: 0.4000 - val_loss: 0.2956 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2607 - acc: 0.4000 - val_loss: 0.2949 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 147us/step - loss: 0.2605 - acc: 0.4000 - val_loss: 0.2941 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2603 - acc: 0.4000 - val_loss: 0.2934 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2601 - acc: 0.4000 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2599 - acc: 0.4000 - val_loss: 0.2919 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 346us/step - loss: 0.2597 - acc: 0.4000 - val_loss: 0.2912 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 230us/step - loss: 0.2595 - acc: 0.4000 - val_loss: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2593 - acc: 0.4000 - val_loss: 0.2897 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 293us/step - loss: 0.2591 - acc: 0.4000 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2589 - acc: 0.4000 - val_loss: 0.2883 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2587 - acc: 0.4000 - val_loss: 0.2876 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2586 - acc: 0.4000 - val_loss: 0.2868 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2584 - acc: 0.4000 - val_loss: 0.2861 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2582 - acc: 0.4000 - val_loss: 0.2854 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 276us/step - loss: 0.2580 - acc: 0.4000 - val_loss: 0.2847 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2578 - acc: 0.4000 - val_loss: 0.2840 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 308us/step - loss: 0.2577 - acc: 0.4000 - val_loss: 0.2833 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 287us/step - loss: 0.2575 - acc: 0.4000 - val_loss: 0.2826 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2573 - acc: 0.4000 - val_loss: 0.2819 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2572 - acc: 0.4000 - val_loss: 0.2812 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2570 - acc: 0.4000 - val_loss: 0.2805 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2568 - acc: 0.4000 - val_loss: 0.2799 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 291us/step - loss: 0.2566 - acc: 0.4000 - val_loss: 0.2792 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 242us/step - loss: 0.2565 - acc: 0.4000 - val_loss: 0.2785 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2563 - acc: 0.4000 - val_loss: 0.2778 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2562 - acc: 0.4000 - val_loss: 0.2772 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 204us/step - loss: 0.2560 - acc: 0.4000 - val_loss: 0.2765 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2558 - acc: 0.4000 - val_loss: 0.2758 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2557 - acc: 0.4000 - val_loss: 0.2752 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2555 - acc: 0.4000 - val_loss: 0.2745 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2554 - acc: 0.4000 - val_loss: 0.2739 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2552 - acc: 0.4000 - val_loss: 0.2732 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2551 - acc: 0.4000 - val_loss: 0.2725 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 231us/step - loss: 0.2549 - acc: 0.4000 - val_loss: 0.2719 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2547 - acc: 0.4000 - val_loss: 0.2713 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 172us/step - loss: 0.2546 - acc: 0.4000 - val_loss: 0.2706 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2545 - acc: 0.4000 - val_loss: 0.2700 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2543 - acc: 0.4000 - val_loss: 0.2693 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 201us/step - loss: 0.2542 - acc: 0.4000 - val_loss: 0.2687 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2540 - acc: 0.4000 - val_loss: 0.2681 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 310us/step - loss: 0.2539 - acc: 0.4000 - val_loss: 0.2675 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2537 - acc: 0.4000 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2536 - acc: 0.4000 - val_loss: 0.2662 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2534 - acc: 0.4000 - val_loss: 0.2656 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2533 - acc: 0.4000 - val_loss: 0.2650 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2532 - acc: 0.4000 - val_loss: 0.2644 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2530 - acc: 0.4000 - val_loss: 0.2638 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2529 - acc: 0.4000 - val_loss: 0.2632 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2528 - acc: 0.4000 - val_loss: 0.2626 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2526 - acc: 0.4000 - val_loss: 0.2620 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 206us/step - loss: 0.2525 - acc: 0.4000 - val_loss: 0.2614 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 267us/step - loss: 0.2524 - acc: 0.4000 - val_loss: 0.2608 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 250us/step - loss: 0.2522 - acc: 0.4000 - val_loss: 0.2602 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2521 - acc: 0.4000 - val_loss: 0.2596 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2520 - acc: 0.4000 - val_loss: 0.2590 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 261us/step - loss: 0.2519 - acc: 0.4000 - val_loss: 0.2584 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 240us/step - loss: 0.2517 - acc: 0.4000 - val_loss: 0.2579 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 256us/step - loss: 0.2516 - acc: 0.4000 - val_loss: 0.2573 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2515 - acc: 0.4000 - val_loss: 0.2567 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 242us/step - loss: 0.2514 - acc: 0.4000 - val_loss: 0.2561 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 413us/step - loss: 0.2513 - acc: 0.4000 - val_loss: 0.2556 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2511 - acc: 0.4000 - val_loss: 0.2550 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 344us/step - loss: 0.2510 - acc: 0.4000 - val_loss: 0.2545 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2509 - acc: 0.4000 - val_loss: 0.2539 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 342us/step - loss: 0.2508 - acc: 0.4000 - val_loss: 0.2533 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 220us/step - loss: 0.2507 - acc: 0.4000 - val_loss: 0.2528 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2506 - acc: 0.4000 - val_loss: 0.2522 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2505 - acc: 0.4000 - val_loss: 0.2517 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2503 - acc: 0.4000 - val_loss: 0.2512 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 299us/step - loss: 0.2502 - acc: 0.4000 - val_loss: 0.2506 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2501 - acc: 0.4000 - val_loss: 0.2501 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2500 - acc: 0.4000 - val_loss: 0.2495 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2499 - acc: 0.6000 - val_loss: 0.2490 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2498 - acc: 0.6000 - val_loss: 0.2485 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2497 - acc: 0.6000 - val_loss: 0.2479 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2496 - acc: 0.6000 - val_loss: 0.2474 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2495 - acc: 0.6000 - val_loss: 0.2469 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2494 - acc: 0.6000 - val_loss: 0.2464 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2493 - acc: 0.6000 - val_loss: 0.2459 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 272us/step - loss: 0.2492 - acc: 0.6000 - val_loss: 0.2453 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 760us/step - loss: 0.2491 - acc: 0.6000 - val_loss: 0.2448 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 228us/step - loss: 0.2490 - acc: 0.6000 - val_loss: 0.2443 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2489 - acc: 0.6000 - val_loss: 0.2438 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2488 - acc: 0.6000 - val_loss: 0.2433 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2487 - acc: 0.6000 - val_loss: 0.2428 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2486 - acc: 0.6000 - val_loss: 0.2423 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2485 - acc: 0.6000 - val_loss: 0.2418 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2484 - acc: 0.6000 - val_loss: 0.2413 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2483 - acc: 0.6000 - val_loss: 0.2408 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 251us/step - loss: 0.2482 - acc: 0.6000 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2481 - acc: 0.6000 - val_loss: 0.2399 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2481 - acc: 0.6000 - val_loss: 0.2394 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2480 - acc: 0.6000 - val_loss: 0.2389 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2479 - acc: 0.6000 - val_loss: 0.2384 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 151us/step - loss: 0.2478 - acc: 0.6000 - val_loss: 0.2379 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2477 - acc: 0.6000 - val_loss: 0.2375 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2476 - acc: 0.6000 - val_loss: 0.2370 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2475 - acc: 0.6000 - val_loss: 0.2365 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2475 - acc: 0.6000 - val_loss: 0.2361 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2474 - acc: 0.6000 - val_loss: 0.2356 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2473 - acc: 0.6000 - val_loss: 0.2351 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2472 - acc: 0.6000 - val_loss: 0.2347 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2471 - acc: 0.6000 - val_loss: 0.2342 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2470 - acc: 0.6000 - val_loss: 0.2338 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2470 - acc: 0.6000 - val_loss: 0.2333 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2469 - acc: 0.6000 - val_loss: 0.2329 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2468 - acc: 0.6000 - val_loss: 0.2324 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 148us/step - loss: 0.2467 - acc: 0.6000 - val_loss: 0.2320 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2467 - acc: 0.6000 - val_loss: 0.2315 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2466 - acc: 0.6000 - val_loss: 0.2311 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 183us/step - loss: 0.2465 - acc: 0.6000 - val_loss: 0.2307 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 258us/step - loss: 0.2464 - acc: 0.6000 - val_loss: 0.2302 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 239us/step - loss: 0.2464 - acc: 0.6000 - val_loss: 0.2298 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2463 - acc: 0.6000 - val_loss: 0.2294 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2462 - acc: 0.6000 - val_loss: 0.2289 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2462 - acc: 0.6000 - val_loss: 0.2285 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2461 - acc: 0.6000 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 168us/step - loss: 0.2460 - acc: 0.6000 - val_loss: 0.2277 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 313us/step - loss: 0.2459 - acc: 0.6000 - val_loss: 0.2272 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 198us/step - loss: 0.2459 - acc: 0.6000 - val_loss: 0.2268 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2458 - acc: 0.6000 - val_loss: 0.2264 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 171us/step - loss: 0.2457 - acc: 0.6000 - val_loss: 0.2260 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2457 - acc: 0.6000 - val_loss: 0.2256 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 157us/step - loss: 0.2456 - acc: 0.6000 - val_loss: 0.2252 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2456 - acc: 0.6000 - val_loss: 0.2248 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.2455 - acc: 0.6000 - val_loss: 0.2244 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2454 - acc: 0.6000 - val_loss: 0.2240 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2454 - acc: 0.6000 - val_loss: 0.2236 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2453 - acc: 0.6000 - val_loss: 0.2232 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2452 - acc: 0.6000 - val_loss: 0.2228 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2452 - acc: 0.6000 - val_loss: 0.2224 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 210us/step - loss: 0.2451 - acc: 0.6000 - val_loss: 0.2220 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2451 - acc: 0.6000 - val_loss: 0.2216 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 328us/step - loss: 0.2450 - acc: 0.6000 - val_loss: 0.2212 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 213us/step - loss: 0.2449 - acc: 0.6000 - val_loss: 0.2208 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2449 - acc: 0.6000 - val_loss: 0.2205 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 163us/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2201 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2448 - acc: 0.6000 - val_loss: 0.2197 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 152us/step - loss: 0.2447 - acc: 0.6000 - val_loss: 0.2193 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 237us/step - loss: 0.2447 - acc: 0.6000 - val_loss: 0.2190 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2186 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2446 - acc: 0.6000 - val_loss: 0.2182 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 305us/step - loss: 0.2445 - acc: 0.6000 - val_loss: 0.2178 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2445 - acc: 0.6000 - val_loss: 0.2175 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 167us/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2171 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2444 - acc: 0.6000 - val_loss: 0.2168 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2443 - acc: 0.6000 - val_loss: 0.2164 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2160 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 176us/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2157 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2442 - acc: 0.6000 - val_loss: 0.2153 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 252us/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2150 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.2441 - acc: 0.6000 - val_loss: 0.2146 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 316us/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2143 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2440 - acc: 0.6000 - val_loss: 0.2139 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2136 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2439 - acc: 0.6000 - val_loss: 0.2133 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2438 - acc: 0.6000 - val_loss: 0.2129 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2438 - acc: 0.6000 - val_loss: 0.2126 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2437 - acc: 0.6000 - val_loss: 0.2122 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2437 - acc: 0.6000 - val_loss: 0.2119 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 249us/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2116 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 279us/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2113 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 255us/step - loss: 0.2436 - acc: 0.6000 - val_loss: 0.2109 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2106 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 241us/step - loss: 0.2435 - acc: 0.6000 - val_loss: 0.2103 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 215us/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2100 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2434 - acc: 0.6000 - val_loss: 0.2096 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 342us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2093 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 217us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2090 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2433 - acc: 0.6000 - val_loss: 0.2087 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 150us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2084 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 145us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2081 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2432 - acc: 0.6000 - val_loss: 0.2077 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.2074 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2431 - acc: 0.6000 - val_loss: 0.2071 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 165us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2068 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2065 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 143us/step - loss: 0.2430 - acc: 0.6000 - val_loss: 0.2062 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2059 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 349us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2056 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2429 - acc: 0.6000 - val_loss: 0.2053 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2050 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2047 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2428 - acc: 0.6000 - val_loss: 0.2045 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 236us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2042 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 190us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2039 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 522us/step - loss: 0.2427 - acc: 0.6000 - val_loss: 0.2036 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 144us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2033 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 136us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2030 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2426 - acc: 0.6000 - val_loss: 0.2027 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2025 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2022 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2425 - acc: 0.6000 - val_loss: 0.2019 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 225us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2016 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 182us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2014 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 187us/step - loss: 0.2424 - acc: 0.6000 - val_loss: 0.2011 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2008 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 164us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2006 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2003 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 159us/step - loss: 0.2423 - acc: 0.6000 - val_loss: 0.2000 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 156us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1998 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 221us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1995 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 161us/step - loss: 0.2422 - acc: 0.6000 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1990 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 226us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1987 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 173us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1985 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 139us/step - loss: 0.2421 - acc: 0.6000 - val_loss: 0.1982 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 155us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1980 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1977 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 160us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1975 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2420 - acc: 0.6000 - val_loss: 0.1972 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 242us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1970 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 261us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1967 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1965 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2419 - acc: 0.6000 - val_loss: 0.1962 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1960 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1958 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1955 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 208us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 179us/step - loss: 0.2418 - acc: 0.6000 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1948 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 207us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1946 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 177us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1943 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 209us/step - loss: 0.2417 - acc: 0.6000 - val_loss: 0.1941 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1939 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 284us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 184us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1934 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 166us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1932 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2416 - acc: 0.6000 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1928 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1925 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 196us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 268us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1921 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 235us/step - loss: 0.2415 - acc: 0.6000 - val_loss: 0.1919 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 174us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1917 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 170us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1915 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1913 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 671us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1910 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 197us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1908 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 218us/step - loss: 0.2414 - acc: 0.6000 - val_loss: 0.1906 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 199us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1904 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 191us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1902 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 244us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 216us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1898 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 227us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1896 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 180us/step - loss: 0.2413 - acc: 0.6000 - val_loss: 0.1894 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1892 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 175us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1890 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 245us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1888 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 265us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 233us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1884 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 200us/step - loss: 0.2412 - acc: 0.6000 - val_loss: 0.1882 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 224us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1880 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 222us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1878 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 205us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1876 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 189us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1874 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 254us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1873 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1871 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 178us/step - loss: 0.2411 - acc: 0.6000 - val_loss: 0.1869 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 162us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1867 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 153us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1865 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 192us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1863 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 185us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1862 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 186us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 323us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1858 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1856 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 194us/step - loss: 0.2410 - acc: 0.6000 - val_loss: 0.1854 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 149us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1853 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 181us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 195us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1849 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1847 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 219us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1846 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 214us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1844 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 223us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1842 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 188us/step - loss: 0.2409 - acc: 0.6000 - val_loss: 0.1841 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 193us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1839 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 229us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1837 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 254us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 248us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1834 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 212us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 169us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 317us/step - loss: 0.2408 - acc: 0.6000 - val_loss: 0.1829 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = network2.fit(X_train, y_train, epochs=500, verbose=1, batch_size=len(X_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 489us/step\n",
      "Loss: 25.523075461387634%\n",
      "Accuracy: 50.0%\n",
      "Time: 2.1943225860595703 s\n"
     ]
    }
   ],
   "source": [
    "score2 = network2.evaluate(X_test, y_test, batch_size=len(X_train))\n",
    "\n",
    "print(\"Loss: \" + str(score2[0]*100.0) + \"%\")\n",
    "print(\"Accuracy: \" + str(score2[1]*100.0) + \"%\")\n",
    "print(\"Time: \" + str(end) +\" s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
